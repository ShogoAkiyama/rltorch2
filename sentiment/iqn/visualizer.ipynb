{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "import warnings ; warnings.filterwarnings('ignore') # mute warnings, live dangerously\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl ; mpl.use(\"Agg\")\n",
    "\n",
    "from model import IQN\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torchtext\n",
    "from utils import tokenizer_with_preprocessing\n",
    "import os\n",
    "from torchtext.vocab import Vectors\n",
    "from trainer import Trainer\n",
    "NEWS_PATH = os.path.join('..', 'data', 'news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=None)\n",
    "parser.add_argument('-e', '--env', default='PongNoFrameskip-v4', type=str, help='gym environment')\n",
    "parser.add_argument('-d', '--density', default=1, type=int, help='density of grid of gaussian blurs')\n",
    "parser.add_argument('-r', '--radius', default=5, type=int, help='radius of gaussian blur')\n",
    "parser.add_argument('-f', '--num_frames', default=100, type=int, help='number of frames in movie')\n",
    "parser.add_argument('-i', '--first_frame', default=150, type=int, help='index of first frame')\n",
    "parser.add_argument('-dpi', '--resolution', default=75, type=int, help='resolution (dpi)')\n",
    "parser.add_argument('-s', '--save_dir', default='./movies/', type=str,\n",
    "                    help='dir to save agent logs and checkpoints')\n",
    "parser.add_argument('-p', '--prefix', default='default', type=str, help='prefix to help make video name unique')\n",
    "parser.add_argument('-c', '--checkpoint', default='*.tar', type=str,\n",
    "                    help='checkpoint name (in case there is more than one')\n",
    "parser.add_argument('-o', '--overfit_mode', default=False, type=bool,\n",
    "                    help='analyze an overfit environment (see paper)')\n",
    "\n",
    "\n",
    "# text parameter\n",
    "parser.add_argument('--max_length', type=int, default=256)\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--target_update_freq', type=int, default=100)\n",
    "parser.add_argument('--evaluation_freq', type=int, default=10)\n",
    "parser.add_argument('--network_save_freq', type=int, default=100)\n",
    "parser.add_argument('--num_actions', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--min_freq', type=int, default=10)\n",
    "parser.add_argument('--embedding_dim', type=int, default=300)\n",
    "parser.add_argument('--n_filters', type=int, default=100)\n",
    "parser.add_argument('--filter_sizes', type=list, default=[3, 4, 5])\n",
    "parser.add_argument('--pad_idx', type=list, default=1)\n",
    "parser.add_argument('--gamma', type=float, default=0.0)\n",
    "parser.add_argument('--learning_rate', type=float, default=2.5e-5)\n",
    "parser.add_argument('--num_quantile', type=int, default=64)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "parser.add_argument('--device', type=str, default=device)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.rnn = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データを取り出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込んだ内容に対して行う処理を定義\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing,\n",
    "                            use_vocab=True, lower=True, include_lengths=True,\n",
    "                            batch_first=True, fix_length=args.max_length,\n",
    "                            init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False, dtype=torch.float)\n",
    "\n",
    "train_ds = torchtext.data.TabularDataset.splits(\n",
    "    path=NEWS_PATH, train='text_train.tsv',\n",
    "    format='tsv',\n",
    "    fields=[('Text1', TEXT), ('Text2', TEXT), ('Label', LABEL)])\n",
    "train_ds = train_ds[0]\n",
    "\n",
    "test_ds = torchtext.data.TabularDataset.splits(\n",
    "    path=NEWS_PATH, train='text_test.tsv',\n",
    "    format='tsv',\n",
    "    fields=[('Text1', TEXT), ('Text2', TEXT), ('Label', LABEL)])\n",
    "test_ds = test_ds[0]\n",
    "\n",
    "japanese_fasttext_vectors = Vectors(name='../data/news/cc.ja.300.vec')\n",
    "TEXT.build_vocab(train_ds,\n",
    "                 vectors=japanese_fasttext_vectors,\n",
    "                 min_freq=args.min_freq)\n",
    "TEXT.vocab.freqs\n",
    "\n",
    "train_dl = torchtext.data.Iterator(\n",
    "    train_ds, batch_size=1, train=True)\n",
    "test_dl = torchtext.data.Iterator(\n",
    "    test_ds, batch_size=1, train=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IQN(\n",
       "  (embedding): Embedding(596, 300)\n",
       "  (phi): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (cnn): CNN(\n",
       "    (convs): ModuleList(\n",
       "      (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
       "      (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
       "      (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
       "    )\n",
       "    (fc0): Linear(in_features=300, out_features=64, bias=True)\n",
       "  )\n",
       "  (rnn): RNN(\n",
       "    (lstm): LSTM(300, 100, batch_first=True, bidirectional=True)\n",
       "    (attn): Attn(\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=24, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=24, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (fc0): Linear(in_features=100, out_features=64, bias=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc_q): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "vocab_size = len(TEXT.vocab.freqs)\n",
    "model = IQN(TEXT.vocab.vectors, vocab_size, args.embedding_dim, args.n_filters,\n",
    "                         args.filter_sizes, args.pad_idx,\n",
    "                         d_model=300,\n",
    "                         n_actions=args.num_actions,\n",
    "                         n_quant=args.num_quantile,\n",
    "                         rnn=args.rnn)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "trainer = Trainer(args, TEXT, train_dl)\n",
    "trainer.load_model()\n",
    "trainer.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rolloutの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを作成する関数を実装\n",
    "def highlight(word, attn):\n",
    "    \"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\"\n",
    "\n",
    "    if attn >= 0:\n",
    "        html_color = '#%02X%02X%02X' % (\n",
    "            255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    else:\n",
    "        html_color = '#%02X%02X%02X' % (\n",
    "            int(255*(1 - attn)), 255, int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
    "\n",
    "def mk_html(sentence, attens):\n",
    "\n",
    "    # 表示用のHTMLを作成する\n",
    "#     html = '正解ラベル：{}<br>推論ラベル：{}<br><br>'.format(reward, pred)\n",
    "    html = \"\"\n",
    "    # 1段目のAttention\n",
    "    html += '[TransformerBlockの1段目のAttentionを可視化]<br>'\n",
    "    for word, attn in zip(sentence, attens):\n",
    "        word = TEXT.vocab.itos[word]\n",
    "        if word[0] == '<':\n",
    "            word = word[1:-1]\n",
    "            if (word == 'pad') or (word=='unk'):\n",
    "                continue\n",
    "        html += highlight(word, attn)\n",
    "    html += \"<br><br>\"\n",
    "\n",
    "    return html\n",
    "\n",
    "def blur_func(I, mask):\n",
    "    return I * mask #+ I * mask#+ gaussian_filter(I, sigma=3) * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "rewards = []\n",
    "for batch in test_dl:\n",
    "    states.append(batch.Text1[0].numpy()[0])\n",
    "    rewards.append(batch.Label.numpy()[0])\n",
    "states = np.array(states)\n",
    "rewards = np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([1, 64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([256, 64, 1])\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "eta = 1\n",
    " \n",
    "sentence = states[idx]\n",
    "state = torch.LongTensor(sentence).to(device).unsqueeze(0)\n",
    "\n",
    "# 1次元maskの作成\n",
    "mask = np.zeros((1*256, 256)).astype(np.int8)\n",
    "\n",
    "for j in range(256):\n",
    "    circle = np.ones([256])\n",
    "    if (sentence[j] == 0) or (sentence[j] == 1) \\\n",
    "            or (sentence[j] == 2) or (sentence[j] == 3):\n",
    "        circle[j] = 1\n",
    "    else:\n",
    "        circle[j] = 0\n",
    "    mask[j] = circle.astype(np.int8)\n",
    "\n",
    "# ネットワークの出力を得る\n",
    "with torch.no_grad():\n",
    "    curr_q, _, _ = trainer.model(state, eta, True)\n",
    "    L = curr_q.mean()\n",
    "\n",
    "# 各ピクセルにマスクする\n",
    "masked_sentence = blur_func(sentence, mask)\n",
    "\n",
    "# ノイズを入れたデータの出力を得る\n",
    "state = torch.LongTensor(masked_sentence).to(device)\n",
    "state = state.view(-1, args.max_length)\n",
    "with torch.no_grad():\n",
    "    masked_curr_q, _, _ = trainer.model(state, eta, True)\n",
    "    l = masked_curr_q.mean(axis=1)\n",
    "\n",
    "pad_mask = np.ones([256])\n",
    "for j in range(256):\n",
    "    if (sentence[j] == 0) or (sentence[j] == 1) \\\n",
    "            or (sentence[j] == 2) or (sentence[j] == 3):\n",
    "        pad_mask[j] = 0\n",
    "    \n",
    "# スコアを記憶する配列\n",
    "scores = np.zeros(256)   # saliency scores S(t,i,j)\n",
    "\n",
    "for j in range(0, 256):\n",
    "    # d=5としてその部分を描画する\n",
    "#     scores[j] = (L-l[j]).pow(2).sum().mul_(.5).item()\n",
    "    scores[j] = (L-l[j]).sum().item()\n",
    "\n",
    "scores = scores * pad_mask\n",
    "saliency = scores / np.abs(scores).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = saliency.copy()\n",
    "# pmax = S.max()\n",
    "\n",
    "# S -= S.min()\n",
    "# S = pmax * S / S.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  1.29662 mean:  tensor(0.1983, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "[TransformerBlockの1段目のAttentionを可視化]<br><span style=\"background-color: #FFFFFF\"> cls</span><span style=\"background-color: #FFFEFE\"> location</span><span style=\"background-color: #FFF8F8\"> 開幕</span><span style=\"background-color: #1AFFF1AF\"> 車</span><span style=\"background-color: #1FEFF1FE\"> 各社</span><span style=\"background-color: #12AFF12A\"> サービス</span><span style=\"background-color: #FFFFFF\"> eos</span><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(7, 2));\n",
    "sns.distplot(curr_q.view(-1).cpu().numpy(), color='blue', ax=ax)\n",
    "\n",
    "print('reward: ', rewards[idx], \n",
    "          'mean: ', curr_q.mean())\n",
    "\n",
    "html_output = mk_html(states[idx], saliency)\n",
    "HTML(html_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1748, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_q.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   4, 290,   5,  30,  24,   8,  25,   9,   6,   7,   0,   9,\n",
       "         7,   1,  63, 300,   5,   5, 457, 545,   0, 118,  62,   0,   0,\n",
       "         1,   4,  62, 417, 385,  10, 298, 192,   0,   0,   1,  11,   5,\n",
       "        30,  24,  11,  22,  61,   4,   5, 442, 177,   1,  10,  36,   0,\n",
       "         0,   0, 210,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
