{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import csv\n",
    "import six\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import collections\n",
    "import argparse\n",
    "\n",
    "from torchtext.vocab import Vectors, Vocab\n",
    "import gensim\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "from model import IQN\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_csv_reader(unicode_csv_data, **kwargs):\n",
    "    # Fix field larger than field limit error\n",
    "    maxInt = sys.maxsize\n",
    "    while True:\n",
    "        # decrease the maxInt value by factor 10\n",
    "        # as long as the OverflowError occurs.\n",
    "        try:\n",
    "            csv.field_size_limit(maxInt)\n",
    "            break\n",
    "        except OverflowError:\n",
    "            maxInt = int(maxInt / 10)\n",
    "    csv.field_size_limit(maxInt)\n",
    "\n",
    "    if six.PY2:\n",
    "        # csv.py doesn't do Unicode; encode temporarily as UTF-8:\n",
    "        csv_reader = csv.reader(utf_8_encoder(unicode_csv_data), **kwargs)\n",
    "        for row in csv_reader:\n",
    "            # decode UTF-8 back to Unicode, cell by cell:\n",
    "            yield [cell.decode('utf-8') for cell in row]\n",
    "    else:\n",
    "        for line in csv.reader(unicode_csv_data, **kwargs):\n",
    "\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, max_len=64, vocab=None, specials=[]):\n",
    "        self.keys = ['Date', 'Code', 'State', 'Next_State', 'Reward']\n",
    "        self.string_keys = ['State', 'Next_State']\n",
    "        self.tensor_keys = ['Reward'] + self.string_keys\n",
    "        self.data_list = {k: [] for k in self.keys}\n",
    "        \n",
    "        with io.open(os.path.expanduser(path), encoding=\"utf8\") as f:\n",
    "            reader = unicode_csv_reader(f, delimiter='\\t')\n",
    "            for line in reader:\n",
    "                for k, x in zip(self.keys, line):\n",
    "                    if k in self.string_keys:\n",
    "                        self.data_list[k].append(x.split(':'))\n",
    "                    elif k in self.tensor_keys:\n",
    "                        self.data_list[k].append(float(x))\n",
    "                    else:\n",
    "                        self.data_list[k].append(x)\n",
    "        \n",
    "        self.unk_token = '<unk>'\n",
    "        self.pad_token = '<pad>'\n",
    "        self.init_token = '<cls>'\n",
    "        self.eos_token = '<eos>'\n",
    "        self.max_len = max_len\n",
    "        self.fix_len = self.max_len + (self.init_token, self.eos_token).count(None) - 2\n",
    "        self.specials = specials\n",
    "\n",
    "        self.words = list(itertools.chain.from_iterable(self.data_list['State']))\n",
    "        self.counter = Counter(self.words)\n",
    "\n",
    "        self.vocab = None\n",
    "        if vocab is not None: \n",
    "            self.vocab = vocab\n",
    "            self.padded_list = self.pad(self.data_list)\n",
    "            self.tensor_list = self.numericalize(self.padded_list)\n",
    "\n",
    "    def build_vocab(self, vectors, min_freq):\n",
    "        specials = list(OrderedDict.fromkeys(\n",
    "            tok for tok in [self.unk_token, self.pad_token, self.init_token,\n",
    "                            self.eos_token] + self.specials\n",
    "            if tok is not None))\n",
    "        self.vocab = Vocab(self.counter, \n",
    "                                           specials=specials, \n",
    "                                           vectors=vectors, \n",
    "                                           min_freq=min_freq) \n",
    "        self.padded_list = self.pad(self.data_list)\n",
    "        self.tensor_list = self.numericalize(self.padded_list)\n",
    "\n",
    "    def pad(self, data):\n",
    "        padded = {k: [] for k in self.keys}\n",
    "        for key, val in data.items():\n",
    "            if key in self.string_keys:\n",
    "                arr = []\n",
    "                for x in val:\n",
    "                    arr.append(\n",
    "                        ([self.init_token])\n",
    "                        + list(x[:self.fix_len])\n",
    "                        + ([self.eos_token])\n",
    "                        + [self.pad_token] * max(0, self.fix_len - len(x)))\n",
    "                padded[key] = arr\n",
    "            else:                \n",
    "                padded[key] = val\n",
    "\n",
    "        return padded\n",
    "\n",
    "    def numericalize(self, padded):\n",
    "        tensor = {k: [] for k in self.keys}\n",
    "        for key, val in padded.items():\n",
    "            if key in self.string_keys:\n",
    "                arr = []\n",
    "                for ex in val:\n",
    "                    arr.append([self.vocab.stoi[x] for x in ex])\n",
    "                tensor[key] = torch.LongTensor(arr).to('cpu')\n",
    "            elif key in self.tensor_keys:\n",
    "                tensor[key] = torch.FloatTensor(val).to('cpu')\n",
    "            else:                \n",
    "                tensor[key] = val\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_list['State'])\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        arr = {k: [] for k in self.keys}\n",
    "        for key in self.keys:\n",
    "            arr[key] = self.tensor_list[key][i]\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MyDataset(\n",
    "    path=os.path.join('..', 'data', 'news', 'text_train.tsv'),\n",
    "    specials=['<company>', '<organization>', '<person>', '<location>']\n",
    ")\n",
    "\n",
    "japanese_fasttext_vectors = Vectors(name='../data/news/cc.ja.300.vec')\n",
    "\n",
    "train_ds.build_vocab(\n",
    "    vectors=japanese_fasttext_vectors,\n",
    "    min_freq=10)\n",
    "\n",
    "test_ds = MyDataset(\n",
    "    path=os.path.join('..', 'data', 'news', 'text_test.tsv'),\n",
    "    vocab=train_ds.vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, \n",
    "    batch_size = 32, \n",
    "    shuffle = True, \n",
    "    num_workers = 2\n",
    ")\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds, \n",
    "    batch_size = 32, \n",
    "    shuffle = False, \n",
    "    num_workers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=None)\n",
    "parser.add_argument('-e', '--env', default='PongNoFrameskip-v4', type=str, help='gym environment')\n",
    "parser.add_argument('-d', '--density', default=1, type=int, help='density of grid of gaussian blurs')\n",
    "parser.add_argument('-r', '--radius', default=5, type=int, help='radius of gaussian blur')\n",
    "parser.add_argument('-f', '--num_frames', default=100, type=int, help='number of frames in movie')\n",
    "parser.add_argument('-i', '--first_frame', default=150, type=int, help='index of first frame')\n",
    "parser.add_argument('-dpi', '--resolution', default=75, type=int, help='resolution (dpi)')\n",
    "parser.add_argument('-s', '--save_dir', default='./movies/', type=str,\n",
    "                    help='dir to save agent logs and checkpoints')\n",
    "parser.add_argument('-p', '--prefix', default='default', type=str, help='prefix to help make video name unique')\n",
    "parser.add_argument('-c', '--checkpoint', default='*.tar', type=str,\n",
    "                    help='checkpoint name (in case there is more than one')\n",
    "parser.add_argument('-o', '--overfit_mode', default=False, type=bool,\n",
    "                    help='analyze an overfit environment (see paper)')\n",
    "\n",
    "# text parameter\n",
    "parser.add_argument('--max_length', type=int, default=64)\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--target_update_freq', type=int, default=100)\n",
    "parser.add_argument('--evaluation_freq', type=int, default=10)\n",
    "parser.add_argument('--network_save_freq', type=int, default=100)\n",
    "parser.add_argument('--num_actions', type=int, default=1)\n",
    "\n",
    "parser.add_argument('--min_freq', type=int, default=10)\n",
    "parser.add_argument('--embedding_dim', type=int, default=300)\n",
    "parser.add_argument('--n_filters', type=int, default=50)\n",
    "parser.add_argument('--filter_sizes', type=list, default=[3, 4, 5])\n",
    "parser.add_argument('--pad_idx', type=list, default=1)\n",
    "parser.add_argument('--gamma', type=float, default=0.0)\n",
    "parser.add_argument('--learning_rate', type=float, default=2.5e-5)\n",
    "parser.add_argument('--round', type=float, default=0)\n",
    "\n",
    "parser.add_argument('--num_quantile', type=int, default=32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "parser.add_argument('--device', type=str, default=device)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.rnn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for IQN:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([2638, 300]) from checkpoint, the shape in current model is torch.Size([1493, 300]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b4bb4c212dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ShogoAkiyama/rltorch2/sentiment/iqn/trainer.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for IQN:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([2638, 300]) from checkpoint, the shape in current model is torch.Size([1493, 300])."
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "text_vectors = train_ds.vocab.vectors\n",
    "vocab_size = len(train_ds.vocab.vectors)\n",
    "model = IQN(text_vectors, vocab_size, args.embedding_dim, args.n_filters,\n",
    "                         args.filter_sizes, args.pad_idx,\n",
    "                         n_actions=args.num_actions,\n",
    "                         n_quant=args.num_quantile,\n",
    "                         rnn=args.rnn)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "trainer = Trainer(args, text_vectors, vocab_size, train_dl)\n",
    "trainer.load_model()\n",
    "trainer.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
