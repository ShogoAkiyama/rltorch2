{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext import data, datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import QRDQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(range(2011, 2019)):\n",
    "    tmp = pd.read_csv('./data/news/' + str(date) + '.csv', encoding='cp932')\n",
    "    tmp = tmp[tmp['Company_IDs(TSE)'] == '7203']\n",
    "    tmp = tmp[['Time_Stamp_Original(JST)', \n",
    "                        'Company_Code(TSE)', \n",
    "                        'Headline', \n",
    "                        'News_Source',\n",
    "                        'Company_Relevance', \n",
    "                        'Keyword_Article']]\n",
    "\n",
    "    # 欠損除去\n",
    "    tmp = tmp[~tmp[\"Keyword_Article\"].isnull()]\n",
    "\n",
    "    # タグ除去\n",
    "    tmp = tmp[(tmp['News_Source'] == '日経') | \n",
    "                        (tmp['News_Source'] == 'ＮＱＮ') |\n",
    "                        (tmp['News_Source'] == 'ＱＵＩＣＫ') | \n",
    "                        (tmp['News_Source'] == 'Ｒ＆Ｉ')]\n",
    "\n",
    "    tmp.index = pd.to_datetime(tmp[\"Time_Stamp_Original(JST)\"])\n",
    "    tmp = tmp.drop(\"Time_Stamp_Original(JST)\", axis=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        df1 = tmp.copy()\n",
    "    else:\n",
    "        df1 = pd.concat([df1, tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# インデックスを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_time(x):\n",
    "    if x.hour > 15:\n",
    "        return x + datetime.timedelta(days=1)\n",
    "    return x\n",
    "\n",
    "time = pd.to_datetime(df1.index.values)\n",
    "df1.index = df1.index.map(norm_time)\n",
    "df1.index = df1.index.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 株価を挿入する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>3265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>3295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>3380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>3455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11</th>\n",
       "      <td>3455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12</th>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-13</th>\n",
       "      <td>3535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-14</th>\n",
       "      <td>3550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-18</th>\n",
       "      <td>3510.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            adj_close\n",
       "2011-01-04     3265.0\n",
       "2011-01-05     3295.0\n",
       "2011-01-06     3380.0\n",
       "2011-01-07     3455.0\n",
       "2011-01-11     3455.0\n",
       "2011-01-12     3500.0\n",
       "2011-01-13     3535.0\n",
       "2011-01-14     3550.0\n",
       "2011-01-17     3500.0\n",
       "2011-01-18     3510.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 株価を取り出す\n",
    "df2 = pd.read_csv('./data/stock_price/7203.csv', index_col=0)\n",
    "df2.index = pd.to_datetime(df2['date'])\n",
    "df2.index = df2.index.date\n",
    "df2 = df2.drop(['date'], axis=1)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時系列をくっつける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ts-zemi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.concat([df1,df2], axis=1, join_axes=[df1.index])\n",
    "df3['price'] = np.round(df2.pct_change().shift(-1) * 100, 3)\n",
    "df3['Keyword_Article'] = \\\n",
    "    df3.groupby(level=0).apply(lambda x: ':<pad>:'.join(list(x['Keyword_Article'])))\n",
    "df3 = df3.dropna()\n",
    "\n",
    "df3 = df3[~df3.duplicated(subset=['Keyword_Article'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Code(TSE)</th>\n",
       "      <th>Headline</th>\n",
       "      <th>News_Source</th>\n",
       "      <th>Company_Relevance</th>\n",
       "      <th>Keyword_Article</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇次世代車の研究開発　名大に国内最大拠点</td>\n",
       "      <td>日経</td>\n",
       "      <td>38</td>\n",
       "      <td>安全:環境:負荷:開発:目指す:開所式:研究拠点:効率:簡素化:次世代:電気自動車:電気:幅...</td>\n",
       "      <td>3265.0</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇12月の中国新車販売、トヨタが単月で過去最高</td>\n",
       "      <td>日経</td>\n",
       "      <td>100</td>\n",
       "      <td>北京:中国:１２月:新車販売台数:前年同月比:増:過去最高:制限:受け:全国:各地:乗用車:...</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>2.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;NQN&gt;◇トヨタ社長「今年は後半に晴れ間」　為替は１ドル＝90円を期待</td>\n",
       "      <td>ＮＱＮ</td>\n",
       "      <td>100</td>\n",
       "      <td>豊田:見通し:販売:エコカー補助金:安定的:伸び:株価:為替:水準:日経平均株価:最低:ライ...</td>\n",
       "      <td>3380.0</td>\n",
       "      <td>2.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇福岡県、自動車の技術者育成へ新組織　年内、中小向け</td>\n",
       "      <td>日経</td>\n",
       "      <td>37</td>\n",
       "      <td>自動車産業:強化:福岡:先端:設置:方針:技術:調査:ニーズ:カリキュラム:大学:受け:生産...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇トヨタ、米ミシガン州に安全研究センター新設</td>\n",
       "      <td>日経</td>\n",
       "      <td>100</td>\n",
       "      <td>先進:安全:子供:高齢者:事故:向上:目指す:米国:大規模:リコール:回収:問題:開催:豊田...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>1.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Company_Code(TSE)                              Headline  \\\n",
       "2011-01-04             7203.0              <日経>◇次世代車の研究開発　名大に国内最大拠点   \n",
       "2011-01-05             7203.0           <日経>◇12月の中国新車販売、トヨタが単月で過去最高   \n",
       "2011-01-06             7203.0  <NQN>◇トヨタ社長「今年は後半に晴れ間」　為替は１ドル＝90円を期待   \n",
       "2011-01-07             7203.0        <日経>◇福岡県、自動車の技術者育成へ新組織　年内、中小向け   \n",
       "2011-01-11             7203.0            <日経>◇トヨタ、米ミシガン州に安全研究センター新設   \n",
       "\n",
       "           News_Source Company_Relevance  \\\n",
       "2011-01-04          日経                38   \n",
       "2011-01-05          日経               100   \n",
       "2011-01-06         ＮＱＮ               100   \n",
       "2011-01-07          日経                37   \n",
       "2011-01-11          日経               100   \n",
       "\n",
       "                                              Keyword_Article  adj_close  \\\n",
       "2011-01-04  安全:環境:負荷:開発:目指す:開所式:研究拠点:効率:簡素化:次世代:電気自動車:電気:幅...     3265.0   \n",
       "2011-01-05  北京:中国:１２月:新車販売台数:前年同月比:増:過去最高:制限:受け:全国:各地:乗用車:...     3295.0   \n",
       "2011-01-06  豊田:見通し:販売:エコカー補助金:安定的:伸び:株価:為替:水準:日経平均株価:最低:ライ...     3380.0   \n",
       "2011-01-07  自動車産業:強化:福岡:先端:設置:方針:技術:調査:ニーズ:カリキュラム:大学:受け:生産...     3455.0   \n",
       "2011-01-11  先進:安全:子供:高齢者:事故:向上:目指す:米国:大規模:リコール:回収:問題:開催:豊田...     3455.0   \n",
       "\n",
       "            price  \n",
       "2011-01-04  0.919  \n",
       "2011-01-05  2.580  \n",
       "2011-01-06  2.219  \n",
       "2011-01-07  0.000  \n",
       "2011-01-11  1.302  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csvファイルに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date = 2015\n",
    "test_date = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df3[['Keyword_Article', 'price']].rename(\n",
    "                                      columns={'Keyword_Article': 'state', 'price': 'reward'}),\n",
    "                               df3[['Keyword_Article']].shift(-1).rename(\n",
    "                                      columns={'Keyword_Article': 'next_state'})], axis=1).dropna()\n",
    "df4 = df4[['state', 'next_state', 'reward']]\n",
    "\n",
    "date_year = df4.index.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[date_year <= train_date].to_csv(\n",
    "        './data/news/text_train.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[(train_date < date_year) & (date_year < test_date)].to_csv(\n",
    "        './data/news/text_val.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[test_date <= date_year].to_csv(\n",
    "        './data/news/text_test.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "def preprocessing_text(text):\n",
    "    # カンマ、ピリオド以外の記号をスペースに置換\n",
    "    for p in string.punctuation:\n",
    "        if (p == \".\") or (p == \",\") or (p == \":\") or (p == \"<\")or (p == \">\"):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    # ピリオドなどの前後にはスペースを入れておく\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = re.sub(r'[0-9 ０-９]', '0', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
    "def tokenizer_punctuation(text):\n",
    "    return text.strip().split(':')\n",
    "\n",
    "# 前処理と分かち書きをまとめた関数を定義\n",
    "def tokenizer_with_preprocessing(text):\n",
    "    text = preprocessing_text(text)\n",
    "    ret = tokenizer_punctuation(text)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# 読み込んだ内容に対して行う処理を定義\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, \n",
    "                            use_vocab=True,\n",
    "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, \n",
    "                            init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/news', train='text_train.tsv',\n",
    "    format='tsv',\n",
    "    fields=[('Text1', TEXT), ('Text2', TEXT), ('Label', LABEL)])\n",
    "train_ds = train_ds[0]\n",
    "\n",
    "japanese_fasttext_vectors = Vectors(name='./data/news/cc.ja.300.vec')\n",
    "TEXT.build_vocab(train_ds, \n",
    "                                 vectors=japanese_fasttext_vectors,\n",
    "                                 min_freq=10)\n",
    "TEXT.vocab.freqs\n",
    "\n",
    "train_dl = torchtext.data.Iterator(\n",
    "    train_ds, batch_size=batch_size, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   2,   10,  820,  ...,    1,    1,    1],\n",
      "        [   2,   81,   33,  ...,    1,    1,    1],\n",
      "        [   2, 2013,  189,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,  288,  396,  ...,    1,    1,    1],\n",
      "        [   2,   28,   26,  ...,    1,    1,    1],\n",
      "        [   2, 1674,  149,  ...,    1,    1,    1]]), tensor([ 63, 368,  92, 159, 108,  71, 432,  47,  64, 106,  43,  71, 173,  49,\n",
      "         32, 350,  64, 173, 276, 216, 195,  25,  10,  75,  62,  12, 207,  34,\n",
      "         53,  20,  16,  60]))\n",
      "(tensor([[  2,   4, 115,  ...,   1,   1,   1],\n",
      "        [  2,  28, 108,  ...,   1,   1,   1],\n",
      "        [  2,   4, 212,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [  2, 172,  13,  ...,   1,   1,   1],\n",
      "        [  2,   4,  10,  ...,   1,   1,   1],\n",
      "        [  2,  59,  35,  ...,   1,   1,   1]]), tensor([172, 185, 221, 235, 100,  74, 318,  34,   6,  36, 130, 169,  52,  39,\n",
      "         45, 119, 273,  41,  43, 183, 328, 164,  54,  73,  98,  26,  43,  16,\n",
      "        148,  25,  12, 155]))\n",
      "tensor([ 1.8780, -0.4050,  0.8910,  0.2810, -1.6620,  0.4330,  0.9350,  0.8200,\n",
      "         0.1580, -0.1520,  0.3010,  0.5930,  0.1280,  1.7210, -0.5580, -1.0010,\n",
      "        -2.1620, -4.2180,  0.6410, -0.9700, -1.0890, -0.1590, -0.9100, -0.1270,\n",
      "        -0.8040, -0.1540, -1.1900,  0.3500,  0.0830, -1.3890, -0.1920, -0.4930])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "print(batch.Text1)\n",
    "print(batch.Text2)\n",
    "print(batch.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab.freqs)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = 1\n",
    "NUM_QUANTILE = 51\n",
    "GAMMA = 0.99\n",
    "cumulative_density = torch.FloatTensor(\n",
    "            (2 * np.arange(NUM_QUANTILE) + 1) / (2.0 * NUM_QUANTILE)).to(device)\n",
    "\n",
    "quantile_weight = 1.0 / NUM_QUANTILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = QRDQN(TEXT.vocab.vectors, VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS,\n",
    "                        FILTER_SIZES, PAD_IDX)\n",
    "\n",
    "target_model = QRDQN(TEXT.vocab.vectors, VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS,\n",
    "                        FILTER_SIZES, PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "target_model = target_model.to(device)\n",
    "\n",
    "target_model.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法\n",
    "learning_rate = 2.5e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(scores, y):    \n",
    "    correct = (scores == y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()\n",
    "    return acc\n",
    "\n",
    "def huber(x):\n",
    "        cond = (x.abs() < 1.0).float().detach()\n",
    "        return 0.5 * x.pow(2) * cond + (x.abs() - 0.5) * (1.0 - cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "## テスト\n",
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----start----\n",
      "--------------------\n",
      "epoch: 0\n",
      "loss: 18.31231117248535\n",
      "epi_reward: 112.33800124563277\n",
      "neutrals: 531   buys: 488\n",
      "--------------------\n",
      "epoch: 1\n",
      "loss: 9.54949951171875\n",
      "epi_reward: 53.62999990209937\n",
      "neutrals: 523   buys: 496\n",
      "--------------------\n",
      "epoch: 2\n",
      "loss: 6.329699516296387\n",
      "epi_reward: 66.58300011977553\n",
      "neutrals: 527   buys: 492\n",
      "--------------------\n",
      "epoch: 3\n",
      "loss: 5.594922065734863\n",
      "epi_reward: 87.6720001026988\n",
      "neutrals: 489   buys: 530\n",
      "--------------------\n",
      "epoch: 4\n",
      "loss: 5.325076580047607\n",
      "epi_reward: 45.84700130484998\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 5\n",
      "loss: 5.884603977203369\n",
      "epi_reward: 27.05100073106587\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 6\n",
      "loss: 6.107192516326904\n",
      "epi_reward: 77.89000067487359\n",
      "neutrals: 490   buys: 529\n",
      "--------------------\n",
      "epoch: 7\n",
      "loss: 5.373363494873047\n",
      "epi_reward: 45.28099951148033\n",
      "neutrals: 495   buys: 524\n",
      "--------------------\n",
      "epoch: 8\n",
      "loss: 5.438186168670654\n",
      "epi_reward: 68.6150014270097\n",
      "neutrals: 508   buys: 511\n",
      "--------------------\n",
      "epoch: 9\n",
      "loss: 5.459033012390137\n",
      "epi_reward: 58.83800013922155\n",
      "neutrals: 511   buys: 508\n",
      "--------------------\n",
      "epoch: 10\n",
      "loss: 16.356000900268555\n",
      "epi_reward: 81.1930015925318\n",
      "neutrals: 488   buys: 531\n",
      "--------------------\n",
      "epoch: 11\n",
      "loss: 9.577017784118652\n",
      "epi_reward: 48.41099996492267\n",
      "neutrals: 489   buys: 530\n",
      "--------------------\n",
      "epoch: 12\n",
      "loss: 4.535859107971191\n",
      "epi_reward: 32.72800008393824\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 13\n",
      "loss: 3.8767147064208984\n",
      "epi_reward: 59.4660027064383\n",
      "neutrals: 534   buys: 485\n",
      "--------------------\n",
      "epoch: 14\n",
      "loss: 4.450021266937256\n",
      "epi_reward: 55.6380007956177\n",
      "neutrals: 525   buys: 494\n",
      "--------------------\n",
      "epoch: 15\n",
      "loss: 3.9761619567871094\n",
      "epi_reward: 12.299000995233655\n",
      "neutrals: 528   buys: 491\n",
      "--------------------\n",
      "epoch: 16\n",
      "loss: 4.256704807281494\n",
      "epi_reward: 84.94299981743097\n",
      "neutrals: 514   buys: 505\n",
      "--------------------\n",
      "epoch: 17\n",
      "loss: 3.861494302749634\n",
      "epi_reward: 56.09500099532306\n",
      "neutrals: 494   buys: 525\n",
      "--------------------\n",
      "epoch: 18\n",
      "loss: 4.114618301391602\n",
      "epi_reward: 32.269000202417374\n",
      "neutrals: 526   buys: 493\n",
      "--------------------\n",
      "epoch: 19\n",
      "loss: 3.2594194412231445\n",
      "epi_reward: 18.44000086002052\n",
      "neutrals: 492   buys: 527\n",
      "--------------------\n",
      "epoch: 20\n",
      "loss: 15.042960166931152\n",
      "epi_reward: 30.250001752749085\n",
      "neutrals: 495   buys: 524\n",
      "--------------------\n",
      "epoch: 21\n",
      "loss: 6.911059856414795\n",
      "epi_reward: 9.942000817507505\n",
      "neutrals: 479   buys: 540\n",
      "--------------------\n",
      "epoch: 22\n",
      "loss: 4.211226940155029\n",
      "epi_reward: 53.13999976962805\n",
      "neutrals: 511   buys: 508\n",
      "--------------------\n",
      "epoch: 23\n",
      "loss: 3.7849786281585693\n",
      "epi_reward: 26.11600013822317\n",
      "neutrals: 492   buys: 527\n",
      "--------------------\n",
      "epoch: 24\n",
      "loss: 3.5471293926239014\n",
      "epi_reward: 18.33500105328858\n",
      "neutrals: 509   buys: 510\n",
      "--------------------\n",
      "epoch: 25\n",
      "loss: 3.1140811443328857\n",
      "epi_reward: 20.50600142776966\n",
      "neutrals: 501   buys: 518\n",
      "--------------------\n",
      "epoch: 26\n",
      "loss: 3.232640504837036\n",
      "epi_reward: 28.151998661458492\n",
      "neutrals: 557   buys: 462\n",
      "--------------------\n",
      "epoch: 27\n",
      "loss: 3.2467222213745117\n",
      "epi_reward: 36.45100033469498\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 28\n",
      "loss: 3.0197017192840576\n",
      "epi_reward: 50.32700123824179\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 29\n",
      "loss: 3.0837578773498535\n",
      "epi_reward: 59.00199959985912\n",
      "neutrals: 511   buys: 508\n",
      "--------------------\n",
      "epoch: 30\n",
      "loss: 18.91461944580078\n",
      "epi_reward: 45.57100106962025\n",
      "neutrals: 516   buys: 503\n",
      "--------------------\n",
      "epoch: 31\n",
      "loss: 6.097155570983887\n",
      "epi_reward: 7.995001146569848\n",
      "neutrals: 516   buys: 503\n",
      "--------------------\n",
      "epoch: 32\n",
      "loss: 2.967683792114258\n",
      "epi_reward: -15.880999371409416\n",
      "neutrals: 536   buys: 483\n",
      "--------------------\n",
      "epoch: 33\n",
      "loss: 3.5486996173858643\n",
      "epi_reward: 59.80199998989701\n",
      "neutrals: 539   buys: 480\n",
      "--------------------\n",
      "epoch: 34\n",
      "loss: 2.6177046298980713\n",
      "epi_reward: 22.57800135947764\n",
      "neutrals: 524   buys: 495\n",
      "--------------------\n",
      "epoch: 35\n",
      "loss: 3.7521519660949707\n",
      "epi_reward: 27.54600084014237\n",
      "neutrals: 536   buys: 483\n",
      "--------------------\n",
      "epoch: 36\n",
      "loss: 2.741774797439575\n",
      "epi_reward: 61.77399920113385\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 37\n",
      "loss: 2.8949642181396484\n",
      "epi_reward: 20.018000738695264\n",
      "neutrals: 483   buys: 536\n",
      "--------------------\n",
      "epoch: 38\n",
      "loss: 3.431928873062134\n",
      "epi_reward: 19.504001459106803\n",
      "neutrals: 526   buys: 493\n",
      "--------------------\n",
      "epoch: 39\n",
      "loss: 2.7661004066467285\n",
      "epi_reward: 2.458999350667\n",
      "neutrals: 511   buys: 508\n",
      "--------------------\n",
      "epoch: 40\n",
      "loss: 13.05723762512207\n",
      "epi_reward: 73.42199968546629\n",
      "neutrals: 494   buys: 525\n",
      "--------------------\n",
      "epoch: 41\n",
      "loss: 6.0106706619262695\n",
      "epi_reward: 23.731999345123768\n",
      "neutrals: 526   buys: 493\n",
      "--------------------\n",
      "epoch: 42\n",
      "loss: 7.857501983642578\n",
      "epi_reward: 64.300999796018\n",
      "neutrals: 514   buys: 505\n",
      "--------------------\n",
      "epoch: 43\n",
      "loss: 2.4738755226135254\n",
      "epi_reward: 61.174999583512545\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 44\n",
      "loss: 2.709383964538574\n",
      "epi_reward: 57.80700094439089\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 45\n",
      "loss: 3.0147950649261475\n",
      "epi_reward: -4.792000386863947\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 46\n",
      "loss: 2.899461507797241\n",
      "epi_reward: 58.60400057211518\n",
      "neutrals: 514   buys: 505\n",
      "--------------------\n",
      "epoch: 47\n",
      "loss: 2.746131420135498\n",
      "epi_reward: 62.61000116355717\n",
      "neutrals: 508   buys: 511\n",
      "--------------------\n",
      "epoch: 48\n",
      "loss: 2.468524217605591\n",
      "epi_reward: 20.89200118370354\n",
      "neutrals: 524   buys: 495\n",
      "--------------------\n",
      "epoch: 49\n",
      "loss: 2.542750120162964\n",
      "epi_reward: 32.2540004234761\n",
      "neutrals: 522   buys: 497\n",
      "--------------------\n",
      "epoch: 50\n",
      "loss: 11.882946014404297\n",
      "epi_reward: 43.853000620380044\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 51\n",
      "loss: 5.709384441375732\n",
      "epi_reward: 60.80399934388697\n",
      "neutrals: 515   buys: 504\n",
      "--------------------\n",
      "epoch: 52\n",
      "loss: 3.285398244857788\n",
      "epi_reward: 91.80500056780875\n",
      "neutrals: 515   buys: 504\n",
      "--------------------\n",
      "epoch: 53\n",
      "loss: 4.024109363555908\n",
      "epi_reward: 59.54400049522519\n",
      "neutrals: 514   buys: 505\n",
      "--------------------\n",
      "epoch: 54\n",
      "loss: 3.046747922897339\n",
      "epi_reward: 41.52300179377198\n",
      "neutrals: 501   buys: 518\n",
      "--------------------\n",
      "epoch: 55\n",
      "loss: 2.590196132659912\n",
      "epi_reward: -10.748998651281\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 56\n",
      "loss: 2.6271114349365234\n",
      "epi_reward: 29.24400021135807\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 57\n",
      "loss: 2.235196352005005\n",
      "epi_reward: 64.73299963213503\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 58\n",
      "loss: 2.3666200637817383\n",
      "epi_reward: 36.72499885596335\n",
      "neutrals: 515   buys: 504\n",
      "--------------------\n",
      "epoch: 59\n",
      "loss: 2.7161388397216797\n",
      "epi_reward: 12.814000809565187\n",
      "neutrals: 528   buys: 491\n",
      "--------------------\n",
      "epoch: 60\n",
      "loss: 14.903716087341309\n",
      "epi_reward: 57.09800040908158\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 61\n",
      "loss: 7.440536975860596\n",
      "epi_reward: 73.54199981689453\n",
      "neutrals: 497   buys: 522\n",
      "--------------------\n",
      "epoch: 62\n",
      "loss: 2.714709758758545\n",
      "epi_reward: 61.31500048562884\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 63\n",
      "loss: 2.8942391872406006\n",
      "epi_reward: 82.39100078493357\n",
      "neutrals: 518   buys: 501\n",
      "--------------------\n",
      "epoch: 64\n",
      "loss: 2.3618099689483643\n",
      "epi_reward: 52.095999831333756\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 65\n",
      "loss: 2.1553738117218018\n",
      "epi_reward: 48.771999068558216\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 66\n",
      "loss: 2.273042917251587\n",
      "epi_reward: 38.39500035345554\n",
      "neutrals: 476   buys: 543\n",
      "--------------------\n",
      "epoch: 67\n",
      "loss: 2.01658034324646\n",
      "epi_reward: 27.143000775948167\n",
      "neutrals: 494   buys: 525\n",
      "--------------------\n",
      "epoch: 68\n",
      "loss: 1.8714869022369385\n",
      "epi_reward: 1.0430014878511429\n",
      "neutrals: 527   buys: 492\n",
      "--------------------\n",
      "epoch: 69\n",
      "loss: 1.9841387271881104\n",
      "epi_reward: 25.171000257134438\n",
      "neutrals: 529   buys: 490\n",
      "--------------------\n",
      "epoch: 70\n",
      "loss: 15.557052612304688\n",
      "epi_reward: -10.005000811070204\n",
      "neutrals: 530   buys: 489\n",
      "--------------------\n",
      "epoch: 71\n",
      "loss: 5.581175804138184\n",
      "epi_reward: 28.290000459179282\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 72\n",
      "loss: 2.76277756690979\n",
      "epi_reward: 89.31800009310246\n",
      "neutrals: 534   buys: 485\n",
      "--------------------\n",
      "epoch: 73\n",
      "loss: 2.5363481044769287\n",
      "epi_reward: 37.639000453054905\n",
      "neutrals: 496   buys: 523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch: 74\n",
      "loss: 2.4790337085723877\n",
      "epi_reward: 69.85800004936755\n",
      "neutrals: 550   buys: 469\n",
      "--------------------\n",
      "epoch: 75\n",
      "loss: 2.3809802532196045\n",
      "epi_reward: 40.871000204235315\n",
      "neutrals: 499   buys: 520\n",
      "--------------------\n",
      "epoch: 76\n",
      "loss: 2.398771047592163\n",
      "epi_reward: 34.51500014029443\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 77\n",
      "loss: 2.0196568965911865\n",
      "epi_reward: 31.486000269651413\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 78\n",
      "loss: 2.109870433807373\n",
      "epi_reward: 16.712999569252133\n",
      "neutrals: 515   buys: 504\n",
      "--------------------\n",
      "epoch: 79\n",
      "loss: 2.1743500232696533\n",
      "epi_reward: 35.709000365808606\n",
      "neutrals: 501   buys: 518\n",
      "--------------------\n",
      "epoch: 80\n",
      "loss: 17.049877166748047\n",
      "epi_reward: 20.315001310780644\n",
      "neutrals: 515   buys: 504\n",
      "--------------------\n",
      "epoch: 81\n",
      "loss: 5.031386375427246\n",
      "epi_reward: 21.037000615149736\n",
      "neutrals: 530   buys: 489\n",
      "--------------------\n",
      "epoch: 82\n",
      "loss: 2.0729660987854004\n",
      "epi_reward: 11.57000270485878\n",
      "neutrals: 486   buys: 533\n",
      "--------------------\n",
      "epoch: 83\n",
      "loss: 2.4081506729125977\n",
      "epi_reward: 18.903001133352518\n",
      "neutrals: 509   buys: 510\n",
      "--------------------\n",
      "epoch: 84\n",
      "loss: 2.0147533416748047\n",
      "epi_reward: 68.4950007405132\n",
      "neutrals: 481   buys: 538\n",
      "--------------------\n",
      "epoch: 85\n",
      "loss: 2.364299774169922\n",
      "epi_reward: 75.5610010754317\n",
      "neutrals: 509   buys: 510\n",
      "--------------------\n",
      "epoch: 86\n",
      "loss: 1.7016708850860596\n",
      "epi_reward: 60.388999938964844\n",
      "neutrals: 522   buys: 497\n",
      "--------------------\n",
      "epoch: 87\n",
      "loss: 2.1030800342559814\n",
      "epi_reward: 39.10400088690221\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 88\n",
      "loss: 2.6769540309906006\n",
      "epi_reward: 58.15100108832121\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 89\n",
      "loss: 2.1497185230255127\n",
      "epi_reward: 51.501999689266086\n",
      "neutrals: 517   buys: 502\n",
      "--------------------\n",
      "epoch: 90\n",
      "loss: 14.279367446899414\n",
      "epi_reward: 22.740001056343317\n",
      "neutrals: 493   buys: 526\n",
      "--------------------\n",
      "epoch: 91\n",
      "loss: 7.612816333770752\n",
      "epi_reward: 6.773000128567219\n",
      "neutrals: 549   buys: 470\n",
      "--------------------\n",
      "epoch: 92\n",
      "loss: 5.68242883682251\n",
      "epi_reward: 9.910000029951334\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 93\n",
      "loss: 2.7022151947021484\n",
      "epi_reward: 55.74600018188357\n",
      "neutrals: 481   buys: 538\n",
      "--------------------\n",
      "epoch: 94\n",
      "loss: 1.8604313135147095\n",
      "epi_reward: 35.41599996201694\n",
      "neutrals: 507   buys: 512\n",
      "--------------------\n",
      "epoch: 95\n",
      "loss: 2.587148427963257\n",
      "epi_reward: 66.740001084283\n",
      "neutrals: 480   buys: 539\n",
      "--------------------\n",
      "epoch: 96\n",
      "loss: 3.1329288482666016\n",
      "epi_reward: 4.330000311136246\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 97\n",
      "loss: 2.961456060409546\n",
      "epi_reward: 25.526000516489148\n",
      "neutrals: 541   buys: 478\n",
      "--------------------\n",
      "epoch: 98\n",
      "loss: 2.590123414993286\n",
      "epi_reward: 38.954000337049365\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 99\n",
      "loss: 2.1404178142547607\n",
      "epi_reward: 33.16099898889661\n",
      "neutrals: 517   buys: 502\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "TARGET_UPDATE_FREQ = 10\n",
    "# dataloaders_dict = {'train': train_dl, 'val':val_dl}\n",
    "dataloaders_dict = {'train': train_dl}\n",
    "\n",
    "print('----start----')\n",
    "net.to(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epi_rewards = []\n",
    "    neutrals = []\n",
    "    buys = []\n",
    "    \n",
    "    # update target_model\n",
    "    if epoch % TARGET_UPDATE_FREQ == 0:\n",
    "        target_model.load_state_dict(model.state_dict())\n",
    "    \n",
    "    for batch in (dataloaders_dict['train']):      \n",
    "        # curr_q\n",
    "        states = batch.Text1[0].to(device)\n",
    "        next_states = batch.Text2[0].to(device)\n",
    "        rewards = batch.Label.to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            dist = net(states) * quantile_weight\n",
    "            actions = dist.sum(dim=2).max(1)[1]\n",
    "\n",
    "            actions = torch.where(torch.randn(len(states)).to(device) >= 0, \n",
    "                                                   actions, \n",
    "                                                  (actions + 1) % 2)\n",
    "\n",
    "            selected_actions = actions.detach().cpu().numpy()\n",
    "            actions = actions.view(states.size(0), 1, 1).expand(-1, -1, NUM_QUANTILE)\n",
    "\n",
    "\n",
    "        epi_rewards.append((selected_actions * rewards.detach().cpu().numpy()).sum())\n",
    "        neutrals.append(len(selected_actions[selected_actions == 0]))\n",
    "        buys.append(len(selected_actions[selected_actions == 1]))\n",
    "        \n",
    "        curr_q = model(states).gather(1, actions).squeeze(dim=1)\n",
    "\n",
    "        # target_q\n",
    "        with torch.no_grad():\n",
    "\n",
    "            next_dist = model(next_states) * quantile_weight\n",
    "            next_action = next_dist.sum(dim=2).max(1)[1].view(next_states.size(0), 1, 1).expand(\n",
    "                -1, -1, NUM_QUANTILE)\n",
    "\n",
    "            next_q = target_model(next_states).gather(1, next_action).squeeze(dim=1)\n",
    "            target_q = rewards.view(-1, 1) + (GAMMA * next_q)\n",
    "\n",
    "        diff = target_q.t().unsqueeze(-1) - curr_q.unsqueeze(0)\n",
    "        loss = huber(diff) * torch.abs(\n",
    "                        cumulative_density.view(1, -1) - (diff < 0).to(torch.float))\n",
    "        loss = loss.transpose(0, 1)\n",
    "        loss = loss.mean(1).sum(-1).mean()\n",
    "\n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in net.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('--------------------')\n",
    "    print('epoch:', epoch)\n",
    "    print('loss:', loss.item())\n",
    "    print('epi_reward:', sum(epi_rewards))\n",
    "    print('neutrals:', sum(neutrals), '  buys:', sum(buys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))\n",
    "states = batch.Text1[0].to(device)\n",
    "next_states = batch.Text2[0].to(device)\n",
    "rewards = batch.Label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = states[9]\n",
    "actions = (net(state.unsqueeze(0)) * quantile_weight)\n",
    "dist_action = actions[0].cpu().detach().numpy()\n",
    "# sns.distplot(dist_action[0], bins=51, color='red')\n",
    "sns.distplot(dist_action[1], bins=51, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0067, -0.0091,  0.0170, -0.0080, -0.0256, -0.0183, -0.0222,\n",
       "          -0.0038,  0.0068, -0.0106,  0.0103,  0.0130,  0.0037, -0.0078,\n",
       "          -0.0027,  0.0095, -0.0018, -0.0128,  0.0025, -0.0107, -0.0070,\n",
       "          -0.0122, -0.0007, -0.0040,  0.0016,  0.0162, -0.0029,  0.0048,\n",
       "          -0.0025, -0.0065,  0.0069,  0.0069,  0.0287,  0.0058,  0.0110,\n",
       "          -0.0213,  0.0178,  0.0264,  0.0240,  0.0245,  0.0073,  0.0084,\n",
       "          -0.0120, -0.0348, -0.0164, -0.0187,  0.0153, -0.0038,  0.0034,\n",
       "           0.0251, -0.0006],\n",
       "         [ 0.0024, -0.0165, -0.0020, -0.0181,  0.0314, -0.0339,  0.0186,\n",
       "          -0.0232, -0.0134,  0.0042, -0.0083,  0.0193, -0.0255, -0.0168,\n",
       "          -0.0156, -0.0097, -0.0103,  0.0084,  0.0135,  0.0107,  0.0107,\n",
       "           0.0031,  0.0044,  0.0084,  0.0262, -0.0418,  0.0363, -0.0134,\n",
       "           0.0058, -0.0152,  0.0045,  0.0108,  0.0111, -0.0197, -0.0134,\n",
       "           0.0073, -0.0099,  0.0238,  0.0059,  0.0097,  0.0164,  0.0139,\n",
       "          -0.0015, -0.0083,  0.0221,  0.0127,  0.0225,  0.0116,  0.0177,\n",
       "           0.0211,  0.0352]]], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
