{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext import data, datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import QRDQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(range(2011, 2019)):\n",
    "    tmp = pd.read_csv('./data/news/' + str(date) + '.csv', encoding='cp932')\n",
    "    tmp = tmp[tmp['Company_IDs(TSE)'] == '7203']\n",
    "    tmp = tmp[['Time_Stamp_Original(JST)', \n",
    "                        'Company_Code(TSE)', \n",
    "                        'Headline', \n",
    "                        'News_Source',\n",
    "                        'Company_Relevance', \n",
    "                        'Keyword_Article']]\n",
    "\n",
    "    # 欠損除去\n",
    "    tmp = tmp[~tmp[\"Keyword_Article\"].isnull()]\n",
    "\n",
    "    # タグ除去\n",
    "    tmp = tmp[(tmp['News_Source'] == '日経') | \n",
    "                        (tmp['News_Source'] == 'ＮＱＮ') |\n",
    "                        (tmp['News_Source'] == 'ＱＵＩＣＫ') | \n",
    "                        (tmp['News_Source'] == 'Ｒ＆Ｉ')]\n",
    "\n",
    "    tmp.index = pd.to_datetime(tmp[\"Time_Stamp_Original(JST)\"])\n",
    "    tmp = tmp.drop(\"Time_Stamp_Original(JST)\", axis=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        df1 = tmp.copy()\n",
    "    else:\n",
    "        df1 = pd.concat([df1, tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# インデックスを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_time(x):\n",
    "    if x.hour > 15:\n",
    "        return x + datetime.timedelta(days=1)\n",
    "    return x\n",
    "\n",
    "time = pd.to_datetime(df1.index.values)\n",
    "df1.index = df1.index.map(norm_time)\n",
    "df1.index = df1.index.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 株価を挿入する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>3265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>3295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>3380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>3455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11</th>\n",
       "      <td>3455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12</th>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-13</th>\n",
       "      <td>3535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-14</th>\n",
       "      <td>3550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-18</th>\n",
       "      <td>3510.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            adj_close\n",
       "2011-01-04     3265.0\n",
       "2011-01-05     3295.0\n",
       "2011-01-06     3380.0\n",
       "2011-01-07     3455.0\n",
       "2011-01-11     3455.0\n",
       "2011-01-12     3500.0\n",
       "2011-01-13     3535.0\n",
       "2011-01-14     3550.0\n",
       "2011-01-17     3500.0\n",
       "2011-01-18     3510.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 株価を取り出す\n",
    "df2 = pd.read_csv('./data/stock_price/7203.csv', index_col=0)\n",
    "df2.index = pd.to_datetime(df2['date'])\n",
    "df2.index = df2.index.date\n",
    "df2 = df2.drop(['date'], axis=1)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時系列をくっつける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shogo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.concat([df1,df2], axis=1, join_axes=[df1.index])\n",
    "df3['price'] = np.round(df2.pct_change().shift(-1) * 100, 3)\n",
    "df3['Keyword_Article'] = \\\n",
    "    df3.groupby(level=0).apply(lambda x: ':<pad>:'.join(list(x['Keyword_Article'])))\n",
    "df3 = df3.dropna()\n",
    "\n",
    "df3 = df3[~df3.duplicated(subset=['Keyword_Article'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Code(TSE)</th>\n",
       "      <th>Headline</th>\n",
       "      <th>News_Source</th>\n",
       "      <th>Company_Relevance</th>\n",
       "      <th>Keyword_Article</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇次世代車の研究開発　名大に国内最大拠点</td>\n",
       "      <td>日経</td>\n",
       "      <td>38</td>\n",
       "      <td>安全:環境:負荷:開発:目指す:開所式:研究拠点:効率:簡素化:次世代:電気自動車:電気:幅...</td>\n",
       "      <td>3265.0</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇12月の中国新車販売、トヨタが単月で過去最高</td>\n",
       "      <td>日経</td>\n",
       "      <td>100</td>\n",
       "      <td>北京:中国:１２月:新車販売台数:前年同月比:増:過去最高:制限:受け:全国:各地:乗用車:...</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>2.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;NQN&gt;◇トヨタ社長「今年は後半に晴れ間」　為替は１ドル＝90円を期待</td>\n",
       "      <td>ＮＱＮ</td>\n",
       "      <td>100</td>\n",
       "      <td>豊田:見通し:販売:エコカー補助金:安定的:伸び:株価:為替:水準:日経平均株価:最低:ライ...</td>\n",
       "      <td>3380.0</td>\n",
       "      <td>2.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇福岡県、自動車の技術者育成へ新組織　年内、中小向け</td>\n",
       "      <td>日経</td>\n",
       "      <td>37</td>\n",
       "      <td>自動車産業:強化:福岡:先端:設置:方針:技術:調査:ニーズ:カリキュラム:大学:受け:生産...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇トヨタ、米ミシガン州に安全研究センター新設</td>\n",
       "      <td>日経</td>\n",
       "      <td>100</td>\n",
       "      <td>先進:安全:子供:高齢者:事故:向上:目指す:米国:大規模:リコール:回収:問題:開催:豊田...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>1.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Company_Code(TSE)                              Headline  \\\n",
       "2011-01-04             7203.0              <日経>◇次世代車の研究開発　名大に国内最大拠点   \n",
       "2011-01-05             7203.0           <日経>◇12月の中国新車販売、トヨタが単月で過去最高   \n",
       "2011-01-06             7203.0  <NQN>◇トヨタ社長「今年は後半に晴れ間」　為替は１ドル＝90円を期待   \n",
       "2011-01-07             7203.0        <日経>◇福岡県、自動車の技術者育成へ新組織　年内、中小向け   \n",
       "2011-01-11             7203.0            <日経>◇トヨタ、米ミシガン州に安全研究センター新設   \n",
       "\n",
       "           News_Source Company_Relevance  \\\n",
       "2011-01-04          日経                38   \n",
       "2011-01-05          日経               100   \n",
       "2011-01-06         ＮＱＮ               100   \n",
       "2011-01-07          日経                37   \n",
       "2011-01-11          日経               100   \n",
       "\n",
       "                                              Keyword_Article  adj_close  \\\n",
       "2011-01-04  安全:環境:負荷:開発:目指す:開所式:研究拠点:効率:簡素化:次世代:電気自動車:電気:幅...     3265.0   \n",
       "2011-01-05  北京:中国:１２月:新車販売台数:前年同月比:増:過去最高:制限:受け:全国:各地:乗用車:...     3295.0   \n",
       "2011-01-06  豊田:見通し:販売:エコカー補助金:安定的:伸び:株価:為替:水準:日経平均株価:最低:ライ...     3380.0   \n",
       "2011-01-07  自動車産業:強化:福岡:先端:設置:方針:技術:調査:ニーズ:カリキュラム:大学:受け:生産...     3455.0   \n",
       "2011-01-11  先進:安全:子供:高齢者:事故:向上:目指す:米国:大規模:リコール:回収:問題:開催:豊田...     3455.0   \n",
       "\n",
       "            price  \n",
       "2011-01-04  0.919  \n",
       "2011-01-05  2.580  \n",
       "2011-01-06  2.219  \n",
       "2011-01-07  0.000  \n",
       "2011-01-11  1.302  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csvファイルに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date = 2015\n",
    "test_date = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df3[['Keyword_Article', 'price']].rename(\n",
    "                                      columns={'Keyword_Article': 'state', 'price': 'reward'}),\n",
    "                               df3[['Keyword_Article']].shift(-1).rename(\n",
    "                                      columns={'Keyword_Article': 'next_state'})], axis=1).dropna()\n",
    "df4 = df4[['state', 'next_state', 'reward']]\n",
    "\n",
    "date_year = df4.index.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[date_year <= train_date].to_csv(\n",
    "        './data/news/text_train.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[(train_date < date_year) & (date_year < test_date)].to_csv(\n",
    "        './data/news/text_val.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[test_date <= date_year].to_csv(\n",
    "        './data/news/text_test.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "def preprocessing_text(text):\n",
    "    # カンマ、ピリオド以外の記号をスペースに置換\n",
    "    for p in string.punctuation:\n",
    "        if (p == \".\") or (p == \",\") or (p == \":\") or (p == \"<\")or (p == \">\"):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    # ピリオドなどの前後にはスペースを入れておく\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = re.sub(r'[0-9 ０-９]', '0', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
    "def tokenizer_punctuation(text):\n",
    "    return text.strip().split(':')\n",
    "\n",
    "# 前処理と分かち書きをまとめた関数を定義\n",
    "def tokenizer_with_preprocessing(text):\n",
    "    text = preprocessing_text(text)\n",
    "    ret = tokenizer_punctuation(text)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "batch_size = 32\n",
    "\n",
    "# 読み込んだ内容に対して行う処理を定義\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, \n",
    "                            use_vocab=True,\n",
    "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, \n",
    "                            init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/news', train='text_train.tsv',\n",
    "    format='tsv',\n",
    "    fields=[('Text1', TEXT), ('Text2', TEXT), ('Label', LABEL)])\n",
    "train_ds = train_ds[0]\n",
    "\n",
    "# japanese_fasttext_vectors = Vectors(name='./data/news/cc.ja.300.vec')\n",
    "TEXT.build_vocab(train_ds, \n",
    "#                  vectors=japanese_fasttext_vectors,\n",
    "                 min_freq=10)\n",
    "TEXT.vocab.freqs\n",
    "\n",
    "train_dl = torchtext.data.Iterator(\n",
    "    train_ds, batch_size=batch_size, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   2,   52,  158,  ...,  150,    1,    3],\n",
      "        [   2,  480,  311,  ...,    1,    1,    1],\n",
      "        [   2,  335,  117,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,    4,  145,  ...,    1,    1,    1],\n",
      "        [   2,  118,  179,  ...,    1,    1,    1],\n",
      "        [   2,  862, 1234,  ...,    1,    1,    1]]), tensor([256, 214, 110, 256, 114, 221, 136,  18, 117, 244,  31, 256,  69,  34,\n",
      "         64,  75,  15, 256, 102,  15,  61,  91,  15,  55,  25,  49, 102, 244,\n",
      "        106,  91,  85, 118]))\n",
      "(tensor([[   2,  147,  196,  ...,    1,    1,    1],\n",
      "        [   2,  263,  111,  ...,  332,   40,    3],\n",
      "        [   2,   48,    4,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,    4,  207,  ...,    1,    1,    1],\n",
      "        [   2,    0, 1158,  ...,    1,    1,    1],\n",
      "        [   2,   78,  193,  ...,    1,    1,    1]]), tensor([166, 256, 108,  43,  26, 145, 244,  90, 108,  76,  81, 256,  73,  52,\n",
      "        256,  45,  58, 201, 239,   5,  17,  98, 118, 107,  60,  59,  80, 256,\n",
      "        202, 107, 106,  14]))\n",
      "tensor([ 1.3890,  0.3270,  0.1510,  0.6410, -0.7670,  0.3420,  0.9340, -0.8300,\n",
      "         1.1450,  1.7310, -1.7120,  0.7950,  1.6390,  0.0320, -2.1620,  0.0900,\n",
      "         2.9010, -1.1460,  0.5560, -2.0960,  0.8060,  1.7580, -2.0050, -2.8370,\n",
      "         0.7590,  2.1380, -0.2270,  0.0930,  0.0000,  1.9610,  2.8050,  0.6440])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "print(batch.Text1)\n",
    "print(batch.Text2)\n",
    "print(batch.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,    4,  148,  139,  114,    0, 1152,  388, 1358, 2038,  463, 1090,\n",
       "         600,  290, 1618,  477,  112,  201,    1,    4, 1367,  139,  114,  777,\n",
       "        1469,  133,   66,  148, 1057, 1257, 1874, 1453,  126,  693,  463,  556,\n",
       "           0,  178, 1160, 1205,  136,  388, 1008, 1356,  880,  468,  819,  181,\n",
       "          35,  858, 1825,  497,  505, 1345, 1717,    0,    0,   61,   56,   73,\n",
       "        1171,   25,   32, 1179,  175,  812, 1326,  824,  346,  112,  201,    1,\n",
       "           4, 1264,  456,  240,  259,   13, 1444,  271,    0,   16,  842,  112,\n",
       "         128,   93,  185,   32,   25,  811,    6,   24,   21, 1676,  211,   14,\n",
       "          41,  115,  341, 1101,   38,    7, 1298,  617,  394,    5,  393,  716,\n",
       "         622,  380,  276,   48,   66,  699,  122,    0,  359,  614,  453,  119,\n",
       "         114,  201,    1, 1427, 1526,    0,  182,  218,  123,   77, 1723,  710,\n",
       "           1,    4,   76,  163,  339, 1608,    5, 1190,    4,   29, 1104,   46,\n",
       "         207,   25,   41,   14,   60,  373,  174,    4, 1139,    4, 1957,  173,\n",
       "           1,   13,   76,  163,  668,  142, 1190,   14,    5,  127,  174,  247,\n",
       "          78,  453,  103,  109,    4,   24,   32,   46,    1,   43, 1102,  550,\n",
       "         270,  112,   21,  333,  806,    0,  135, 1552,  612,  388,    0, 2191,\n",
       "         128, 1730, 1879,  315, 1267, 1682,  213,  522,   36, 1444,    1,  172,\n",
       "          43,  142,  247,   41,  327,  145,  342,  339, 2094,   13,  273,  161,\n",
       "          62,  361,   88,   11,   76,  966,  243,  913,    8,  127,   69,  633,\n",
       "          68,    5,  207,  573,   60,   51,  132,  103,  359,  341, 1291,  968,\n",
       "         333,  849, 1798,  488,    6, 1752,  181,   31,  401,    4,   74,    4,\n",
       "         169,  651,  309,    3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.Text1[0][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab.freqs)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = 1\n",
    "GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, text_embedding_vector,vocab_size, embedding_dim, \n",
    "                    n_filters, filter_sizes, pad_idx,\n",
    "                    d_model=300, num_actions=2, quantiles=51):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,\n",
    "                      out_channels=n_filters,\n",
    "                      kernel_size=(fs, embedding_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, self.num_actions)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)    # [batch size, sent len, emb dim]\n",
    "\n",
    "        embedded = embedded.unsqueeze(1)   # [batch size, 1, sent len, emb dim]\n",
    "\n",
    "        h = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]   # [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "\n",
    "        h = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in h]\n",
    "\n",
    "        h = torch.cat(h, dim=1)\n",
    "\n",
    "        h = self.fc(h)\n",
    "\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DQN(TEXT.vocab.vectors, VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS,\n",
    "                        FILTER_SIZES, PAD_IDX)\n",
    "\n",
    "target_model = DQN(TEXT.vocab.vectors, VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS,\n",
    "                        FILTER_SIZES, PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "target_model = tarmax_length = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# 読み込んだ内容に対して行う処理を定義\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, \n",
    "                            use_vocab=True,\n",
    "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, \n",
    "                            init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False, dtype=torch.float)get_model.to(device)\n",
    "\n",
    "target_model.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法\n",
    "learning_rate = 2.5e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(scores, y):    \n",
    "    correct = (scores == y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()\n",
    "    return acc\n",
    "\n",
    "def huber(x):\n",
    "        cond = (x.abs() < 1.0).float().detach()\n",
    "        return 0.5 * x.pow(2) * cond + (x.abs() - 0.5) * (1.0 - cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_q\n",
    "states = batch.Text1[0].to(device)\n",
    "next_states = batch.Text2[0].to(device)\n",
    "rewards = batch.Label.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    actions = torch.argmax(model(states), 1)\n",
    "    actions = torch.where(torch.randn(len(states)).to(device) >= 0, \n",
    "                          actions, \n",
    "                          (actions + 1) % 2)\n",
    "\n",
    "    selected_actions = actions.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# epi_rewards.append((selected_actions * rewards.detach().cpu().numpy()).sum())\n",
    "# neutrals.append(len(selected_actions[selected_actions == 0]))\n",
    "# buys.append(len(selected_actions[selected_actions == 1]))\n",
    "\n",
    "actions = actions.view(-1, 1)\n",
    "curr_q = model(states).gather(1, actions).squeeze(dim=1)\n",
    "\n",
    "# target_q\n",
    "with torch.no_grad():\n",
    "\n",
    "    next_actions = torch.argmax(model(next_states), 1).view(-1, 1)\n",
    "\n",
    "    next_q = target_model(next_states).gather(1, next_actions)\n",
    "    target_q = rewards.view(-1, 1) + (GAMMA * next_q)\n",
    "\n",
    "loss = torch.mean((target_q - curr_q)**2)\n",
    "\n",
    "# Optimize the model\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "for param in model.parameters():\n",
    "    param.grad.data.clamp_(-1, 1)\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----start----\n",
      "--------------------\n",
      "epoch: 0\n",
      "loss: 2.0674140453338623\n",
      "epi_reward: 53.54200131818652\n",
      "neutrals: 490   buys: 529\n",
      "--------------------\n",
      "epoch: 1\n",
      "loss: 4.894399166107178\n",
      "epi_reward: 27.3910000808537\n",
      "neutrals: 511   buys: 508\n",
      "--------------------\n",
      "epoch: 2\n",
      "loss: 1.9778602123260498\n",
      "epi_reward: 36.14900116622448\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 3\n",
      "loss: 5.133679389953613\n",
      "epi_reward: 43.3600003644824\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 4\n",
      "loss: 1.8334323167800903\n",
      "epi_reward: 23.222000082954764\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 5\n",
      "loss: 3.417635440826416\n",
      "epi_reward: 39.153000354766846\n",
      "neutrals: 515   buys: 504\n",
      "--------------------\n",
      "epoch: 6\n",
      "loss: 5.337892055511475\n",
      "epi_reward: 38.70099985413253\n",
      "neutrals: 526   buys: 493\n",
      "--------------------\n",
      "epoch: 7\n",
      "loss: 4.28289794921875\n",
      "epi_reward: 57.407000264152884\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 8\n",
      "loss: 2.911771774291992\n",
      "epi_reward: 50.74299978837371\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 9\n",
      "loss: 3.373694658279419\n",
      "epi_reward: 41.12200023047626\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 10\n",
      "loss: 1.8009858131408691\n",
      "epi_reward: 11.455000892281532\n",
      "neutrals: 529   buys: 490\n",
      "--------------------\n",
      "epoch: 11\n",
      "loss: 2.858908176422119\n",
      "epi_reward: 32.64300040528178\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 12\n",
      "loss: 1.9206902980804443\n",
      "epi_reward: 51.21700074151158\n",
      "neutrals: 543   buys: 476\n",
      "--------------------\n",
      "epoch: 13\n",
      "loss: 3.212898015975952\n",
      "epi_reward: 35.246000634506345\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 14\n",
      "loss: 2.3164260387420654\n",
      "epi_reward: 33.86700012721121\n",
      "neutrals: 523   buys: 496\n",
      "--------------------\n",
      "epoch: 15\n",
      "loss: 1.9681203365325928\n",
      "epi_reward: 32.63900041393936\n",
      "neutrals: 517   buys: 502\n",
      "--------------------\n",
      "epoch: 16\n",
      "loss: 1.7254921197891235\n",
      "epi_reward: 47.23300041817129\n",
      "neutrals: 522   buys: 497\n",
      "--------------------\n",
      "epoch: 17\n",
      "loss: 1.7550556659698486\n",
      "epi_reward: 36.85700132139027\n",
      "neutrals: 498   buys: 521\n",
      "--------------------\n",
      "epoch: 18\n",
      "loss: 2.7531185150146484\n",
      "epi_reward: 25.206000491976738\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 19\n",
      "loss: 1.980494499206543\n",
      "epi_reward: 50.63700016774237\n",
      "neutrals: 518   buys: 501\n",
      "--------------------\n",
      "epoch: 20\n",
      "loss: 1.1924453973770142\n",
      "epi_reward: 40.07200001180172\n",
      "neutrals: 489   buys: 530\n",
      "--------------------\n",
      "epoch: 21\n",
      "loss: 2.429414987564087\n",
      "epi_reward: 40.65800107643008\n",
      "neutrals: 489   buys: 530\n",
      "--------------------\n",
      "epoch: 22\n",
      "loss: 3.7750349044799805\n",
      "epi_reward: 84.82100026682019\n",
      "neutrals: 536   buys: 483\n",
      "--------------------\n",
      "epoch: 23\n",
      "loss: 3.449371337890625\n",
      "epi_reward: 23.940001184120774\n",
      "neutrals: 522   buys: 497\n",
      "--------------------\n",
      "epoch: 24\n",
      "loss: 3.745816469192505\n",
      "epi_reward: 69.2509998511523\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 25\n",
      "loss: 2.5856149196624756\n",
      "epi_reward: 29.870999226346612\n",
      "neutrals: 484   buys: 535\n",
      "--------------------\n",
      "epoch: 26\n",
      "loss: 2.3256843090057373\n",
      "epi_reward: 43.42800026014447\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 27\n",
      "loss: 2.3621938228607178\n",
      "epi_reward: 52.76900038123131\n",
      "neutrals: 509   buys: 510\n",
      "--------------------\n",
      "epoch: 28\n",
      "loss: 5.005654811859131\n",
      "epi_reward: 41.20200005546212\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 29\n",
      "loss: 3.062096118927002\n",
      "epi_reward: 17.37000137194991\n",
      "neutrals: 514   buys: 505\n",
      "--------------------\n",
      "epoch: 30\n",
      "loss: 2.9562268257141113\n",
      "epi_reward: 24.87100082822144\n",
      "neutrals: 521   buys: 498\n",
      "--------------------\n",
      "epoch: 31\n",
      "loss: 2.831570863723755\n",
      "epi_reward: 42.06700038909912\n",
      "neutrals: 479   buys: 540\n",
      "--------------------\n",
      "epoch: 32\n",
      "loss: 3.649240016937256\n",
      "epi_reward: 51.5139998216182\n",
      "neutrals: 472   buys: 547\n",
      "--------------------\n",
      "epoch: 33\n",
      "loss: 2.045229911804199\n",
      "epi_reward: 15.686000583693385\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 34\n",
      "loss: 2.2777721881866455\n",
      "epi_reward: 87.6159995906055\n",
      "neutrals: 516   buys: 503\n",
      "--------------------\n",
      "epoch: 35\n",
      "loss: 2.4973056316375732\n",
      "epi_reward: 38.16700157336891\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 36\n",
      "loss: 2.8507308959960938\n",
      "epi_reward: 34.482000820338726\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 37\n",
      "loss: 6.137270450592041\n",
      "epi_reward: 86.25700150616467\n",
      "neutrals: 494   buys: 525\n",
      "--------------------\n",
      "epoch: 38\n",
      "loss: 4.164160251617432\n",
      "epi_reward: 33.740000484511256\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 39\n",
      "loss: 3.2019777297973633\n",
      "epi_reward: 39.45100093819201\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 40\n",
      "loss: 1.9446698427200317\n",
      "epi_reward: 40.36400063894689\n",
      "neutrals: 488   buys: 531\n",
      "--------------------\n",
      "epoch: 41\n",
      "loss: 2.69362735748291\n",
      "epi_reward: 22.76499904319644\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 42\n",
      "loss: 3.70737361907959\n",
      "epi_reward: 59.099000396206975\n",
      "neutrals: 482   buys: 537\n",
      "--------------------\n",
      "epoch: 43\n",
      "loss: 2.6189768314361572\n",
      "epi_reward: 38.49699990451336\n",
      "neutrals: 518   buys: 501\n",
      "--------------------\n",
      "epoch: 44\n",
      "loss: 3.0785629749298096\n",
      "epi_reward: 35.895000115036964\n",
      "neutrals: 532   buys: 487\n",
      "--------------------\n",
      "epoch: 45\n",
      "loss: 1.2557237148284912\n",
      "epi_reward: -1.1630004569888115\n",
      "neutrals: 519   buys: 500\n",
      "--------------------\n",
      "epoch: 46\n",
      "loss: 1.3867299556732178\n",
      "epi_reward: 12.600001703947783\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 47\n",
      "loss: 1.8799233436584473\n",
      "epi_reward: 26.468000965192914\n",
      "neutrals: 532   buys: 487\n",
      "--------------------\n",
      "epoch: 48\n",
      "loss: 2.0731115341186523\n",
      "epi_reward: 30.781001454219222\n",
      "neutrals: 495   buys: 524\n",
      "--------------------\n",
      "epoch: 49\n",
      "loss: 3.3631720542907715\n",
      "epi_reward: 64.26100128889084\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 50\n",
      "loss: 2.848215103149414\n",
      "epi_reward: 40.92800041846931\n",
      "neutrals: 508   buys: 511\n",
      "--------------------\n",
      "epoch: 51\n",
      "loss: 2.1839067935943604\n",
      "epi_reward: 41.589000230655074\n",
      "neutrals: 531   buys: 488\n",
      "--------------------\n",
      "epoch: 52\n",
      "loss: 3.7283709049224854\n",
      "epi_reward: 69.41600144654512\n",
      "neutrals: 476   buys: 543\n",
      "--------------------\n",
      "epoch: 53\n",
      "loss: 3.823270320892334\n",
      "epi_reward: 100.8210005685687\n",
      "neutrals: 490   buys: 529\n",
      "--------------------\n",
      "epoch: 54\n",
      "loss: 1.7556952238082886\n",
      "epi_reward: 67.59199987724423\n",
      "neutrals: 495   buys: 524\n",
      "--------------------\n",
      "epoch: 55\n",
      "loss: 5.388742923736572\n",
      "epi_reward: 29.213999938219786\n",
      "neutrals: 510   buys: 509\n",
      "--------------------\n",
      "epoch: 56\n",
      "loss: 4.262820720672607\n",
      "epi_reward: 58.04599983431399\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 57\n",
      "loss: 4.2258124351501465\n",
      "epi_reward: 77.26100031472743\n",
      "neutrals: 523   buys: 496\n",
      "--------------------\n",
      "epoch: 58\n",
      "loss: 2.9336328506469727\n",
      "epi_reward: 69.20799996331334\n",
      "neutrals: 489   buys: 530\n",
      "--------------------\n",
      "epoch: 59\n",
      "loss: 5.904265403747559\n",
      "epi_reward: 61.216999700292945\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 60\n",
      "loss: 2.7018892765045166\n",
      "epi_reward: 69.73799962922931\n",
      "neutrals: 509   buys: 510\n",
      "--------------------\n",
      "epoch: 61\n",
      "loss: 1.8812273740768433\n",
      "epi_reward: 9.560000833123922\n",
      "neutrals: 524   buys: 495\n",
      "--------------------\n",
      "epoch: 62\n",
      "loss: 1.5885987281799316\n",
      "epi_reward: -0.7719990946352482\n",
      "neutrals: 488   buys: 531\n",
      "--------------------\n",
      "epoch: 63\n",
      "loss: 2.1846468448638916\n",
      "epi_reward: -6.930000165477395\n",
      "neutrals: 533   buys: 486\n",
      "--------------------\n",
      "epoch: 64\n",
      "loss: 3.294485092163086\n",
      "epi_reward: 18.333999902009964\n",
      "neutrals: 538   buys: 481\n",
      "--------------------\n",
      "epoch: 65\n",
      "loss: 3.296367883682251\n",
      "epi_reward: 27.677999828010798\n",
      "neutrals: 529   buys: 490\n",
      "--------------------\n",
      "epoch: 66\n",
      "loss: 2.983444929122925\n",
      "epi_reward: 106.58500066027045\n",
      "neutrals: 519   buys: 500\n",
      "--------------------\n",
      "epoch: 67\n",
      "loss: 4.629764080047607\n",
      "epi_reward: 27.63300008326769\n",
      "neutrals: 544   buys: 475\n",
      "--------------------\n",
      "epoch: 68\n",
      "loss: 1.6832183599472046\n",
      "epi_reward: 72.28200067952275\n",
      "neutrals: 508   buys: 511\n",
      "--------------------\n",
      "epoch: 69\n",
      "loss: 3.5287482738494873\n",
      "epi_reward: 18.154000036418438\n",
      "neutrals: 511   buys: 508\n",
      "--------------------\n",
      "epoch: 70\n",
      "loss: 1.8868614435195923\n",
      "epi_reward: 42.87800069153309\n",
      "neutrals: 518   buys: 501\n",
      "--------------------\n",
      "epoch: 71\n",
      "loss: 6.508549213409424\n",
      "epi_reward: 16.806000066921115\n",
      "neutrals: 495   buys: 524\n",
      "--------------------\n",
      "epoch: 72\n",
      "loss: 3.926997184753418\n",
      "epi_reward: 45.10000057145953\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 73\n",
      "loss: 2.6199941635131836\n",
      "epi_reward: 44.27200036868453\n",
      "neutrals: 509   buys: 510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch: 74\n",
      "loss: 2.2340328693389893\n",
      "epi_reward: 51.07299919426441\n",
      "neutrals: 495   buys: 524\n",
      "--------------------\n",
      "epoch: 75\n",
      "loss: 3.8179001808166504\n",
      "epi_reward: 75.05400026403368\n",
      "neutrals: 507   buys: 512\n",
      "--------------------\n",
      "epoch: 76\n",
      "loss: 5.913333892822266\n",
      "epi_reward: 43.88199939019978\n",
      "neutrals: 526   buys: 493\n",
      "--------------------\n",
      "epoch: 77\n",
      "loss: 3.699885845184326\n",
      "epi_reward: 43.87299994751811\n",
      "neutrals: 477   buys: 542\n",
      "--------------------\n",
      "epoch: 78\n",
      "loss: 2.6545627117156982\n",
      "epi_reward: 49.22800051793456\n",
      "neutrals: 527   buys: 492\n",
      "--------------------\n",
      "epoch: 79\n",
      "loss: 2.3813862800598145\n",
      "epi_reward: 55.07000015862286\n",
      "neutrals: 518   buys: 501\n",
      "--------------------\n",
      "epoch: 80\n",
      "loss: 1.7790753841400146\n",
      "epi_reward: 55.151000302284956\n",
      "neutrals: 505   buys: 514\n",
      "--------------------\n",
      "epoch: 81\n",
      "loss: 1.8370882272720337\n",
      "epi_reward: 10.405999476090074\n",
      "neutrals: 541   buys: 478\n",
      "--------------------\n",
      "epoch: 82\n",
      "loss: 4.761754035949707\n",
      "epi_reward: 16.193000299856067\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 83\n",
      "loss: 1.6005544662475586\n",
      "epi_reward: 45.068000093102455\n",
      "neutrals: 526   buys: 493\n",
      "--------------------\n",
      "epoch: 84\n",
      "loss: 2.23710298538208\n",
      "epi_reward: 43.621000315994024\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 85\n",
      "loss: 1.7523930072784424\n",
      "epi_reward: 47.63600021786988\n",
      "neutrals: 535   buys: 484\n",
      "--------------------\n",
      "epoch: 86\n",
      "loss: 4.095355033874512\n",
      "epi_reward: 62.31599887274206\n",
      "neutrals: 492   buys: 527\n",
      "--------------------\n",
      "epoch: 87\n",
      "loss: 4.6912055015563965\n",
      "epi_reward: 57.232999758794904\n",
      "neutrals: 521   buys: 498\n",
      "--------------------\n",
      "epoch: 88\n",
      "loss: 2.240417957305908\n",
      "epi_reward: 26.357000835239887\n",
      "neutrals: 490   buys: 529\n",
      "--------------------\n",
      "epoch: 89\n",
      "loss: 2.9199514389038086\n",
      "epi_reward: 64.54800092615187\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 90\n",
      "loss: 3.218989849090576\n",
      "epi_reward: 1.8140007182955742\n",
      "neutrals: 521   buys: 498\n",
      "--------------------\n",
      "epoch: 91\n",
      "loss: 2.0870707035064697\n",
      "epi_reward: 33.63599934615195\n",
      "neutrals: 533   buys: 486\n",
      "--------------------\n",
      "epoch: 92\n",
      "loss: 2.8339250087738037\n",
      "epi_reward: 39.399000184610486\n",
      "neutrals: 490   buys: 529\n",
      "--------------------\n",
      "epoch: 93\n",
      "loss: 2.443455219268799\n",
      "epi_reward: -1.5739987511187792\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 94\n",
      "loss: 1.5488567352294922\n",
      "epi_reward: 91.62300064601004\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 95\n",
      "loss: 2.2593069076538086\n",
      "epi_reward: 59.031000481918454\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 96\n",
      "loss: 1.5776301622390747\n",
      "epi_reward: 10.394000297412276\n",
      "neutrals: 507   buys: 512\n",
      "--------------------\n",
      "epoch: 97\n",
      "loss: 3.5719246864318848\n",
      "epi_reward: 31.60000185482204\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 98\n",
      "loss: 2.0403316020965576\n",
      "epi_reward: 39.57400176115334\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 99\n",
      "loss: 3.346658229827881\n",
      "epi_reward: 54.12900027632713\n",
      "neutrals: 482   buys: 537\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "TARGET_UPDATE_FREQ = 10\n",
    "# dataloaders_dict = {'train': train_dl, 'val':val_dl}\n",
    "dataloaders_dict = {'train': train_dl}\n",
    "\n",
    "print('----start----')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epi_rewards = []\n",
    "    neutrals = []\n",
    "    buys = []\n",
    "    \n",
    "    # update target_model\n",
    "    if epoch % TARGET_UPDATE_FREQ == 0:\n",
    "        target_model.load_state_dict(model.state_dict())\n",
    "    \n",
    "    for batch in (dataloaders_dict['train']):      \n",
    "        # curr_q\n",
    "        states = batch.Text1[0].to(device)\n",
    "        next_states = batch.Text2[0].to(device)\n",
    "        rewards = batch.Label.to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            actions = torch.argmax(model(states), 1)\n",
    "            actions = torch.where(torch.randn(len(states)).to(device) >= 0, \n",
    "                                  actions, \n",
    "                                  (actions + 1) % 2)\n",
    "\n",
    "            selected_actions = actions.detach().cpu().numpy()\n",
    "            actions = actions.view(-1, 1)\n",
    "\n",
    "        epi_rewards.append((selected_actions * rewards.detach().cpu().numpy()).sum())\n",
    "        neutrals.append(len(selected_actions[selected_actions == 0]))\n",
    "        buys.append(len(selected_actions[selected_actions == 1]))\n",
    "        \n",
    "        curr_q = model(states).gather(1, actions).squeeze(dim=1)\n",
    "\n",
    "        # target_q\n",
    "        with torch.no_grad():\n",
    "\n",
    "            next_actions = torch.argmax(model(next_states), 1).view(-1, 1)\n",
    "\n",
    "            next_q = target_model(next_states).gather(1, next_actions)\n",
    "            target_q = rewards.view(-1, 1) + (GAMMA * next_q)\n",
    "\n",
    "        loss = torch.mean((target_q - curr_q)**2)\n",
    "\n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('--------------------')\n",
    "    print('epoch:', epoch)\n",
    "    print('loss:', loss.item())\n",
    "    print('epi_reward:', sum(epi_rewards))\n",
    "    print('neutrals:', sum(neutrals), '  buys:', sum(buys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))\n",
    "states = batch.Text1[0].to(device)\n",
    "next_states = batch.Text2[0].to(device)\n",
    "rewards = batch.Label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = states[4]\n",
    "actions = torch.argmax(model(states), 1)\n",
    "# dist_action = actions[0].cpu().detach().numpy()\n",
    "# # sns.distplot(dist_action[0], bins=51, color='red')\n",
    "# sns.distplot(dist_action[1], bins=10, color='blue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
