{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext import data, datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import QRDQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(range(2011, 2019)):\n",
    "    tmp = pd.read_csv('./data/news/' + str(date) + '.csv', encoding='cp932')\n",
    "    tmp = tmp[tmp['Company_IDs(TSE)'] == '7203']\n",
    "    tmp = tmp[['Time_Stamp_Original(JST)', \n",
    "                        'Company_Code(TSE)', \n",
    "                        'Headline', \n",
    "                        'News_Source',\n",
    "                        'Company_Relevance', \n",
    "                        'Keyword_Article']]\n",
    "\n",
    "    # 欠損除去\n",
    "    tmp = tmp[~tmp[\"Keyword_Article\"].isnull()]\n",
    "\n",
    "    # タグ除去\n",
    "    tmp = tmp[(tmp['News_Source'] == '日経') | \n",
    "                        (tmp['News_Source'] == 'ＮＱＮ') |\n",
    "                        (tmp['News_Source'] == 'ＱＵＩＣＫ') | \n",
    "                        (tmp['News_Source'] == 'Ｒ＆Ｉ')]\n",
    "\n",
    "    tmp.index = pd.to_datetime(tmp[\"Time_Stamp_Original(JST)\"])\n",
    "    tmp = tmp.drop(\"Time_Stamp_Original(JST)\", axis=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        df1 = tmp.copy()\n",
    "    else:\n",
    "        df1 = pd.concat([df1, tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# インデックスを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_time(x):\n",
    "    if x.hour > 15:\n",
    "        return x + datetime.timedelta(days=1)\n",
    "    return x\n",
    "\n",
    "time = pd.to_datetime(df1.index.values)\n",
    "df1.index = df1.index.map(norm_time)\n",
    "df1.index = df1.index.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 株価を挿入する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>3265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>3295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>3380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>3455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11</th>\n",
       "      <td>3455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12</th>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-13</th>\n",
       "      <td>3535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-14</th>\n",
       "      <td>3550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-18</th>\n",
       "      <td>3510.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            adj_close\n",
       "2011-01-04     3265.0\n",
       "2011-01-05     3295.0\n",
       "2011-01-06     3380.0\n",
       "2011-01-07     3455.0\n",
       "2011-01-11     3455.0\n",
       "2011-01-12     3500.0\n",
       "2011-01-13     3535.0\n",
       "2011-01-14     3550.0\n",
       "2011-01-17     3500.0\n",
       "2011-01-18     3510.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 株価を取り出す\n",
    "df2 = pd.read_csv('./data/stock_price/7203.csv', index_col=0)\n",
    "df2.index = pd.to_datetime(df2['date'])\n",
    "df2.index = df2.index.date\n",
    "df2 = df2.drop(['date'], axis=1)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時系列をくっつける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shogo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.concat([df1,df2], axis=1, join_axes=[df1.index])\n",
    "df3['price'] = np.round(df2.pct_change().shift(-1) * 100, 3)\n",
    "df3['Keyword_Article'] = \\\n",
    "    df3.groupby(level=0).apply(lambda x: ':<pad>:'.join(list(x['Keyword_Article'])))\n",
    "df3 = df3.dropna()\n",
    "\n",
    "df3 = df3[~df3.duplicated(subset=['Keyword_Article'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Code(TSE)</th>\n",
       "      <th>Headline</th>\n",
       "      <th>News_Source</th>\n",
       "      <th>Company_Relevance</th>\n",
       "      <th>Keyword_Article</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇次世代車の研究開発　名大に国内最大拠点</td>\n",
       "      <td>日経</td>\n",
       "      <td>38</td>\n",
       "      <td>安全:環境:負荷:開発:目指す:開所式:研究拠点:効率:簡素化:次世代:電気自動車:電気:幅...</td>\n",
       "      <td>3265.0</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇12月の中国新車販売、トヨタが単月で過去最高</td>\n",
       "      <td>日経</td>\n",
       "      <td>100</td>\n",
       "      <td>北京:中国:１２月:新車販売台数:前年同月比:増:過去最高:制限:受け:全国:各地:乗用車:...</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>2.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;NQN&gt;◇トヨタ社長「今年は後半に晴れ間」　為替は１ドル＝90円を期待</td>\n",
       "      <td>ＮＱＮ</td>\n",
       "      <td>100</td>\n",
       "      <td>豊田:見通し:販売:エコカー補助金:安定的:伸び:株価:為替:水準:日経平均株価:最低:ライ...</td>\n",
       "      <td>3380.0</td>\n",
       "      <td>2.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇福岡県、自動車の技術者育成へ新組織　年内、中小向け</td>\n",
       "      <td>日経</td>\n",
       "      <td>37</td>\n",
       "      <td>自動車産業:強化:福岡:先端:設置:方針:技術:調査:ニーズ:カリキュラム:大学:受け:生産...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇トヨタ、米ミシガン州に安全研究センター新設</td>\n",
       "      <td>日経</td>\n",
       "      <td>100</td>\n",
       "      <td>先進:安全:子供:高齢者:事故:向上:目指す:米国:大規模:リコール:回収:問題:開催:豊田...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>1.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Company_Code(TSE)                              Headline  \\\n",
       "2011-01-04             7203.0              <日経>◇次世代車の研究開発　名大に国内最大拠点   \n",
       "2011-01-05             7203.0           <日経>◇12月の中国新車販売、トヨタが単月で過去最高   \n",
       "2011-01-06             7203.0  <NQN>◇トヨタ社長「今年は後半に晴れ間」　為替は１ドル＝90円を期待   \n",
       "2011-01-07             7203.0        <日経>◇福岡県、自動車の技術者育成へ新組織　年内、中小向け   \n",
       "2011-01-11             7203.0            <日経>◇トヨタ、米ミシガン州に安全研究センター新設   \n",
       "\n",
       "           News_Source Company_Relevance  \\\n",
       "2011-01-04          日経                38   \n",
       "2011-01-05          日経               100   \n",
       "2011-01-06         ＮＱＮ               100   \n",
       "2011-01-07          日経                37   \n",
       "2011-01-11          日経               100   \n",
       "\n",
       "                                              Keyword_Article  adj_close  \\\n",
       "2011-01-04  安全:環境:負荷:開発:目指す:開所式:研究拠点:効率:簡素化:次世代:電気自動車:電気:幅...     3265.0   \n",
       "2011-01-05  北京:中国:１２月:新車販売台数:前年同月比:増:過去最高:制限:受け:全国:各地:乗用車:...     3295.0   \n",
       "2011-01-06  豊田:見通し:販売:エコカー補助金:安定的:伸び:株価:為替:水準:日経平均株価:最低:ライ...     3380.0   \n",
       "2011-01-07  自動車産業:強化:福岡:先端:設置:方針:技術:調査:ニーズ:カリキュラム:大学:受け:生産...     3455.0   \n",
       "2011-01-11  先進:安全:子供:高齢者:事故:向上:目指す:米国:大規模:リコール:回収:問題:開催:豊田...     3455.0   \n",
       "\n",
       "            price  \n",
       "2011-01-04  0.919  \n",
       "2011-01-05  2.580  \n",
       "2011-01-06  2.219  \n",
       "2011-01-07  0.000  \n",
       "2011-01-11  1.302  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csvファイルに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date = 2015\n",
    "test_date = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df3[['Keyword_Article', 'price']].rename(\n",
    "                                      columns={'Keyword_Article': 'state', 'price': 'reward'}),\n",
    "                               df3[['Keyword_Article']].shift(-1).rename(\n",
    "                                      columns={'Keyword_Article': 'next_state'})], axis=1).dropna()\n",
    "df4 = df4[['state', 'next_state', 'reward']]\n",
    "\n",
    "date_year = df4.index.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[date_year <= train_date].to_csv(\n",
    "        './data/news/text_train.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[(train_date < date_year) & (date_year < test_date)].to_csv(\n",
    "        './data/news/text_val.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[test_date <= date_year].to_csv(\n",
    "        './data/news/text_test.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "def preprocessing_text(text):\n",
    "    # カンマ、ピリオド以外の記号をスペースに置換\n",
    "    for p in string.punctuation:\n",
    "        if (p == \".\") or (p == \",\") or (p == \":\") or (p == \"<\")or (p == \">\"):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    # ピリオドなどの前後にはスペースを入れておく\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = re.sub(r'[0-9 ０-９]', '0', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
    "def tokenizer_punctuation(text):\n",
    "    return text.strip().split(':')\n",
    "\n",
    "# 前処理と分かち書きをまとめた関数を定義\n",
    "def tokenizer_with_preprocessing(text):\n",
    "    text = preprocessing_text(text)\n",
    "    ret = tokenizer_punctuation(text)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# 読み込んだ内容に対して行う処理を定義\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, \n",
    "                            use_vocab=True,\n",
    "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, \n",
    "                            init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/news', train='text_train.tsv',\n",
    "    format='tsv',\n",
    "    fields=[('Text1', TEXT), ('Text2', TEXT), ('Label', LABEL)])\n",
    "train_ds = train_ds[0]\n",
    "\n",
    "# japanese_fasttext_vectors = Vectors(name='./data/news/cc.ja.300.vec')\n",
    "TEXT.build_vocab(train_ds, \n",
    "#                  vectors=japanese_fasttext_vectors,\n",
    "                 min_freq=10)\n",
    "TEXT.vocab.freqs\n",
    "\n",
    "train_dl = torchtext.data.Iterator(\n",
    "    train_ds, batch_size=batch_size, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   2,   35,   55,  ...,    1,    1,    1],\n",
      "        [   2,   92,   40,  ...,    1,    1,    1],\n",
      "        [   2,   28,   26,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,    4,    0,  ...,    1,    1,    1],\n",
      "        [   2, 1791, 1362,  ...,    1,    1,    1],\n",
      "        [   2,  172,  617,  ...,    1,    1,    1]]), tensor([ 44, 907,  35, 161,  74,  18,  90,  89, 108, 126,  18, 111, 207,  35,\n",
      "        125, 279, 118,  11,  60,  58,  63, 144,  38,  55, 111,  67, 194, 151,\n",
      "        326,  18,  20,  91]))\n",
      "(tensor([[  2,  10,   4,  ...,   1,   1,   1],\n",
      "        [  2,  11, 169,  ...,   1,   1,   1],\n",
      "        [  2, 232, 867,  ...,   1,   1,   1],\n",
      "        ...,\n",
      "        [  2,  10,   4,  ...,   1,   1,   1],\n",
      "        [  2,  33,  96,  ...,   1,   1,   1],\n",
      "        [  2,   4, 207,  ...,   1,   1,   1]]), tensor([ 29,  61, 199, 272, 125,  27,  72,  44,  52,  27, 173,  64,  14,  32,\n",
      "        191, 183,  28,  49,  18,  64, 377, 108,  24, 107,  49,  92, 453,  40,\n",
      "        129, 125, 121, 171]))\n",
      "tensor([ 1.0100, -1.1160,  0.1960, -0.7210,  0.5950,  0.7690, -0.9020, -1.9800,\n",
      "        -0.7510, -1.1250, -0.1280, -0.6920, -0.5000, -0.5480, -0.0120, -0.8460,\n",
      "        -0.4470,  0.4260, -0.8960,  2.9000,  1.0520, -2.2580, -1.2260, -2.8370,\n",
      "        -0.1320, -0.3120, -1.7500, -1.3490,  1.5580,  0.2140, -4.6080, -0.9170])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "print(batch.Text1)\n",
    "print(batch.Text2)\n",
    "print(batch.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,   92,   40,  272,   28,  130, 1381,    7,  539,  279,   16,   23,\n",
       "        1421, 1534,  350, 1380,    4,  251,   94,   11,  138,  320,  256,   22,\n",
       "         238,  515, 1652,   15,   42,   12, 1285,   89,  108,   39,  176,  514,\n",
       "         512,  993,   44,   37,  620,   19,    0,  683,  547,    0,  146,  392,\n",
       "           1,   33,    6,  742,   27,  460,   16,  338,   35,  154,   60,   51,\n",
       "          13,  203,  161,   62, 2172,  169,   45, 1591,   86,    1,  183,  169,\n",
       "         116,    8,  320,  146,  332,   90,  104,   28,   12,   36,  238,    4,\n",
       "          89,  437,  687,  155,   22,  303,  222,  804,  152,   20,   16,    1,\n",
       "          33,   71,  241,  239,  156,  111,  891,  354,  499,    0,  173, 1048,\n",
       "         694,    1,  158,  116,    8,  169,   11,  416, 1323,   27,   94,   31,\n",
       "         186,   79,   41,    6,   51,  390,  138,  621,    9,   40,   52,  391,\n",
       "         203,  354,  482,  177,  180,   96,  171,   73,   72,  154, 1066,  160,\n",
       "         218, 1213,  134,  129,  253, 1001,   20,  374,  107,  109,    0,  362,\n",
       "           1,   33,  113,  225,   57,  755,    0,  931,   71, 2178,   72,    6,\n",
       "         365,  218,  610,    9,  375,  109,   29,  398,   63,   77,   70,  171,\n",
       "         248,    1,   33,    4,  235,  644,   75,  125, 1594,  248,   71, 1193,\n",
       "        1066,    9, 1347,  324,    6,   51,  161,   11,    1,   33,  145,   81,\n",
       "          74,    8,  370,  242,   50,  138,  125,  621,  511,    1,  171,   33,\n",
       "         158,  152,   74,    8,  169,  319, 1323,   27,   77,   11,  248,  218,\n",
       "         610,  375,  109,   29,  398,    6,  972,    4,  235,  644,  363,    9,\n",
       "        1177,   84, 1193,  425,  547,    5,  660, 1104,  601,  569,  499,   81,\n",
       "        1347,   60,  161,   48,  113, 1228,  384, 2108,  301,  253, 1001,   20,\n",
       "          63,    0,  107,  416,   69,   65,   34,    1,  383,   96,   74,   30,\n",
       "          48,   60,    5,  145,    6,   35,   55,  384,  282,  816,  164,   41,\n",
       "          51,   12,   11,  398,   36,    1,   52,   31,  171, 1405,  116,    8,\n",
       "          11,   79,   19,   40,  668, 1235,   27,  396,  511,   69,   63,  225,\n",
       "         408,  228,  531,   33,   96,   74,  152,  587,  589,  203,   51,  273,\n",
       "          78,  154,   41,   97,  196,  180,   80,  186,   50,   60,  782,  535,\n",
       "           5,  214,  122,  354,   73,  198, 1963,   24, 1951,   61,    0,  133,\n",
       "         153,   84,  641,   32,  660,  370,  107,  274,  502,  277,   94, 1515,\n",
       "         213,   49,  243,  143,  127,   72,    6,  441,  218,  610,  707,   65,\n",
       "          22,  168, 1229,   71,  443,  239,  156,    1,  145,    4,   18,   56,\n",
       "         403,  742,   27, 1523,   16,  247,   24,    4,  235,  219,   35,   55,\n",
       "        1566,   51,  125,    4,  109,  416,  644,   50, 1232,   41,  649, 1331,\n",
       "         169,   23,    5,  286,  365,  248,  252,   17,   29,   81,   32,    4,\n",
       "          34,   61,  171,   33,    6,   36,  363, 1347,  180,  151,    9, 1594,\n",
       "         129, 1133,  402,  930,   38,  660, 1104,  601,    1,    0,    7,   92,\n",
       "         171,  289,  169,   13,  147,   14,   27,    1,  356,    7,   13,  553,\n",
       "          84,    9,   48,  100,    4,   36,  645,  227,  781,  224,  177, 1432,\n",
       "          15,   54,  664,  499,  688,  975,  279,  783,   49,  309, 2021,  130,\n",
       "        1466,  322,  380,  297,  450, 1095, 1081,    0,  306,  379,  352,  287,\n",
       "         623, 2196,   20, 2090,  607,  417,  858,   94,  169,  320,   14,   40,\n",
       "         222, 1357,    0,   19,  563,   45,  664,  311,    0,  167,  585,  292,\n",
       "        1189,    0,  208, 1431,  157,  131,   46,  387,  571,   90,  258,  517,\n",
       "         521,  290,  317,  646,  950,  466,  395,  663, 1093, 1590, 1587,    4,\n",
       "           1,  843,  101,   28,  108,  147,   39, 1656,   13,  287,  798,  645,\n",
       "         781,  271,  167,  844,   75,  100,   89,   62,   36,  171, 1405,   11,\n",
       "         116,    8,  169,  156,  125, 1445,  570,  109,  162,   92,  518,  229,\n",
       "           1,   28,  673,   92,   62,    7,   15,   54,  798,  645,  781,   13,\n",
       "         287,  205,  289,  169,  452,    1,  452,   16,   84,  462,   11,  169,\n",
       "         116,    8,  146,   19,   92,    1,  452,   15,   54,   16,   84,  462,\n",
       "          92,  332,    4,  133,   39,   40, 1300,  169,  797,   94,  109,  162,\n",
       "         101,   36,  146,   19,    0,  192, 1255,  930, 1489,  150,   42,  155,\n",
       "           1,  263,  111,  171,  289,  169,    4, 1554,   96,  116,    8,  797,\n",
       "          94,   11,  109,  570,  391,   42,  503,   74,   36, 1415,  362,  370,\n",
       "         621,    9,   41,  161,   56,  653,  107,  125,  332,   40,  180,    7,\n",
       "          19,  403,   75,  133,  186,   27,  199,  277,   79,  137,  325, 1086,\n",
       "         274,   88,  242,   33,   15,  858,  997,   52,   39,  420,  230,    1,\n",
       "         171,  289,  169,    4, 1554,   96,  116,    8,  797,   94,   11,  109,\n",
       "         570,  391,   42,  503,   74,   36, 1415,  362,  370,  621,    9,   41,\n",
       "         161,   56,  653,  107,  125,  332,   40,  180,    7,   19,  403,   75,\n",
       "         133,  186,   27,  199,  277,   79,  137,  325, 1086,  274,   88,  242,\n",
       "          33,   15,  858,  997,   52,   39,  420,  230,    1,  183,   28,   52,\n",
       "         169,  320,  417,   12,  146,   49,   89,  234,  798,  645,  781,   13,\n",
       "         287,  329,  524,  147,  253,  130,  301, 2153, 2070, 1596,  228,   33,\n",
       "          29,  491,   42,    0,  764,  503,  167,    7,  272,   40,    1,   28,\n",
       "         234,   92,  147,   14,   15,   54,   85,   40,  798,  645,  781,   13,\n",
       "         287,  260,  169,    7,  417,  288,  424,    1,   28,  673,   52,   12,\n",
       "        2008,   33,   14,   29,   13,  527,  287,  651,  116,  146,   19,  130,\n",
       "         301,   40,  272,  222,   89,    7,  204,   62,    1,  356,    7,   13,\n",
       "         553,   89,   19,   12,  386,  107,   42,   37,    9,  664,  499,  645,\n",
       "         781,    0,  352,  673,   31,  134, 1072,   15,  664,  664,  417,  130,\n",
       "         100,  238,  894, 1494,  279,   99,    0,  450,  995, 2101,  998,  311,\n",
       "         563,    0,    0,  779, 1354,   25,    0,  860, 1431,  157,  131,   46,\n",
       "         387,  571,   90,  258,   20,  517,  521,  290,  317,  646,  950,  466,\n",
       "         395,  663, 1093, 1590, 1587,    4,    3,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.Text1[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab.freqs)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "PAD_IDX = 1\n",
    "NUM_QUANTILE = 51\n",
    "GAMMA = 0.99\n",
    "cumulative_density = torch.FloatTensor(\n",
    "            (2 * np.arange(NUM_QUANTILE) + 1) / (2.0 * NUM_QUANTILE)).to(device)\n",
    "\n",
    "quantile_weight = 1.0 / NUM_QUANTILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = QRDQN(TEXT.vocab.vectors, VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS,\n",
    "                        FILTER_SIZES, PAD_IDX)\n",
    "\n",
    "target_model = QRDQN(TEXT.vocab.vectors, VOCAB_SIZE, EMBEDDING_DIM, N_FILTERS,\n",
    "                        FILTER_SIZES, PAD_IDX)\n",
    "\n",
    "model = model.to(device)\n",
    "target_model = target_model.to(device)\n",
    "\n",
    "target_model.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法\n",
    "learning_rate = 2.5e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(scores, y):    \n",
    "    correct = (scores == y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()\n",
    "    return acc\n",
    "\n",
    "def huber(x):\n",
    "        cond = (x.abs() < 1.0).float().detach()\n",
    "        return 0.5 * x.pow(2) * cond + (x.abs() - 0.5) * (1.0 - cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## テスト\n",
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----start----\n",
      "--------------------\n",
      "epoch: 0\n",
      "loss: 27.723329544067383\n",
      "epi_reward: 52.19899989105761\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 1\n",
      "loss: 16.834699630737305\n",
      "epi_reward: 60.825000336393714\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 2\n",
      "loss: 20.93568229675293\n",
      "epi_reward: 66.28099965117872\n",
      "neutrals: 525   buys: 494\n",
      "--------------------\n",
      "epoch: 3\n",
      "loss: 17.961671829223633\n",
      "epi_reward: 19.13199987448752\n",
      "neutrals: 486   buys: 533\n",
      "--------------------\n",
      "epoch: 4\n",
      "loss: 17.829740524291992\n",
      "epi_reward: 42.83800185471773\n",
      "neutrals: 491   buys: 528\n",
      "--------------------\n",
      "epoch: 5\n",
      "loss: 22.103946685791016\n",
      "epi_reward: 30.029000770300627\n",
      "neutrals: 517   buys: 502\n",
      "--------------------\n",
      "epoch: 6\n",
      "loss: 17.072996139526367\n",
      "epi_reward: 68.70500061661005\n",
      "neutrals: 510   buys: 509\n",
      "--------------------\n",
      "epoch: 7\n",
      "loss: 15.591486930847168\n",
      "epi_reward: 87.60299984179437\n",
      "neutrals: 531   buys: 488\n",
      "--------------------\n",
      "epoch: 8\n",
      "loss: 10.740290641784668\n",
      "epi_reward: 12.942998705431819\n",
      "neutrals: 509   buys: 510\n",
      "--------------------\n",
      "epoch: 9\n",
      "loss: 13.301034927368164\n",
      "epi_reward: 42.347999485209584\n",
      "neutrals: 526   buys: 493\n",
      "--------------------\n",
      "epoch: 10\n",
      "loss: 21.818557739257812\n",
      "epi_reward: 26.138000536710024\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 11\n",
      "loss: 17.047853469848633\n",
      "epi_reward: 73.11500178463757\n",
      "neutrals: 493   buys: 526\n",
      "--------------------\n",
      "epoch: 12\n",
      "loss: 15.07099723815918\n",
      "epi_reward: 23.500000091269612\n",
      "neutrals: 475   buys: 544\n",
      "--------------------\n",
      "epoch: 13\n",
      "loss: 14.092758178710938\n",
      "epi_reward: 24.767000641673803\n",
      "neutrals: 535   buys: 484\n",
      "--------------------\n",
      "epoch: 14\n",
      "loss: 11.713233947753906\n",
      "epi_reward: 37.76400117762387\n",
      "neutrals: 492   buys: 527\n",
      "--------------------\n",
      "epoch: 15\n",
      "loss: 13.555005073547363\n",
      "epi_reward: 48.43999973498285\n",
      "neutrals: 508   buys: 511\n",
      "--------------------\n",
      "epoch: 16\n",
      "loss: 11.019207954406738\n",
      "epi_reward: 50.377999007701874\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 17\n",
      "loss: 11.052567481994629\n",
      "epi_reward: 24.847999906167388\n",
      "neutrals: 511   buys: 508\n",
      "--------------------\n",
      "epoch: 18\n",
      "loss: 12.177607536315918\n",
      "epi_reward: 80.73099954612553\n",
      "neutrals: 499   buys: 520\n",
      "--------------------\n",
      "epoch: 19\n",
      "loss: 13.639126777648926\n",
      "epi_reward: 43.250000244006515\n",
      "neutrals: 480   buys: 539\n",
      "--------------------\n",
      "epoch: 20\n",
      "loss: 13.977763175964355\n",
      "epi_reward: 16.385000966489315\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 21\n",
      "loss: 11.962461471557617\n",
      "epi_reward: 51.39200058206916\n",
      "neutrals: 516   buys: 503\n",
      "--------------------\n",
      "epoch: 22\n",
      "loss: 11.200408935546875\n",
      "epi_reward: 61.0580004286021\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 23\n",
      "loss: 10.40794849395752\n",
      "epi_reward: 42.89900094456971\n",
      "neutrals: 516   buys: 503\n",
      "--------------------\n",
      "epoch: 24\n",
      "loss: 12.931540489196777\n",
      "epi_reward: -19.152999913319945\n",
      "neutrals: 505   buys: 514\n",
      "--------------------\n",
      "epoch: 25\n",
      "loss: 10.661797523498535\n",
      "epi_reward: 79.33899974636734\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 26\n",
      "loss: 10.622138977050781\n",
      "epi_reward: 28.427000235766172\n",
      "neutrals: 522   buys: 497\n",
      "--------------------\n",
      "epoch: 27\n",
      "loss: 11.085783958435059\n",
      "epi_reward: 16.389999974519014\n",
      "neutrals: 519   buys: 500\n",
      "--------------------\n",
      "epoch: 28\n",
      "loss: 12.353378295898438\n",
      "epi_reward: 31.63599893823266\n",
      "neutrals: 544   buys: 475\n",
      "--------------------\n",
      "epoch: 29\n",
      "loss: 10.837424278259277\n",
      "epi_reward: 59.405999375507236\n",
      "neutrals: 525   buys: 494\n",
      "--------------------\n",
      "epoch: 30\n",
      "loss: 15.476639747619629\n",
      "epi_reward: 11.24100174382329\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 31\n",
      "loss: 11.815115928649902\n",
      "epi_reward: 83.1520002707839\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 32\n",
      "loss: 8.910555839538574\n",
      "epi_reward: 50.73099975846708\n",
      "neutrals: 492   buys: 527\n",
      "--------------------\n",
      "epoch: 33\n",
      "loss: 10.257378578186035\n",
      "epi_reward: 44.97500019706786\n",
      "neutrals: 502   buys: 517\n",
      "--------------------\n",
      "epoch: 34\n",
      "loss: 9.29990291595459\n",
      "epi_reward: 9.206002065911889\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 35\n",
      "loss: 9.104303359985352\n",
      "epi_reward: 33.074999425560236\n",
      "neutrals: 508   buys: 511\n",
      "--------------------\n",
      "epoch: 36\n",
      "loss: 9.325027465820312\n",
      "epi_reward: 10.964000139385462\n",
      "neutrals: 539   buys: 480\n",
      "--------------------\n",
      "epoch: 37\n",
      "loss: 9.844474792480469\n",
      "epi_reward: 72.6469990387559\n",
      "neutrals: 538   buys: 481\n",
      "--------------------\n",
      "epoch: 38\n",
      "loss: 9.616532325744629\n",
      "epi_reward: -3.475999789312482\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 39\n",
      "loss: 9.822263717651367\n",
      "epi_reward: 63.42800025828183\n",
      "neutrals: 505   buys: 514\n",
      "--------------------\n",
      "epoch: 40\n",
      "loss: 15.441618919372559\n",
      "epi_reward: 48.66099854558706\n",
      "neutrals: 489   buys: 530\n",
      "--------------------\n",
      "epoch: 41\n",
      "loss: 9.060911178588867\n",
      "epi_reward: 66.41800037771463\n",
      "neutrals: 510   buys: 509\n",
      "--------------------\n",
      "epoch: 42\n",
      "loss: 7.957070827484131\n",
      "epi_reward: 61.50800062902272\n",
      "neutrals: 520   buys: 499\n",
      "--------------------\n",
      "epoch: 43\n",
      "loss: 8.76242733001709\n",
      "epi_reward: 8.855999235063791\n",
      "neutrals: 516   buys: 503\n",
      "--------------------\n",
      "epoch: 44\n",
      "loss: 8.230545997619629\n",
      "epi_reward: 63.97199874185026\n",
      "neutrals: 480   buys: 539\n",
      "--------------------\n",
      "epoch: 45\n",
      "loss: 8.402780532836914\n",
      "epi_reward: 78.44000168330967\n",
      "neutrals: 507   buys: 512\n",
      "--------------------\n",
      "epoch: 46\n",
      "loss: 8.034791946411133\n",
      "epi_reward: 30.419999895617366\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 47\n",
      "loss: 8.018129348754883\n",
      "epi_reward: 33.39100099913776\n",
      "neutrals: 492   buys: 527\n",
      "--------------------\n",
      "epoch: 48\n",
      "loss: 8.137284278869629\n",
      "epi_reward: 34.7650003451854\n",
      "neutrals: 506   buys: 513\n",
      "--------------------\n",
      "epoch: 49\n",
      "loss: 7.676088809967041\n",
      "epi_reward: 14.439000079408288\n",
      "neutrals: 480   buys: 539\n",
      "--------------------\n",
      "epoch: 50\n",
      "loss: 12.924753189086914\n",
      "epi_reward: 21.28099984675646\n",
      "neutrals: 494   buys: 525\n",
      "--------------------\n",
      "epoch: 51\n",
      "loss: 7.888509750366211\n",
      "epi_reward: 22.91100025549531\n",
      "neutrals: 494   buys: 525\n",
      "--------------------\n",
      "epoch: 52\n",
      "loss: 7.392663955688477\n",
      "epi_reward: 38.479000421240926\n",
      "neutrals: 490   buys: 529\n",
      "--------------------\n",
      "epoch: 53\n",
      "loss: 6.826189994812012\n",
      "epi_reward: 29.60099959746003\n",
      "neutrals: 497   buys: 522\n",
      "--------------------\n",
      "epoch: 54\n",
      "loss: 7.045611381530762\n",
      "epi_reward: 36.31899970769882\n",
      "neutrals: 543   buys: 476\n",
      "--------------------\n",
      "epoch: 55\n",
      "loss: 6.436223030090332\n",
      "epi_reward: 47.06600094400346\n",
      "neutrals: 477   buys: 542\n",
      "--------------------\n",
      "epoch: 56\n",
      "loss: 6.761891841888428\n",
      "epi_reward: 37.89100137911737\n",
      "neutrals: 521   buys: 498\n",
      "--------------------\n",
      "epoch: 57\n",
      "loss: 6.843565940856934\n",
      "epi_reward: 48.84600034169853\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 58\n",
      "loss: 6.713322639465332\n",
      "epi_reward: 12.562000125646591\n",
      "neutrals: 487   buys: 532\n",
      "--------------------\n",
      "epoch: 59\n",
      "loss: 6.570734024047852\n",
      "epi_reward: 52.35300051420927\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 60\n",
      "loss: 14.20753002166748\n",
      "epi_reward: 44.36700195632875\n",
      "neutrals: 517   buys: 502\n",
      "--------------------\n",
      "epoch: 61\n",
      "loss: 7.965818881988525\n",
      "epi_reward: -13.349999805912375\n",
      "neutrals: 515   buys: 504\n",
      "--------------------\n",
      "epoch: 62\n",
      "loss: 6.018826961517334\n",
      "epi_reward: 40.95000059902668\n",
      "neutrals: 537   buys: 482\n",
      "--------------------\n",
      "epoch: 63\n",
      "loss: 7.816952228546143\n",
      "epi_reward: 50.73799973540008\n",
      "neutrals: 478   buys: 541\n",
      "--------------------\n",
      "epoch: 64\n",
      "loss: 6.008539199829102\n",
      "epi_reward: 4.196001483127475\n",
      "neutrals: 525   buys: 494\n",
      "--------------------\n",
      "epoch: 65\n",
      "loss: 5.465472221374512\n",
      "epi_reward: 84.44300033338368\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 66\n",
      "loss: 5.951108455657959\n",
      "epi_reward: 61.4270006865263\n",
      "neutrals: 493   buys: 526\n",
      "--------------------\n",
      "epoch: 67\n",
      "loss: 5.891017913818359\n",
      "epi_reward: 66.66900208964944\n",
      "neutrals: 510   buys: 509\n",
      "--------------------\n",
      "epoch: 68\n",
      "loss: 6.382711410522461\n",
      "epi_reward: 58.35000053048134\n",
      "neutrals: 492   buys: 527\n",
      "--------------------\n",
      "epoch: 69\n",
      "loss: 6.101057529449463\n",
      "epi_reward: 41.01500038057566\n",
      "neutrals: 530   buys: 489\n",
      "--------------------\n",
      "epoch: 70\n",
      "loss: 16.34144401550293\n",
      "epi_reward: 19.38800015486777\n",
      "neutrals: 509   buys: 510\n",
      "--------------------\n",
      "epoch: 71\n",
      "loss: 7.22050666809082\n",
      "epi_reward: 67.0760006159544\n",
      "neutrals: 505   buys: 514\n",
      "--------------------\n",
      "epoch: 72\n",
      "loss: 6.147563934326172\n",
      "epi_reward: 6.8710002694278955\n",
      "neutrals: 530   buys: 489\n",
      "--------------------\n",
      "epoch: 73\n",
      "loss: 5.702777862548828\n",
      "epi_reward: 21.088000930845737\n",
      "neutrals: 520   buys: 499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "epoch: 74\n",
      "loss: 5.458675384521484\n",
      "epi_reward: 27.394000513479114\n",
      "neutrals: 528   buys: 491\n",
      "--------------------\n",
      "epoch: 75\n",
      "loss: 5.646203517913818\n",
      "epi_reward: 54.22399999760091\n",
      "neutrals: 503   buys: 516\n",
      "--------------------\n",
      "epoch: 76\n",
      "loss: 5.1616291999816895\n",
      "epi_reward: 44.05700019560754\n",
      "neutrals: 510   buys: 509\n",
      "--------------------\n",
      "epoch: 77\n",
      "loss: 5.189136028289795\n",
      "epi_reward: -30.14299938827753\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 78\n",
      "loss: 5.236669063568115\n",
      "epi_reward: 37.579001024365425\n",
      "neutrals: 494   buys: 525\n",
      "--------------------\n",
      "epoch: 79\n",
      "loss: 5.16577672958374\n",
      "epi_reward: 9.58800052665174\n",
      "neutrals: 480   buys: 539\n",
      "--------------------\n",
      "epoch: 80\n",
      "loss: 11.733405113220215\n",
      "epi_reward: 9.305999506264925\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 81\n",
      "loss: 5.509894371032715\n",
      "epi_reward: 58.99700066819787\n",
      "neutrals: 505   buys: 514\n",
      "--------------------\n",
      "epoch: 82\n",
      "loss: 5.16268253326416\n",
      "epi_reward: 65.37999972142279\n",
      "neutrals: 510   buys: 509\n",
      "--------------------\n",
      "epoch: 83\n",
      "loss: 5.496706485748291\n",
      "epi_reward: 5.566001346334815\n",
      "neutrals: 512   buys: 507\n",
      "--------------------\n",
      "epoch: 84\n",
      "loss: 5.281569004058838\n",
      "epi_reward: 6.3050017431378365\n",
      "neutrals: 491   buys: 528\n",
      "--------------------\n",
      "epoch: 85\n",
      "loss: 4.749293804168701\n",
      "epi_reward: 29.47600087337196\n",
      "neutrals: 522   buys: 497\n",
      "--------------------\n",
      "epoch: 86\n",
      "loss: 4.779975414276123\n",
      "epi_reward: 70.99900029413402\n",
      "neutrals: 515   buys: 504\n",
      "--------------------\n",
      "epoch: 87\n",
      "loss: 4.673876762390137\n",
      "epi_reward: 77.14999980852008\n",
      "neutrals: 516   buys: 503\n",
      "--------------------\n",
      "epoch: 88\n",
      "loss: 4.8754777908325195\n",
      "epi_reward: 16.62200110591948\n",
      "neutrals: 500   buys: 519\n",
      "--------------------\n",
      "epoch: 89\n",
      "loss: 4.308682441711426\n",
      "epi_reward: 55.63500009663403\n",
      "neutrals: 521   buys: 498\n",
      "--------------------\n",
      "epoch: 90\n",
      "loss: 14.281365394592285\n",
      "epi_reward: 76.45300057530403\n",
      "neutrals: 504   buys: 515\n",
      "--------------------\n",
      "epoch: 91\n",
      "loss: 4.698190212249756\n",
      "epi_reward: 58.59500075876713\n",
      "neutrals: 489   buys: 530\n",
      "--------------------\n",
      "epoch: 92\n",
      "loss: 4.607080936431885\n",
      "epi_reward: 32.62599980086088\n",
      "neutrals: 513   buys: 506\n",
      "--------------------\n",
      "epoch: 93\n",
      "loss: 4.115962982177734\n",
      "epi_reward: 30.247000688686967\n",
      "neutrals: 517   buys: 502\n",
      "--------------------\n",
      "epoch: 94\n",
      "loss: 3.7730844020843506\n",
      "epi_reward: 37.12199981510639\n",
      "neutrals: 519   buys: 500\n",
      "--------------------\n",
      "epoch: 95\n",
      "loss: 3.982553005218506\n",
      "epi_reward: 72.48799916170537\n",
      "neutrals: 511   buys: 508\n",
      "--------------------\n",
      "epoch: 96\n",
      "loss: 4.027303218841553\n",
      "epi_reward: 89.53600119613111\n",
      "neutrals: 536   buys: 483\n",
      "--------------------\n",
      "epoch: 97\n",
      "loss: 3.9400131702423096\n",
      "epi_reward: 31.747001269832253\n",
      "neutrals: 496   buys: 523\n",
      "--------------------\n",
      "epoch: 98\n",
      "loss: 3.629199504852295\n",
      "epi_reward: 59.15900100953877\n",
      "neutrals: 540   buys: 479\n",
      "--------------------\n",
      "epoch: 99\n",
      "loss: 3.9033496379852295\n",
      "epi_reward: 11.72199996188283\n",
      "neutrals: 495   buys: 524\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "TARGET_UPDATE_FREQ = 10\n",
    "# dataloaders_dict = {'train': train_dl, 'val':val_dl}\n",
    "dataloaders_dict = {'train': train_dl}\n",
    "\n",
    "print('----start----')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epi_rewards = []\n",
    "    neutrals = []\n",
    "    buys = []\n",
    "    \n",
    "    # update target_model\n",
    "    if epoch % TARGET_UPDATE_FREQ == 0:\n",
    "        target_model.load_state_dict(model.state_dict())\n",
    "    \n",
    "    for batch in (dataloaders_dict['train']):      \n",
    "        # curr_q\n",
    "        states = batch.Text1[0].to(device)\n",
    "        next_states = batch.Text2[0].to(device)\n",
    "        rewards = batch.Label.to(device)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            dist = model(states) * quantile_weight\n",
    "            actions = dist.sum(dim=2).max(1)[1]\n",
    "\n",
    "            actions = torch.where(torch.randn(len(states)).to(device) >= 0, \n",
    "                                                   actions, \n",
    "                                                  (actions + 1) % 2)\n",
    "\n",
    "            selected_actions = actions.detach().cpu().numpy()\n",
    "            actions = actions.view(states.size(0), 1, 1).expand(-1, -1, NUM_QUANTILE)\n",
    "\n",
    "\n",
    "        epi_rewards.append((selected_actions * rewards.detach().cpu().numpy()).sum())\n",
    "        neutrals.append(len(selected_actions[selected_actions == 0]))\n",
    "        buys.append(len(selected_actions[selected_actions == 1]))\n",
    "        \n",
    "        curr_q = model(states).gather(1, actions).squeeze(dim=1)\n",
    "\n",
    "        # target_q\n",
    "        with torch.no_grad():\n",
    "\n",
    "            next_dist = model(next_states) * quantile_weight\n",
    "            next_action = next_dist.sum(dim=2).max(1)[1].view(next_states.size(0), 1, 1).expand(\n",
    "                -1, -1, NUM_QUANTILE)\n",
    "\n",
    "            next_q = target_model(next_states).gather(1, next_action).squeeze(dim=1)\n",
    "            target_q = rewards.view(-1, 1) + (GAMMA * next_q)\n",
    "\n",
    "        diff = target_q.t().unsqueeze(-1) - curr_q.unsqueeze(0)\n",
    "        loss = huber(diff) * torch.abs(\n",
    "                        cumulative_density.view(1, -1) - (diff < 0).to(torch.float))\n",
    "        loss = loss.transpose(0, 1)\n",
    "        loss = loss.mean(1).sum(-1).mean()\n",
    "\n",
    "        # Optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('--------------------')\n",
    "    print('epoch:', epoch)\n",
    "    print('loss:', loss.item())\n",
    "    print('epi_reward:', sum(epi_rewards))\n",
    "    print('neutrals:', sum(neutrals), '  buys:', sum(buys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 描画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))\n",
    "states = batch.Text1[0].to(device)\n",
    "next_states = batch.Text2[0].to(device)\n",
    "rewards = batch.Label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = states[8]\n",
    "actions = (model(state.unsqueeze(0)) * quantile_weight)\n",
    "dist_action = actions[0].cpu().detach().numpy()\n",
    "# sns.distplot(dist_action[0], bins=51, color='red')\n",
    "sns.distplot(dist_action[1], bins=10, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = states[8]\n",
    "actions = (model(state.unsqueeze(0)) * quantile_weight)\n",
    "dist_action = actions[0].cpu().detach().numpy()\n",
    "# sns.distplot(dist_action[0], bins=51, color='red')\n",
    "sns.distplot(dist_action[1], bins=30, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
