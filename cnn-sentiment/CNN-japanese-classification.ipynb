{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext import data, datasets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from model import TransformerClassification, weights_init, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "日経       144749\n",
       "ＮＱＮ       77146\n",
       "発表        30245\n",
       "ＱＵＩＣＫ      5796\n",
       "日銀         2256\n",
       "Ｒ＆Ｉ        1692\n",
       "財務省         748\n",
       "Name: News_Source, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./data/news/2011.csv', encoding='cp932')\n",
    "# df1 = df1[df1['Company_IDs(TSE)'] == '7203']\n",
    "df1['News_Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100                                                            80749\n",
       "86:86                                                           1600\n",
       "50                                                              1205\n",
       "49                                                               790\n",
       "48                                                               701\n",
       "                                                               ...  \n",
       "29:29:28:28:28:28:28:28:27:27:27:27:26:26:26:26:26:25              1\n",
       "28:28:27:27:27:27:25:25:25:25:25:25:25:25:25:25:25:25:25:25        1\n",
       "85:38:38:35:33                                                     1\n",
       "31:31:31:29:27:26:26                                               1\n",
       "37:37:37:37:35:32:27                                               1\n",
       "Name: Company_Relevance, Length: 8801, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Company_Relevance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(range(2011, 2019)):\n",
    "    tmp = pd.read_csv('./data/news/' + str(date) + '.csv', encoding='cp932')\n",
    "    tmp = tmp[tmp['Company_IDs(TSE)'] == '7203']\n",
    "    tmp = tmp[['Time_Stamp_Original(JST)', \n",
    "                        'Company_Code(TSE)', \n",
    "                        'Headline', \n",
    "                        'News_Source',\n",
    "                        'Company_Relevance', \n",
    "                        'Keyword_Article']]\n",
    "\n",
    "    # 欠損除去\n",
    "    tmp = tmp[~tmp[\"Keyword_Article\"].isnull()]\n",
    "\n",
    "    # タグ除去\n",
    "    tmp = tmp[(tmp['News_Source'] == '日経') | \n",
    "                        (tmp['News_Source'] == 'ＮＱＮ') |\n",
    "                        (tmp['News_Source'] == 'ＱＵＩＣＫ') | \n",
    "                        (tmp['News_Source'] == 'Ｒ＆Ｉ')]\n",
    "\n",
    "    tmp.index = pd.to_datetime(tmp[\"Time_Stamp_Original(JST)\"])\n",
    "    tmp = tmp.drop(\"Time_Stamp_Original(JST)\", axis=1)\n",
    "    \n",
    "    if i == 0:\n",
    "        df1 = tmp.copy()\n",
    "    else:\n",
    "        df1 = pd.concat([df1, tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# インデックスを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_time(x):\n",
    "    if x.hour > 15:\n",
    "        return x + datetime.timedelta(days=1)\n",
    "    return x\n",
    "\n",
    "time = pd.to_datetime(df1.index.values)\n",
    "df1.index = df1.index.map(norm_time)\n",
    "df1.index = df1.index.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 株価を挿入する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>3265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>3295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>3380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>3455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11</th>\n",
       "      <td>3455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-12</th>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-13</th>\n",
       "      <td>3535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-14</th>\n",
       "      <td>3550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-17</th>\n",
       "      <td>3500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-18</th>\n",
       "      <td>3510.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            adj_close\n",
       "2011-01-04     3265.0\n",
       "2011-01-05     3295.0\n",
       "2011-01-06     3380.0\n",
       "2011-01-07     3455.0\n",
       "2011-01-11     3455.0\n",
       "2011-01-12     3500.0\n",
       "2011-01-13     3535.0\n",
       "2011-01-14     3550.0\n",
       "2011-01-17     3500.0\n",
       "2011-01-18     3510.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 株価を取り出す\n",
    "df2 = pd.read_csv('./data/stock_price/7203.csv', index_col=0)\n",
    "df2.index = pd.to_datetime(df2['date'])\n",
    "df2.index = df2.index.date\n",
    "df2 = df2.drop(['date'], axis=1)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時系列をくっつける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ts-zemi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.concat([df1,df2], axis=1, join_axes=[df1.index])\n",
    "df3['price'] = np.round(df2.pct_change().shift(-1) * 100, 3)\n",
    "df3.loc[df3['price'] > 0, 'price'] = 1\n",
    "df3.loc[df3['price'] < 0, 'price'] = 0\n",
    "df3['Keyword_Article'] = \\\n",
    "    df3.groupby(level=0).apply(lambda x: ':<pad>:'.join(list(x['Keyword_Article'])))\n",
    "df3 = df3.dropna()\n",
    "\n",
    "df3 = df3[~df3.duplicated(subset=['Keyword_Article'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Code(TSE)</th>\n",
       "      <th>Headline</th>\n",
       "      <th>News_Source</th>\n",
       "      <th>Company_Relevance</th>\n",
       "      <th>Keyword_Article</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇次世代車の研究開発　名大に国内最大拠点</td>\n",
       "      <td>日経</td>\n",
       "      <td>38</td>\n",
       "      <td>安全:環境:負荷:開発:目指す:開所式:研究拠点:効率:簡素化:次世代:電気自動車:電気:幅...</td>\n",
       "      <td>3265.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇12月の中国新車販売、トヨタが単月で過去最高</td>\n",
       "      <td>日経</td>\n",
       "      <td>100</td>\n",
       "      <td>北京:中国:１２月:新車販売台数:前年同月比:増:過去最高:制限:受け:全国:各地:乗用車:...</td>\n",
       "      <td>3295.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;NQN&gt;◇トヨタ社長「今年は後半に晴れ間」　為替は１ドル＝90円を期待</td>\n",
       "      <td>ＮＱＮ</td>\n",
       "      <td>100</td>\n",
       "      <td>豊田:見通し:販売:エコカー補助金:安定的:伸び:株価:為替:水準:日経平均株価:最低:ライ...</td>\n",
       "      <td>3380.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇福岡県、自動車の技術者育成へ新組織　年内、中小向け</td>\n",
       "      <td>日経</td>\n",
       "      <td>37</td>\n",
       "      <td>自動車産業:強化:福岡:先端:設置:方針:技術:調査:ニーズ:カリキュラム:大学:受け:生産...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-11</th>\n",
       "      <td>7203.0</td>\n",
       "      <td>&lt;日経&gt;◇トヨタ、米ミシガン州に安全研究センター新設</td>\n",
       "      <td>日経</td>\n",
       "      <td>100</td>\n",
       "      <td>先進:安全:子供:高齢者:事故:向上:目指す:米国:大規模:リコール:回収:問題:開催:豊田...</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Company_Code(TSE)                              Headline  \\\n",
       "2011-01-04             7203.0              <日経>◇次世代車の研究開発　名大に国内最大拠点   \n",
       "2011-01-05             7203.0           <日経>◇12月の中国新車販売、トヨタが単月で過去最高   \n",
       "2011-01-06             7203.0  <NQN>◇トヨタ社長「今年は後半に晴れ間」　為替は１ドル＝90円を期待   \n",
       "2011-01-07             7203.0        <日経>◇福岡県、自動車の技術者育成へ新組織　年内、中小向け   \n",
       "2011-01-11             7203.0            <日経>◇トヨタ、米ミシガン州に安全研究センター新設   \n",
       "\n",
       "           News_Source Company_Relevance  \\\n",
       "2011-01-04          日経                38   \n",
       "2011-01-05          日経               100   \n",
       "2011-01-06         ＮＱＮ               100   \n",
       "2011-01-07          日経                37   \n",
       "2011-01-11          日経               100   \n",
       "\n",
       "                                              Keyword_Article  adj_close  \\\n",
       "2011-01-04  安全:環境:負荷:開発:目指す:開所式:研究拠点:効率:簡素化:次世代:電気自動車:電気:幅...     3265.0   \n",
       "2011-01-05  北京:中国:１２月:新車販売台数:前年同月比:増:過去最高:制限:受け:全国:各地:乗用車:...     3295.0   \n",
       "2011-01-06  豊田:見通し:販売:エコカー補助金:安定的:伸び:株価:為替:水準:日経平均株価:最低:ライ...     3380.0   \n",
       "2011-01-07  自動車産業:強化:福岡:先端:設置:方針:技術:調査:ニーズ:カリキュラム:大学:受け:生産...     3455.0   \n",
       "2011-01-11  先進:安全:子供:高齢者:事故:向上:目指す:米国:大規模:リコール:回収:問題:開催:豊田...     3455.0   \n",
       "\n",
       "            price  \n",
       "2011-01-04    1.0  \n",
       "2011-01-05    1.0  \n",
       "2011-01-06    1.0  \n",
       "2011-01-07    0.0  \n",
       "2011-01-11    1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csvファイルに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date = 2015\n",
    "test_date = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_year = df3.index.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[date_year <= train_date][['Keyword_Article', 'price']].to_csv(\n",
    "        './data/news/text_train.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[(train_date < date_year) & (date_year > test_date)][['Keyword_Article', 'price']].to_csv(\n",
    "        './data/news/text_val.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[test_date <= date_year][['Keyword_Article', 'price']].to_csv(\n",
    "        './data/news/text_test.tsv',\n",
    "        header=None,\n",
    "        index=None,\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "def preprocessing_text(text):\n",
    "    # カンマ、ピリオド以外の記号をスペースに置換\n",
    "    for p in string.punctuation:\n",
    "        if (p == \".\") or (p == \",\") or (p == \":\") or (p == \"<\")or (p == \">\"):\n",
    "            continue\n",
    "        else:\n",
    "            text = text.replace(p, \" \")\n",
    "\n",
    "    # ピリオドなどの前後にはスペースを入れておく\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = re.sub(r'[0-9 ０-９]', '0', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
    "def tokenizer_punctuation(text):\n",
    "    return text.strip().split(':')\n",
    "\n",
    "# 前処理と分かち書きをまとめた関数を定義\n",
    "def tokenizer_with_preprocessing(text):\n",
    "    text = preprocessing_text(text)\n",
    "    ret = tokenizer_punctuation(text)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# 読み込んだ内容に対して行う処理を定義\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, \n",
    "                            use_vocab=True,\n",
    "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, \n",
    "                            init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/news', train='text_train.tsv',\n",
    "    format='tsv',\n",
    "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "train_ds = train_ds[0]\n",
    "# print(vars(train_ds[1]))\n",
    "\n",
    "val_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/news', train='text_val.tsv',\n",
    "    format='tsv',\n",
    "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "val_ds = val_ds[0]\n",
    "\n",
    "test_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/news', train='text_test.tsv',\n",
    "    format='tsv',\n",
    "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "test_ds = test_ds[0]\n",
    "\n",
    "japanese_fasttext_vectors = Vectors(name='./data/news/cc.ja.300.vec')\n",
    "TEXT.build_vocab(train_ds, \n",
    "                                 vectors=japanese_fasttext_vectors,\n",
    "                                 min_freq=10)\n",
    "TEXT.vocab.freqs\n",
    "\n",
    "train_dl = torchtext.data.Iterator(\n",
    "    train_ds, batch_size=batch_size, train=True)\n",
    "val_dl = torchtext.data.Iterator(\n",
    "    val_ds, batch_size=batch_size, train=False, sort=False)\n",
    "test_dl = torchtext.data.Iterator(\n",
    "    test_ds, batch_size=len(vars(test_ds)['examples']), train=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 動作確認\n",
    "# batch = next(iter(train_dl))\n",
    "# print(batch.Text[0])\n",
    "# print(batch.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # モデルの構築\n",
    "# net = TransformerClassification(\n",
    "#     text_embedding_vectors=TEXT.vocab.vectors, \n",
    "#     d_model=300,\n",
    "#     max_seq_len=256, \n",
    "#     output_dim=1)\n",
    "\n",
    "# # 訓練モード\n",
    "# net.train()\n",
    "\n",
    "# # パラメータ初期化\n",
    "# net.net3_1.apply(weights_init)\n",
    "# net.net3_2.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=300, out_features=1, bias=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIM = len(TEXT.vocab.freqs)\n",
    "EMBEDDING_DIM = 300\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.1\n",
    "PAD_IDX = 1\n",
    "\n",
    "net = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "net.convs.apply(weights_init)\n",
    "net.fc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(scores, y):    \n",
    "    correct = (scores == y)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----start----\n",
      "Epoch 1/100 | train | Loss: 0.9380 Acc: 0.5074\n",
      "Epoch 1/100 |  val  | Loss: 0.7400 Acc: 0.5330\n",
      "Epoch 2/100 | train | Loss: 0.7651 Acc: 0.5132\n",
      "Epoch 2/100 |  val  | Loss: 0.7104 Acc: 0.5279\n",
      "Epoch 3/100 | train | Loss: 0.7002 Acc: 0.5633\n",
      "Epoch 3/100 |  val  | Loss: 0.7078 Acc: 0.5431\n",
      "Epoch 4/100 | train | Loss: 0.6820 Acc: 0.5898\n",
      "Epoch 4/100 |  val  | Loss: 0.7065 Acc: 0.5482\n",
      "Epoch 5/100 | train | Loss: 0.6566 Acc: 0.5918\n",
      "Epoch 5/100 |  val  | Loss: 0.7044 Acc: 0.5431\n",
      "Epoch 6/100 | train | Loss: 0.6388 Acc: 0.6330\n",
      "Epoch 6/100 |  val  | Loss: 0.7029 Acc: 0.5482\n",
      "Epoch 7/100 | train | Loss: 0.5944 Acc: 0.6614\n",
      "Epoch 7/100 |  val  | Loss: 0.7006 Acc: 0.5482\n",
      "Epoch 8/100 | train | Loss: 0.5988 Acc: 0.6575\n",
      "Epoch 8/100 |  val  | Loss: 0.7021 Acc: 0.5482\n",
      "Epoch 9/100 | train | Loss: 0.5475 Acc: 0.7242\n",
      "Epoch 9/100 |  val  | Loss: 0.6985 Acc: 0.5431\n",
      "Epoch 10/100 | train | Loss: 0.5270 Acc: 0.7448\n",
      "Epoch 10/100 |  val  | Loss: 0.6983 Acc: 0.5533\n",
      "Epoch 11/100 | train | Loss: 0.4990 Acc: 0.7802\n",
      "Epoch 11/100 |  val  | Loss: 0.6977 Acc: 0.5584\n",
      "Epoch 12/100 | train | Loss: 0.4898 Acc: 0.7812\n",
      "Epoch 12/100 |  val  | Loss: 0.6975 Acc: 0.5584\n",
      "Epoch 13/100 | train | Loss: 0.4804 Acc: 0.7920\n",
      "Epoch 13/100 |  val  | Loss: 0.6966 Acc: 0.5482\n",
      "Epoch 14/100 | train | Loss: 0.4583 Acc: 0.8204\n",
      "Epoch 14/100 |  val  | Loss: 0.6962 Acc: 0.5482\n",
      "Epoch 15/100 | train | Loss: 0.4471 Acc: 0.8361\n",
      "Epoch 15/100 |  val  | Loss: 0.6959 Acc: 0.5431\n",
      "Epoch 16/100 | train | Loss: 0.4274 Acc: 0.8391\n",
      "Epoch 16/100 |  val  | Loss: 0.6958 Acc: 0.5584\n",
      "Epoch 17/100 | train | Loss: 0.4209 Acc: 0.8469\n",
      "Epoch 17/100 |  val  | Loss: 0.6956 Acc: 0.5584\n",
      "Epoch 18/100 | train | Loss: 0.4035 Acc: 0.8675\n",
      "Epoch 18/100 |  val  | Loss: 0.6951 Acc: 0.5584\n",
      "Epoch 19/100 | train | Loss: 0.3887 Acc: 0.8822\n",
      "Epoch 19/100 |  val  | Loss: 0.6943 Acc: 0.5482\n",
      "Epoch 20/100 | train | Loss: 0.3674 Acc: 0.8921\n",
      "Epoch 20/100 |  val  | Loss: 0.6937 Acc: 0.5482\n",
      "Epoch 21/100 | train | Loss: 0.3673 Acc: 0.8891\n",
      "Epoch 21/100 |  val  | Loss: 0.6934 Acc: 0.5482\n",
      "Epoch 22/100 | train | Loss: 0.3610 Acc: 0.8960\n",
      "Epoch 22/100 |  val  | Loss: 0.6952 Acc: 0.5635\n",
      "Epoch 23/100 | train | Loss: 0.3447 Acc: 0.9156\n",
      "Epoch 23/100 |  val  | Loss: 0.6934 Acc: 0.5431\n",
      "Epoch 24/100 | train | Loss: 0.3273 Acc: 0.9176\n",
      "Epoch 24/100 |  val  | Loss: 0.6942 Acc: 0.5533\n",
      "Epoch 25/100 | train | Loss: 0.3280 Acc: 0.9274\n",
      "Epoch 25/100 |  val  | Loss: 0.6938 Acc: 0.5482\n",
      "Epoch 26/100 | train | Loss: 0.3122 Acc: 0.9303\n",
      "Epoch 26/100 |  val  | Loss: 0.6939 Acc: 0.5482\n",
      "Epoch 27/100 | train | Loss: 0.2993 Acc: 0.9421\n",
      "Epoch 27/100 |  val  | Loss: 0.6936 Acc: 0.5482\n",
      "Epoch 28/100 | train | Loss: 0.2995 Acc: 0.9313\n",
      "Epoch 28/100 |  val  | Loss: 0.6943 Acc: 0.5482\n",
      "Epoch 29/100 | train | Loss: 0.3040 Acc: 0.9392\n",
      "Epoch 29/100 |  val  | Loss: 0.6935 Acc: 0.5533\n",
      "Epoch 30/100 | train | Loss: 0.2761 Acc: 0.9500\n",
      "Epoch 30/100 |  val  | Loss: 0.6941 Acc: 0.5584\n",
      "Epoch 31/100 | train | Loss: 0.2787 Acc: 0.9578\n",
      "Epoch 31/100 |  val  | Loss: 0.6943 Acc: 0.5431\n",
      "Epoch 32/100 | train | Loss: 0.2713 Acc: 0.9627\n",
      "Epoch 32/100 |  val  | Loss: 0.6932 Acc: 0.5533\n",
      "Epoch 33/100 | train | Loss: 0.2561 Acc: 0.9607\n",
      "Epoch 33/100 |  val  | Loss: 0.6931 Acc: 0.5431\n",
      "Epoch 34/100 | train | Loss: 0.2502 Acc: 0.9666\n",
      "Epoch 34/100 |  val  | Loss: 0.6926 Acc: 0.5482\n",
      "Epoch 35/100 | train | Loss: 0.2466 Acc: 0.9598\n",
      "Epoch 35/100 |  val  | Loss: 0.6932 Acc: 0.5381\n",
      "Epoch 36/100 | train | Loss: 0.2307 Acc: 0.9764\n",
      "Epoch 36/100 |  val  | Loss: 0.6921 Acc: 0.5584\n",
      "Epoch 37/100 | train | Loss: 0.2405 Acc: 0.9686\n",
      "Epoch 37/100 |  val  | Loss: 0.6922 Acc: 0.5482\n",
      "Epoch 38/100 | train | Loss: 0.2287 Acc: 0.9715\n",
      "Epoch 38/100 |  val  | Loss: 0.6922 Acc: 0.5533\n",
      "Epoch 39/100 | train | Loss: 0.2260 Acc: 0.9706\n",
      "Epoch 39/100 |  val  | Loss: 0.6922 Acc: 0.5482\n",
      "Epoch 40/100 | train | Loss: 0.2287 Acc: 0.9706\n",
      "Epoch 40/100 |  val  | Loss: 0.6932 Acc: 0.5482\n",
      "Epoch 41/100 | train | Loss: 0.2158 Acc: 0.9715\n",
      "Epoch 41/100 |  val  | Loss: 0.6929 Acc: 0.5330\n",
      "Epoch 42/100 | train | Loss: 0.2142 Acc: 0.9764\n",
      "Epoch 42/100 |  val  | Loss: 0.6920 Acc: 0.5381\n",
      "Epoch 43/100 | train | Loss: 0.2201 Acc: 0.9804\n",
      "Epoch 43/100 |  val  | Loss: 0.6922 Acc: 0.5381\n",
      "Epoch 44/100 | train | Loss: 0.1958 Acc: 0.9853\n",
      "Epoch 44/100 |  val  | Loss: 0.6920 Acc: 0.5381\n",
      "Epoch 45/100 | train | Loss: 0.1915 Acc: 0.9882\n",
      "Epoch 45/100 |  val  | Loss: 0.6922 Acc: 0.5381\n",
      "Epoch 46/100 | train | Loss: 0.1907 Acc: 0.9833\n",
      "Epoch 46/100 |  val  | Loss: 0.6922 Acc: 0.5381\n",
      "Epoch 47/100 | train | Loss: 0.1942 Acc: 0.9823\n",
      "Epoch 47/100 |  val  | Loss: 0.6921 Acc: 0.5381\n",
      "Epoch 48/100 | train | Loss: 0.1853 Acc: 0.9814\n",
      "Epoch 48/100 |  val  | Loss: 0.6919 Acc: 0.5381\n",
      "Epoch 49/100 | train | Loss: 0.1800 Acc: 0.9853\n",
      "Epoch 49/100 |  val  | Loss: 0.6917 Acc: 0.5381\n",
      "Epoch 50/100 | train | Loss: 0.1776 Acc: 0.9912\n",
      "Epoch 50/100 |  val  | Loss: 0.6916 Acc: 0.5431\n",
      "Epoch 51/100 | train | Loss: 0.1774 Acc: 0.9853\n",
      "Epoch 51/100 |  val  | Loss: 0.6923 Acc: 0.5431\n",
      "Epoch 52/100 | train | Loss: 0.1665 Acc: 0.9912\n",
      "Epoch 52/100 |  val  | Loss: 0.6919 Acc: 0.5431\n",
      "Epoch 53/100 | train | Loss: 0.1721 Acc: 0.9843\n",
      "Epoch 53/100 |  val  | Loss: 0.6919 Acc: 0.5381\n",
      "Epoch 54/100 | train | Loss: 0.1657 Acc: 0.9872\n",
      "Epoch 54/100 |  val  | Loss: 0.6918 Acc: 0.5381\n",
      "Epoch 55/100 | train | Loss: 0.1600 Acc: 0.9951\n",
      "Epoch 55/100 |  val  | Loss: 0.6917 Acc: 0.5330\n",
      "Epoch 56/100 | train | Loss: 0.1620 Acc: 0.9863\n",
      "Epoch 56/100 |  val  | Loss: 0.6922 Acc: 0.5381\n",
      "Epoch 57/100 | train | Loss: 0.1549 Acc: 0.9872\n",
      "Epoch 57/100 |  val  | Loss: 0.6923 Acc: 0.5330\n",
      "Epoch 58/100 | train | Loss: 0.1534 Acc: 0.9941\n",
      "Epoch 58/100 |  val  | Loss: 0.6922 Acc: 0.5228\n",
      "Epoch 59/100 | train | Loss: 0.1453 Acc: 0.9931\n",
      "Epoch 59/100 |  val  | Loss: 0.6919 Acc: 0.5330\n",
      "Epoch 60/100 | train | Loss: 0.1481 Acc: 0.9912\n",
      "Epoch 60/100 |  val  | Loss: 0.6919 Acc: 0.5533\n",
      "Epoch 61/100 | train | Loss: 0.1421 Acc: 0.9912\n",
      "Epoch 61/100 |  val  | Loss: 0.6919 Acc: 0.5533\n",
      "Epoch 62/100 | train | Loss: 0.1388 Acc: 0.9951\n",
      "Epoch 62/100 |  val  | Loss: 0.6919 Acc: 0.5431\n",
      "Epoch 63/100 | train | Loss: 0.1364 Acc: 0.9941\n",
      "Epoch 63/100 |  val  | Loss: 0.6914 Acc: 0.5330\n",
      "Epoch 64/100 | train | Loss: 0.1351 Acc: 0.9892\n",
      "Epoch 64/100 |  val  | Loss: 0.6919 Acc: 0.5584\n",
      "Epoch 65/100 | train | Loss: 0.1276 Acc: 0.9951\n",
      "Epoch 65/100 |  val  | Loss: 0.6919 Acc: 0.5482\n",
      "Epoch 66/100 | train | Loss: 0.1351 Acc: 0.9872\n",
      "Epoch 66/100 |  val  | Loss: 0.6923 Acc: 0.5482\n",
      "Epoch 67/100 | train | Loss: 0.1253 Acc: 0.9931\n",
      "Epoch 67/100 |  val  | Loss: 0.6918 Acc: 0.5533\n",
      "Epoch 68/100 | train | Loss: 0.1300 Acc: 0.9921\n",
      "Epoch 68/100 |  val  | Loss: 0.6918 Acc: 0.5533\n",
      "Epoch 69/100 | train | Loss: 0.1210 Acc: 0.9961\n",
      "Epoch 69/100 |  val  | Loss: 0.6921 Acc: 0.5482\n",
      "Epoch 70/100 | train | Loss: 0.1187 Acc: 0.9961\n",
      "Epoch 70/100 |  val  | Loss: 0.6920 Acc: 0.5482\n",
      "Epoch 71/100 | train | Loss: 0.1123 Acc: 0.9951\n",
      "Epoch 71/100 |  val  | Loss: 0.6926 Acc: 0.5482\n",
      "Epoch 72/100 | train | Loss: 0.1177 Acc: 0.9941\n",
      "Epoch 72/100 |  val  | Loss: 0.6924 Acc: 0.5482\n",
      "Epoch 73/100 | train | Loss: 0.1116 Acc: 0.9941\n",
      "Epoch 73/100 |  val  | Loss: 0.6927 Acc: 0.5482\n",
      "Epoch 74/100 | train | Loss: 0.1128 Acc: 0.9931\n",
      "Epoch 74/100 |  val  | Loss: 0.6925 Acc: 0.5482\n",
      "Epoch 75/100 | train | Loss: 0.1131 Acc: 0.9912\n",
      "Epoch 75/100 |  val  | Loss: 0.6922 Acc: 0.5635\n",
      "Epoch 76/100 | train | Loss: 0.1091 Acc: 0.9961\n",
      "Epoch 76/100 |  val  | Loss: 0.6931 Acc: 0.5533\n",
      "Epoch 77/100 | train | Loss: 0.1108 Acc: 0.9961\n",
      "Epoch 77/100 |  val  | Loss: 0.6924 Acc: 0.5533\n",
      "Epoch 78/100 | train | Loss: 0.1051 Acc: 0.9961\n",
      "Epoch 78/100 |  val  | Loss: 0.6923 Acc: 0.5533\n",
      "Epoch 79/100 | train | Loss: 0.0998 Acc: 0.9961\n",
      "Epoch 79/100 |  val  | Loss: 0.6924 Acc: 0.5584\n",
      "Epoch 80/100 | train | Loss: 0.1038 Acc: 0.9971\n",
      "Epoch 80/100 |  val  | Loss: 0.6923 Acc: 0.5533\n",
      "Epoch 81/100 | train | Loss: 0.0953 Acc: 0.9980\n",
      "Epoch 81/100 |  val  | Loss: 0.6918 Acc: 0.5584\n",
      "Epoch 82/100 | train | Loss: 0.0996 Acc: 0.9961\n",
      "Epoch 82/100 |  val  | Loss: 0.6920 Acc: 0.5533\n",
      "Epoch 83/100 | train | Loss: 0.0982 Acc: 0.9921\n",
      "Epoch 83/100 |  val  | Loss: 0.6920 Acc: 0.5584\n",
      "Epoch 84/100 | train | Loss: 0.0950 Acc: 0.9961\n",
      "Epoch 84/100 |  val  | Loss: 0.6923 Acc: 0.5381\n",
      "Epoch 85/100 | train | Loss: 0.0938 Acc: 0.9971\n",
      "Epoch 85/100 |  val  | Loss: 0.6928 Acc: 0.5381\n",
      "Epoch 86/100 | train | Loss: 0.0932 Acc: 0.9980\n",
      "Epoch 86/100 |  val  | Loss: 0.6925 Acc: 0.5635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 | train | Loss: 0.0881 Acc: 0.9961\n",
      "Epoch 87/100 |  val  | Loss: 0.6929 Acc: 0.5381\n",
      "Epoch 88/100 | train | Loss: 0.0852 Acc: 0.9971\n",
      "Epoch 88/100 |  val  | Loss: 0.6928 Acc: 0.5431\n",
      "Epoch 89/100 | train | Loss: 0.0806 Acc: 0.9980\n",
      "Epoch 89/100 |  val  | Loss: 0.6928 Acc: 0.5482\n",
      "Epoch 90/100 | train | Loss: 0.0827 Acc: 0.9980\n",
      "Epoch 90/100 |  val  | Loss: 0.6931 Acc: 0.5381\n",
      "Epoch 91/100 | train | Loss: 0.0808 Acc: 0.9971\n",
      "Epoch 91/100 |  val  | Loss: 0.6933 Acc: 0.5482\n",
      "Epoch 92/100 | train | Loss: 0.0809 Acc: 0.9980\n",
      "Epoch 92/100 |  val  | Loss: 0.6938 Acc: 0.5381\n",
      "Epoch 93/100 | train | Loss: 0.0767 Acc: 0.9980\n",
      "Epoch 93/100 |  val  | Loss: 0.6940 Acc: 0.5482\n",
      "Epoch 94/100 | train | Loss: 0.0763 Acc: 0.9961\n",
      "Epoch 94/100 |  val  | Loss: 0.6941 Acc: 0.5431\n",
      "Epoch 95/100 | train | Loss: 0.0795 Acc: 0.9971\n",
      "Epoch 95/100 |  val  | Loss: 0.6938 Acc: 0.5482\n",
      "Epoch 96/100 | train | Loss: 0.0787 Acc: 0.9971\n",
      "Epoch 96/100 |  val  | Loss: 0.6947 Acc: 0.5381\n",
      "Epoch 97/100 | train | Loss: 0.0755 Acc: 0.9971\n",
      "Epoch 97/100 |  val  | Loss: 0.6937 Acc: 0.5431\n",
      "Epoch 98/100 | train | Loss: 0.0733 Acc: 0.9951\n",
      "Epoch 98/100 |  val  | Loss: 0.6938 Acc: 0.5431\n",
      "Epoch 99/100 | train | Loss: 0.0767 Acc: 0.9971\n",
      "Epoch 99/100 |  val  | Loss: 0.6937 Acc: 0.5431\n",
      "Epoch 100/100 | train | Loss: 0.0690 Acc: 0.9990\n",
      "Epoch 100/100 |  val  | Loss: 0.6951 Acc: 0.5482\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "dataloaders_dict = {'train': train_dl, 'val':val_dl}\n",
    "\n",
    "\n",
    "print('----start----')\n",
    "net.to(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_corrects = 0\n",
    "\n",
    "        for batch in (dataloaders_dict[phase]):\n",
    "            inputs = batch.Text[0].to(device)\n",
    "            labels = batch.Label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                # Transformerに入力\n",
    "                preds = net(inputs)\n",
    "                preds = preds.view(-1)\n",
    "#                 loss = torch.mean((preds - labels)**2)\n",
    "                loss = criterion(preds, labels)\n",
    "\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                # 更新\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # 結果の計算\n",
    "                epoch_loss += loss.item() * inputs.size(0)\n",
    "                preds[preds > 0.3] = 1\n",
    "                preds[preds < 0.3] =0\n",
    "                epoch_corrects += binary_accuracy(preds, labels) #torch.sum(preds == labels.data)\n",
    "\n",
    "        # epochごとのlossと正解率\n",
    "        epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "\n",
    "        print('Epoch {}/{} | {:^5} | Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                                                                     epoch+1,\n",
    "                                                                     num_epochs,\n",
    "                                                                     phase,\n",
    "                                                                     epoch_loss,\n",
    "                                                                     epoch_acc))\n",
    "\n",
    "net_trained = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_accuracy(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AttentionMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "batch = next(iter(test_dl))\n",
    "\n",
    "inputs = batch.Text[0].to(device)\n",
    "labels = batch.Label.to(device)\n",
    "\n",
    "preds = net_trained(inputs)\n",
    "preds = preds.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[preds > 0.3] = 1\n",
    "preds[preds < 0.3] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5062034739454094"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = (labels == preds).detach().cpu().sum().numpy().item()\n",
    "correct / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
