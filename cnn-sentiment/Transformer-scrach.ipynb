{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from glob import glob\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDbのデータを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データの作成\n",
    "with open('./data/IMDb_train.tsv', 'w') as f:\n",
    "\n",
    "    path = './data/aclImdb/train/pos/'\n",
    "    for fname in glob(os.path.join(path, '*.txt')):\n",
    "        with io.open(fname, 'r', encoding='utf-8') as ff:\n",
    "            text = ff.readline()\n",
    "            text = text.replace('\\t', ' ')\n",
    "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
    "            f.write(text)\n",
    "\n",
    "\n",
    "    path = './data/aclImdb/train/neg/'\n",
    "    for fname in glob(os.path.join(path, '*.txt')):\n",
    "        with io.open(fname, 'r', encoding='utf-8') as ff:\n",
    "            text = ff.readline()\n",
    "            text = text.replace('\\t', ' ')\n",
    "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasetの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_IMDb_DataLoaders_and_TEXT(max_length=256, batch_size=24):\n",
    "    \"\"\"IMDbのDataLoaderとTEXTオブジェクトを取得する。 \"\"\"\n",
    "\n",
    "    # 訓練データのtsvファイルを作成します\n",
    "    f = open('./data/IMDb_train.tsv', 'w')\n",
    "\n",
    "    path = './data/aclImdb/train/pos/'\n",
    "    for fname in glob(os.path.join(path, '*.txt')):\n",
    "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
    "            text = ff.readline()\n",
    "\n",
    "            # タブがあれば消しておきます\n",
    "            text = text.replace('\\t', \" \")\n",
    "\n",
    "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
    "            f.write(text)\n",
    "\n",
    "    path = './data/aclImdb/train/neg/'\n",
    "    for fname in glob(os.path.join(path, '*.txt')):\n",
    "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
    "            text = ff.readline()\n",
    "\n",
    "            # タブがあれば消しておきます\n",
    "            text = text.replace('\\t', \" \")\n",
    "\n",
    "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
    "            f.write(text)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "   # テストデータの作成\n",
    "    f = open('./data/IMDb_test.tsv', 'w')\n",
    "\n",
    "    path = './data/aclImdb/test/pos/'\n",
    "    for fname in glob(os.path.join(path, '*.txt')):\n",
    "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
    "            text = ff.readline()\n",
    "\n",
    "            # タブがあれば消しておきます\n",
    "            text = text.replace('\\t', \" \")\n",
    "\n",
    "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
    "            f.write(text)\n",
    "\n",
    "    path = './data/aclImdb/test/neg/'\n",
    "    for fname in glob(os.path.join(path, '*.txt')):\n",
    "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
    "            text = ff.readline()\n",
    "\n",
    "            # タブがあれば消しておきます\n",
    "            text = text.replace('\\t', \" \")\n",
    "\n",
    "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
    "            f.write(text)\n",
    "    f.close()\n",
    "\n",
    "    def preprocessing_text(text):\n",
    "        # 改行コードを消去\n",
    "        text = re.sub('<br />', '', text)\n",
    "\n",
    "        # カンマ、ピリオド以外の記号をスペースに置換\n",
    "        for p in string.punctuation:\n",
    "            if (p == \".\") or (p == \",\"):\n",
    "                continue\n",
    "            else:\n",
    "                text = text.replace(p, \" \")\n",
    "\n",
    "        # ピリオドなどの前後にはスペースを入れておく\n",
    "        text = text.replace(\".\", \" . \")\n",
    "        text = text.replace(\",\", \" , \")\n",
    "        return text\n",
    "\n",
    "    # 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
    "    def tokenizer_punctuation(text):\n",
    "        return text.strip().split()\n",
    "\n",
    "\n",
    "    # 前処理と分かち書きをまとめた関数を定義\n",
    "    def tokenizer_with_preprocessing(text):\n",
    "        text = preprocessing_text(text)\n",
    "        ret = tokenizer_punctuation(text)\n",
    "        return ret\n",
    "\n",
    "\n",
    "    # 読み込んだ内容に対して行う処理を定義\n",
    "    TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
    "                                lower=True, include_lengths=True, batch_first=True, fix_length=max_length, \n",
    "                                init_token=\"<cls>\", eos_token=\"<eos>\")\n",
    "    LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "    # フォルダ「data」から各tsvファイルを読み込み\n",
    "    train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
    "        path='./data/', train='IMDb_train.tsv',\n",
    "        test='IMDb_test.tsv', format='tsv',\n",
    "        fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "\n",
    "    # 訓練データとvalidationデータを分ける\n",
    "    train_ds, val_ds = train_val_ds.split(\n",
    "        split_ratio=0.8, random_state=random.seed(1234))\n",
    "\n",
    "    # torchtextで単語ベクトルとして英語学習済みモデルを読み込みます\n",
    "    english_fasttext_vectors = Vectors(name='data/wiki-news-300d-1M.vec')\n",
    "\n",
    "    # ボキャブラリー\n",
    "    TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors, min_freq=10)\n",
    "\n",
    "    # DataLoaderを作成\n",
    "    train_dl = torchtext.data.Iterator(\n",
    "        train_ds, batch_size=batch_size, train=True)\n",
    "\n",
    "    val_dl = torchtext.data.Iterator(\n",
    "        val_ds, batch_size=batch_size, train=False, sort=False)\n",
    "\n",
    "    test_dl = torchtext.data.Iterator(\n",
    "        test_ds, batch_size=batch_size, train=False, sort=False)\n",
    "\n",
    "    return train_dl, val_dl, test_dl, TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(\n",
    "    max_length=256, batch_size=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformerの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, text_embedding_vectors):\n",
    "        super(Embedder, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "        embeddings=text_embedding_vectors, freeze=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.embeddings(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PositionalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model=300, max_seq_len=256):\n",
    "        super(PositionalEncoder, self).__init__()\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # 単語ベクトルの次元数\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # 単語の順番posとベクトルの次元位置iの(p, i)によって一意に定まる表を作成する\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        \n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(\n",
    "                                        pos / (10000 ** ((2*i)/d_model)))\n",
    "                pe[pos, i+1] = math.cos(\n",
    "                                        pos / (10000 ** ((2*(i+1))/d_model)))\n",
    "        \n",
    "        self.pe = pe.to(device).unsqueeze(0)\n",
    "        \n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 入力xとPositional Encoderを足し算する\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attentionの作成\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=300):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 特徴量の作成\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # 出力の全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Attentionの大きさ調整の変数\n",
    "        self.d_k = d_model\n",
    "        \n",
    "    def forward(self, q, k, v, mask):\n",
    "        q = self.q_linear(q)\n",
    "        k = self.k_linear(k)\n",
    "        v = self.v_linear(v)\n",
    "        \n",
    "        # Attentionの値を計算する\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # maskを計算\n",
    "        mask = mask.unsqueeze(1)\n",
    "        weights = weights.masked_fill(mask==0, -1e9)\n",
    "        \n",
    "        # softmaxで規格化する\n",
    "        normalized_weights = F.softmax(weights, dim=-1)\n",
    "        \n",
    "        # AttentionをValueと掛け算\n",
    "        output = torch.matmul(normalized_weights, v)\n",
    "        \n",
    "        # 特徴量を変換\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output, normalized_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeedForwardの作成\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Blockの作成\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # LayerNorm層\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "        \n",
    "        # 全結合層\n",
    "        self.ff = FeedForward(d_model)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        x_normalized = self.norm_1(x)\n",
    "        output, normalized_weights = self.attn(\n",
    "            x_normalized, x_normalized, x_normalized, mask)\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "        \n",
    "        # 正規化と全結合層構築\n",
    "        x_normalized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normalized2))\n",
    "        \n",
    "        return output, normalized_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, d_model=300, output_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)\n",
    "        \n",
    "        # 重み初期化\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]   # 各文の先頭の単語の特徴量を取り出す\n",
    "        out = self.linear(x0)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformerClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassification(nn.Module):\n",
    "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256,\n",
    "                           output_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # モデルの構築\n",
    "        self.net1 = Embedder(text_embedding_vectors)\n",
    "        self.net2 = PositionalEncoder(d_model, max_seq_len)\n",
    "        self.net3_1 = TransformerBlock(d_model)\n",
    "        self.net3_2 = TransformerBlock(d_model)\n",
    "        self.net4 = ClassificationHead(d_model, output_dim)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x1 = self.net1(x)\n",
    "        x2 = self.net2(x1)\n",
    "        x3_1, normalized_weights_1 = self.net3_1(x2, mask)\n",
    "        x3_2, normalized_weights_2 = self.net3_2(x3_1, mask)\n",
    "        x4 = self.net4(x3_2)\n",
    "        return x4, normalized_weights_1, normalized_weights_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの構築\n",
    "net = TransformerClassification(\n",
    "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerBlock(\n",
       "  (norm_1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm_2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): Attention(\n",
       "    (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (out): Linear(in_features=300, out_features=300, bias=True)\n",
       "  )\n",
       "  (ff): FeedForward(\n",
       "    (linear_1): Linear(in_features=300, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear_2): Linear(in_features=1024, out_features=300, bias=True)\n",
       "  )\n",
       "  (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout_2): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パラメータの初期化を定義\n",
    "def weights_init(m):\n",
    "    classname =  m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "# 訓練モード\n",
    "net.train()\n",
    "\n",
    "# パラメータ初期化\n",
    "net.net3_1.apply(weights_init)\n",
    "net.net3_2.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0344, -0.0601, -0.0251,  ...,  0.2494,  0.3044,  0.0519]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習・推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最適化手法\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練と検証\n",
    "\n",
    "def train_model(net, datalloaders_dict, criterion, optimizer, num_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('----start----')\n",
    "    net.to(device)\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "            else:\n",
    "                net.eval()\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            for batch in (dataloaders_dict[phase]):\n",
    "                inputs = batch.Text[0].to(device)\n",
    "                labels = batch.Label.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    # maskの作成\n",
    "                    input_pad = 1\n",
    "                    input_mask = (inputs != input_pad)\n",
    "                    \n",
    "                    # Transformerに入力\n",
    "                    outputs, _, _ = net(inputs, input_mask)\n",
    "#                     print(outputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    # 更新\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    # 結果の計算\n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            # epochごとのlossと正解率\n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "            \n",
    "            print('Epoch {}/{} | {:^5} | Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                                                                         epoch+1,\n",
    "                                                                         num_epochs,\n",
    "                                                                         phase,\n",
    "                                                                         epoch_loss,\n",
    "                                                                         epoch_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書オブジェクトにまとめる\n",
    "dataloaders_dict = {'train': train_dl, 'val': val_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----start----\n",
      "Epoch 1/10 | train | Loss: 0.4133 Acc: 0.8156\n",
      "Epoch 1/10 |  val  | Loss: 0.3838 Acc: 0.8300\n",
      "Epoch 2/10 | train | Loss: 0.3843 Acc: 0.8309\n",
      "Epoch 2/10 |  val  | Loss: 0.3945 Acc: 0.8226\n",
      "Epoch 3/10 | train | Loss: 0.3657 Acc: 0.8402\n",
      "Epoch 3/10 |  val  | Loss: 0.3650 Acc: 0.8374\n",
      "Epoch 4/10 | train | Loss: 0.3530 Acc: 0.8452\n",
      "Epoch 4/10 |  val  | Loss: 0.3611 Acc: 0.8428\n",
      "Epoch 5/10 | train | Loss: 0.3454 Acc: 0.8520\n",
      "Epoch 5/10 |  val  | Loss: 0.3798 Acc: 0.8356\n",
      "Epoch 6/10 | train | Loss: 0.3358 Acc: 0.8544\n",
      "Epoch 6/10 |  val  | Loss: 0.3544 Acc: 0.8506\n",
      "Epoch 7/10 | train | Loss: 0.3289 Acc: 0.8612\n",
      "Epoch 7/10 |  val  | Loss: 0.3514 Acc: 0.8482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a5e7d69af4eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-d7ba3e805d16>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, datalloaders_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;31m# 結果の計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0mepoch_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "net_trained = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータでの正答率を求める\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net_trained.eval()\n",
    "net_trained.to(device)\n",
    "\n",
    "epoch_corrects = 0\n",
    "\n",
    "for batch in test_dl:\n",
    "    inputs = batch.Text[0].to(device)\n",
    "    labels = batch.Label.to(device)\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        input_pad = 1\n",
    "        input_mask = (inputs != input_pad)\n",
    "        \n",
    "        outputs, _, _ = net_trained(inputs, input_mask)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        epoch_corrects += torch.sum(preds == labels.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータ25000個の正解率: 0.8526\n"
     ]
    }
   ],
   "source": [
    "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
    "print('テストデータ{}個の正解率: {:.4f}'.format(len(test_dl.dataset), epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentionの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLを作成する関数を実装\n",
    "\n",
    "\n",
    "def highlight(word, attn):\n",
    "    \"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\"\n",
    "\n",
    "    html_color = '#%02X%02X%02X' % (\n",
    "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
    "\n",
    "\n",
    "def mk_html(index, batch, preds, normlized_weights_1, normlized_weights_2, TEXT):\n",
    "    \"HTMLデータを作成する\"\n",
    "\n",
    "    # indexの結果を抽出\n",
    "    sentence = batch.Text[0][index]  # 文章\n",
    "    label = batch.Label[index]  # ラベル\n",
    "    pred = preds[index]  # 予測\n",
    "\n",
    "    # indexのAttentionを抽出と規格化\n",
    "    attens1 = normlized_weights_1[index, 0, :]  # 0番目の<cls>のAttention\n",
    "    attens1 /= attens1.max()\n",
    "\n",
    "    attens2 = normlized_weights_2[index, 0, :]  # 0番目の<cls>のAttention\n",
    "    attens2 /= attens2.max()\n",
    "\n",
    "    # ラベルと予測結果を文字に置き換え\n",
    "    if label == 0:\n",
    "        label_str = \"Negative\"\n",
    "    else:\n",
    "        label_str = \"Positive\"\n",
    "\n",
    "    if pred == 0:\n",
    "        pred_str = \"Negative\"\n",
    "    else:\n",
    "        pred_str = \"Positive\"\n",
    "\n",
    "    # 表示用のHTMLを作成する\n",
    "    html = '正解ラベル：{}<br>推論ラベル：{}<br><br>'.format(label_str, pred_str)\n",
    "\n",
    "    # 1段目のAttention\n",
    "    html += '[TransformerBlockの1段目のAttentionを可視化]<br>'\n",
    "    for word, attn in zip(sentence, attens1):\n",
    "        html += highlight(TEXT.vocab.itos[word], attn)\n",
    "    html += \"<br><br>\"\n",
    "\n",
    "    # 2段目のAttention\n",
    "    html += '[TransformerBlockの2段目のAttentionを可視化]<br>'\n",
    "    for word, attn in zip(sentence, attens2):\n",
    "        html += highlight(TEXT.vocab.itos[word], attn)\n",
    "\n",
    "    html += \"<br><br>\"\n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "正解ラベル：Positive<br>推論ラベル：Positive<br><br>[TransformerBlockの1段目のAttentionを可視化]<br><span style=\"background-color: #FFFCFC\"> <cls></span><span style=\"background-color: #FFFAFA\"> <unk></span><span style=\"background-color: #FF0000\"> bilge</span><span style=\"background-color: #FFF7F7\"> <unk></span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFFDFD\"> 2002</span><span style=\"background-color: #FFFCFC\"> film</span><span style=\"background-color: #FFF9F9\"> distant</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFCFC\"> third</span><span style=\"background-color: #FFFEFE\"> feature</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFDFD\"> first</span><span style=\"background-color: #FFFDFD\"> was</span><span style=\"background-color: #FFFEFE\"> 1997</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFBFB\"> black</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFBFB\"> white</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> small</span><span style=\"background-color: #FFFEFE\"> town</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFAFA\"> is</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFF0F0\"> significant</span><span style=\"background-color: #FFFEFE\"> step</span><span style=\"background-color: #FFFCFC\"> up</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFF2F2\"> good</span><span style=\"background-color: #FFFAFA\"> but</span><span style=\"background-color: #FFDBDB\"> flawed</span><span style=\"background-color: #FFFEFE\"> 1999</span><span style=\"background-color: #FFFCFC\"> film</span><span style=\"background-color: #FFF6F6\"> clouds</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFF1F1\"> may</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> earlier</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFDFD\"> had</span><span style=\"background-color: #FFFDFD\"> potential</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFF8F8\"> but</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> small</span><span style=\"background-color: #FFFCFC\"> budget</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFEFE\"> improvised</span><span style=\"background-color: #FFFBFB\"> quality</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FF1313\"> worst</span><span style=\"background-color: #FFF6F6\"> ways</span><span style=\"background-color: #FFFDFD\"> plot</span><span style=\"background-color: #FFF2F2\"> holes</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFDFD\"> wooden</span><span style=\"background-color: #FFFEFE\"> acting</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> amateurs</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFF7F7\"> clouds</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFEFEF\"> may</span><span style=\"background-color: #FFFBFB\"> succeeded</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFEFE\"> any</span><span style=\"background-color: #FFFEFE\"> level</span><span style=\"background-color: #FFFEFE\"> was</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> testament</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFAFA\"> <unk></span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFFEFE\"> talent</span><span style=\"background-color: #FFF7F7\"> as</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> budding</span><span style=\"background-color: #FFFEFE\"> filmmaker</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFBFB\"> however</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF8F8\"> distant</span><span style=\"background-color: #FFF9F9\"> is</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFDFD\"> arrival</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> international</span><span style=\"background-color: #FFFEFE\"> scene</span><span style=\"background-color: #FFF8F8\"> as</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFF6F6\"> great</span><span style=\"background-color: #FFFEFE\"> artist</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFFDFD\"> one</span><span style=\"background-color: #FFFDFD\"> who</span><span style=\"background-color: #FFFBFB\"> has</span><span style=\"background-color: #FFF8F8\"> many</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFCFC\"> same</span><span style=\"background-color: #FFFDFD\"> qualities</span><span style=\"background-color: #FFF6F6\"> as</span><span style=\"background-color: #FFFDFD\"> other</span><span style=\"background-color: #FFF5F5\"> great</span><span style=\"background-color: #FFFEFE\"> filmmakers</span><span style=\"background-color: #FFFEFE\"> like</span><span style=\"background-color: #FFF9F9\"> ingmar</span><span style=\"background-color: #FFFEFE\"> bergman</span><span style=\"background-color: #FFF1F1\"> although</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFCFC\"> screenplay</span><span style=\"background-color: #FFF9F9\"> is</span><span style=\"background-color: #FFF8F8\"> not</span><span style=\"background-color: #FFF6F6\"> as</span><span style=\"background-color: #FFE9E9\"> dialogue</span><span style=\"background-color: #FFBABA\"> heavy</span><span style=\"background-color: #FFF5F5\"> it</span><span style=\"background-color: #FFF8F8\"> is</span><span style=\"background-color: #FFFCFC\"> just</span><span style=\"background-color: #FFF7F7\"> as</span><span style=\"background-color: #FFF7F7\"> brooding</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF8F8\"> and</span><span style=\"background-color: #FFF7F7\"> he</span><span style=\"background-color: #FFC4C4\"> lacks</span><span style=\"background-color: #FFFEFE\"> bergman</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFF4F4\"> penchant</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFD6D6\"> close</span><span style=\"background-color: #FFE6E6\"> ups</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> shots</span><span style=\"background-color: #FFFBFB\"> are</span><span style=\"background-color: #FFFCFC\"> usually</span><span style=\"background-color: #FFFBFB\"> long</span><span style=\"background-color: #FFFEFE\"> shots</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFEFE\"> exteriors</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFDFD\"> medium</span><span style=\"background-color: #FFFEFE\"> shots</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFCFC\"> interiors</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> ozu</span><span style=\"background-color: #FFFEFE\"> whose</span><span style=\"background-color: #FFF0F0\"> penetrating</span><span style=\"background-color: #FFFAFA\"> scenes</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFD4D4\"> contemplation</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFBFB\"> bulk</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFCFC\"> film</span><span style=\"background-color: #FFFCFC\"> takes</span><span style=\"background-color: #FFFEFE\"> place</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFF3F3\"> snowy</span><span style=\"background-color: #FFFAFA\"> <unk></span><span style=\"background-color: #FFEFEF\"> istanbul</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFEFEF\"> fact</span><span style=\"background-color: #FFFCFC\"> that</span><span style=\"background-color: #FFF6F6\"> it</span><span style=\"background-color: #FFFBFB\"> <unk></span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFCECE\"> turkey</span><span style=\"background-color: #FFEAEA\"> will</span><span style=\"background-color: #FFC5C5\"> likely</span><span style=\"background-color: #FFD9D9\"> surprise</span><span style=\"background-color: #FFFAFA\"> some</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFBFB\"> which</span><span style=\"background-color: #FFF6F6\"> lends</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFCFC\"> film</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFBFB\"> definite</span><span style=\"background-color: #FFF9F9\"> <unk></span><span style=\"background-color: #FFFDFD\"> feel</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFF4F4\"> as</span><span style=\"background-color: #FFDADA\"> well</span><span style=\"background-color: #FFF5F5\"> as</span><span style=\"background-color: #FFFDFD\"> reminding</span><span style=\"background-color: #FFFDFD\"> one</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFBFB\"> some</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFF8F8\"> bleak</span><span style=\"background-color: #FFF3F3\"> snowy</span><span style=\"background-color: #FFFCFC\"> urban</span><span style=\"background-color: #FFF2F2\"> images</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> natural</span><span style=\"background-color: #FFF0F0\"> images</span><span style=\"background-color: #FFFBFB\"> <unk></span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFEBEB\"> best</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> werner</span><span style=\"background-color: #FFFDFD\"> herzog</span><span style=\"background-color: #FFF6F6\"> as</span><span style=\"background-color: #FFFDFD\"> they</span><span style=\"background-color: #FFFDFD\"> tend</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFCFC\"> go</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFEDED\"> beat</span><span style=\"background-color: #FFFDFD\"> or</span><span style=\"background-color: #FFF8F8\"> two</span><span style=\"background-color: #FFF7F7\"> longer</span><span style=\"background-color: #FFFDFD\"> than</span><span style=\"background-color: #FFFAFA\"> standard</span><span style=\"background-color: #FFFCFC\"> film</span><span style=\"background-color: #FFFBFB\"> theory</span><span style=\"background-color: #FFFDFD\"> would</span><span style=\"background-color: #FFF9F9\"> <unk></span><span style=\"background-color: #FFFAFA\"> which</span><span style=\"background-color: #FFF7F7\"> is</span><span style=\"background-color: #FFFAFA\"> what</span><span style=\"background-color: #FFDEDE\"> makes</span><span style=\"background-color: #FFFEFE\"> them</span><span style=\"background-color: #FFF7F7\"> even</span><span style=\"background-color: #FFFCFC\"> more</span><span style=\"background-color: #FFF9F9\"> memorable</span><span style=\"background-color: #FFF6F6\"> <eos></span><br><br>[TransformerBlockの2段目のAttentionを可視化]<br><span style=\"background-color: #FFFEFE\"> <cls></span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FF0000\"> bilge</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFCFC\"> s</span><span style=\"background-color: #FFFDFD\"> 2002</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFAFA\"> distant</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFBFB\"> his</span><span style=\"background-color: #FFF6F6\"> third</span><span style=\"background-color: #FFFEFE\"> feature</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFF9F9\"> his</span><span style=\"background-color: #FFF9F9\"> first</span><span style=\"background-color: #FFFAFA\"> was</span><span style=\"background-color: #FFFBFB\"> 1997</span><span style=\"background-color: #FFFCFC\"> s</span><span style=\"background-color: #FFFEFE\"> black</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> white</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFBFB\"> small</span><span style=\"background-color: #FFFEFE\"> town</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFBFB\"> is</span><span style=\"background-color: #FFFCFC\"> a</span><span style=\"background-color: #FFFCFC\"> significant</span><span style=\"background-color: #FFFDFD\"> step</span><span style=\"background-color: #FFFBFB\"> up</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFBFB\"> his</span><span style=\"background-color: #FF9494\"> good</span><span style=\"background-color: #FFF9F9\"> but</span><span style=\"background-color: #FF9797\"> flawed</span><span style=\"background-color: #FFFDFD\"> 1999</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFF7F7\"> clouds</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> may</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFBFB\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFDBDB\"> earlier</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFDFD\"> had</span><span style=\"background-color: #FFFBFB\"> potential</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF8F8\"> but</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFF8F8\"> a</span><span style=\"background-color: #FFFBFB\"> small</span><span style=\"background-color: #FFFEFE\"> budget</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> improvised</span><span style=\"background-color: #FFFEFE\"> quality</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFB8B8\"> worst</span><span style=\"background-color: #FFFBFB\"> ways</span><span style=\"background-color: #FFF7F7\"> plot</span><span style=\"background-color: #FFFDFD\"> holes</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> wooden</span><span style=\"background-color: #FFFDFD\"> acting</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> amateurs</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> that</span><span style=\"background-color: #FFF8F8\"> clouds</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> may</span><span style=\"background-color: #FFF8F8\"> succeeded</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFEFE\"> any</span><span style=\"background-color: #FFFDFD\"> level</span><span style=\"background-color: #FFFCFC\"> was</span><span style=\"background-color: #FFF9F9\"> a</span><span style=\"background-color: #FFE1E1\"> testament</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFFCFC\"> talent</span><span style=\"background-color: #FFECEC\"> as</span><span style=\"background-color: #FFF8F8\"> a</span><span style=\"background-color: #FFF9F9\"> budding</span><span style=\"background-color: #FFFDFD\"> filmmaker</span><span style=\"background-color: #FFFAFA\"> .</span><span style=\"background-color: #FFD0D0\"> however</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFAFA\"> distant</span><span style=\"background-color: #FFF8F8\"> is</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFFBFB\"> arrival</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> international</span><span style=\"background-color: #FFFDFD\"> scene</span><span style=\"background-color: #FFF4F4\"> as</span><span style=\"background-color: #FFF9F9\"> a</span><span style=\"background-color: #FF5353\"> great</span><span style=\"background-color: #FFFDFD\"> artist</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFAFA\"> one</span><span style=\"background-color: #FFFEFE\"> who</span><span style=\"background-color: #FFFAFA\"> has</span><span style=\"background-color: #FFFDFD\"> many</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFCFC\"> same</span><span style=\"background-color: #FFF9F9\"> qualities</span><span style=\"background-color: #FFEEEE\"> as</span><span style=\"background-color: #FFFEFE\"> other</span><span style=\"background-color: #FF7575\"> great</span><span style=\"background-color: #FFFEFE\"> filmmakers</span><span style=\"background-color: #FFF4F4\"> like</span><span style=\"background-color: #FFFEFE\"> ingmar</span><span style=\"background-color: #FFFCFC\"> bergman</span><span style=\"background-color: #FFE2E2\"> although</span><span style=\"background-color: #FFF6F6\"> his</span><span style=\"background-color: #FFFDFD\"> screenplay</span><span style=\"background-color: #FFF4F4\"> is</span><span style=\"background-color: #FFF5F5\"> not</span><span style=\"background-color: #FFEEEE\"> as</span><span style=\"background-color: #FFF6F6\"> dialogue</span><span style=\"background-color: #FFE3E3\"> heavy</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFF9F9\"> is</span><span style=\"background-color: #FFF8F8\"> just</span><span style=\"background-color: #FFF3F3\"> as</span><span style=\"background-color: #FFEBEB\"> brooding</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> he</span><span style=\"background-color: #FF3A3A\"> lacks</span><span style=\"background-color: #FFFDFD\"> bergman</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFDFDF\"> penchant</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFCFC\"> close</span><span style=\"background-color: #FFF2F2\"> ups</span><span style=\"background-color: #FFFCFC\"> his</span><span style=\"background-color: #FFFDFD\"> shots</span><span style=\"background-color: #FFFCFC\"> are</span><span style=\"background-color: #FFFBFB\"> usually</span><span style=\"background-color: #FFF1F1\"> long</span><span style=\"background-color: #FFFDFD\"> shots</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFEFE\"> exteriors</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> medium</span><span style=\"background-color: #FFFDFD\"> shots</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFEFE\"> interiors</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> ozu</span><span style=\"background-color: #FFFDFD\"> whose</span><span style=\"background-color: #FFFDFD\"> penetrating</span><span style=\"background-color: #FFFDFD\"> scenes</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFCFC\"> contemplation</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFBFB\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFF4F4\"> bulk</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFDFD\"> takes</span><span style=\"background-color: #FFFEFE\"> place</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFD8D8\"> snowy</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFCFC\"> istanbul</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFD7D7\"> fact</span><span style=\"background-color: #FFFDFD\"> that</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFDFD\"> turkey</span><span style=\"background-color: #FFFEFE\"> will</span><span style=\"background-color: #FFBABA\"> likely</span><span style=\"background-color: #FF6363\"> surprise</span><span style=\"background-color: #FFFDFD\"> some</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFFCFC\"> lends</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFF4F4\"> a</span><span style=\"background-color: #FFE8E8\"> definite</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFF1F1\"> feel</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFEAEA\"> as</span><span style=\"background-color: #FFB0B0\"> well</span><span style=\"background-color: #FFEDED\"> as</span><span style=\"background-color: #FFFEFE\"> reminding</span><span style=\"background-color: #FFF8F8\"> one</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFCFC\"> some</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFD8D8\"> bleak</span><span style=\"background-color: #FFB3B3\"> snowy</span><span style=\"background-color: #FFFDFD\"> urban</span><span style=\"background-color: #FFFDFD\"> images</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFCFC\"> s</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFBFB\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFF4F4\"> natural</span><span style=\"background-color: #FFFEFE\"> images</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFD4D4\"> best</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> werner</span><span style=\"background-color: #FFF4F4\"> herzog</span><span style=\"background-color: #FFE7E7\"> as</span><span style=\"background-color: #FFFEFE\"> they</span><span style=\"background-color: #FFE8E8\"> tend</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> go</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFAFA\"> a</span><span style=\"background-color: #FFFDFD\"> beat</span><span style=\"background-color: #FFFEFE\"> or</span><span style=\"background-color: #FFFDFD\"> two</span><span style=\"background-color: #FFFDFD\"> longer</span><span style=\"background-color: #FFF8F8\"> than</span><span style=\"background-color: #FFFDFD\"> standard</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFF5F5\"> theory</span><span style=\"background-color: #FFFEFE\"> would</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFF4F4\"> is</span><span style=\"background-color: #FFFDFD\"> what</span><span style=\"background-color: #FFFBFB\"> makes</span><span style=\"background-color: #FFFEFE\"> them</span><span style=\"background-color: #FFFCFC\"> even</span><span style=\"background-color: #FFFAFA\"> more</span><span style=\"background-color: #FFD9D9\"> memorable</span><span style=\"background-color: #FFFEFE\"> <eos></span><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "batch = next(iter(test_dl))\n",
    "\n",
    "inputs = batch.Text[0].to(device)\n",
    "labels = batch.Label.to(device)\n",
    "\n",
    "input_pad = 1\n",
    "input_mask = (inputs != input_pad)\n",
    "\n",
    "outputs, normilized_weights_1, normilized_weights_2 = net_trained(inputs, input_mask)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "index = 3\n",
    "html_output = mk_html(index, batch, preds, normilized_weights_1, normilized_weights_2, TEXT)\n",
    "HTML(html_output)  # HTML形式で出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "正解ラベル：Positive<br>推論ラベル：Negative<br><br>[TransformerBlockの1段目のAttentionを可視化]<br><span style=\"background-color: #FFFCFC\"> <cls></span><span style=\"background-color: #FFFCFC\"> death</span><span style=\"background-color: #FFFEFE\"> wish</span><span style=\"background-color: #FFC6C6\"> 3</span><span style=\"background-color: #FFF6F6\"> brings</span><span style=\"background-color: #FFF9F9\"> back</span><span style=\"background-color: #FFFBFB\"> charles</span><span style=\"background-color: #FFF7F7\"> bronson</span><span style=\"background-color: #FFF7F7\"> as</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFDFD\"> time</span><span style=\"background-color: #FFFEFE\"> vigilante</span><span style=\"background-color: #FFF8F8\"> paul</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFBFB\"> now</span><span style=\"background-color: #FFFDFD\"> retired</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFE6E6\"> yeah</span><span style=\"background-color: #FFFDFD\"> ,</span><span style=\"background-color: #FFFCFC\"> right</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> before</span><span style=\"background-color: #FFFCFC\"> long</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFAFA\"> is</span><span style=\"background-color: #FFFBFB\"> back</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> old</span><span style=\"background-color: #FFF4F4\"> ways</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFAFA\"> but</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFDFD\"> time</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFAFA\"> its</span><span style=\"background-color: #FFF7F7\"> not</span><span style=\"background-color: #FFFCFC\"> just</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFAFA\"> few</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFDFD\"> at</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> time</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFBFB\"> its</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> gang</span><span style=\"background-color: #FFFEFE\"> who</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> taken</span><span style=\"background-color: #FFFDFD\"> over</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> run</span><span style=\"background-color: #FFFBFB\"> down</span><span style=\"background-color: #FFFEFE\"> part</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> city</span><span style=\"background-color: #FFFEFE\"> new</span><span style=\"background-color: #FFFCFC\"> york</span><span style=\"background-color: #FFEDED\"> again</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFBFB\"> way</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFDFD\"> time</span><span style=\"background-color: #FFFCFC\"> its</span><span style=\"background-color: #FFFDFD\"> war</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFF9F9\"> so</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFCFC\"> out</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> big</span><span style=\"background-color: #FFFEFE\"> guns</span><span style=\"background-color: #FFFCFC\"> literally</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> body</span><span style=\"background-color: #FFFCFC\"> count</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFDFD\"> one</span><span style=\"background-color: #FFFDFD\"> rivals</span><span style=\"background-color: #FFFDFD\"> anything</span><span style=\"background-color: #FFFEFE\"> stallone</span><span style=\"background-color: #FFFDFD\"> or</span><span style=\"background-color: #FFFBFB\"> schwarzenegger</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFCFC\"> come</span><span style=\"background-color: #FFFDFD\"> up</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFDFD\"> movie</span><span style=\"background-color: #FFFAFA\"> is</span><span style=\"background-color: #FFF9F9\"> actually</span><span style=\"background-color: #FFF4F4\"> somewhat</span><span style=\"background-color: #FFCDCD\"> fun</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFCFC\"> watch</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF6F6\"> particularly</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFF8F8\"> few</span><span style=\"background-color: #FFFDFD\"> one</span><span style=\"background-color: #FFFBFB\"> liners</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> course</span><span style=\"background-color: #FFADAD\"> bad</span><span style=\"background-color: #FFFCFC\"> guys</span><span style=\"background-color: #FFFBFB\"> die</span><span style=\"background-color: #FFF9F9\"> ,</span><span style=\"background-color: #FFFDFD\"> or</span><span style=\"background-color: #FFFEFE\"> get</span><span style=\"background-color: #FFE0E0\"> severely</span><span style=\"background-color: #FFFCFC\"> injured</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> creative</span><span style=\"background-color: #FFF2F2\"> ways</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFAFA\"> which</span><span style=\"background-color: #FFF8F8\"> is</span><span style=\"background-color: #FFFCFC\"> always</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFEEEE\"> good</span><span style=\"background-color: #FFFDFD\"> thing</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFF9F9\"> violence</span><span style=\"background-color: #FFF8F8\"> is</span><span style=\"background-color: #FFF8F8\"> not</span><span style=\"background-color: #FFF7F7\"> as</span><span style=\"background-color: #FFFEFE\"> personal</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFBFB\"> its</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFF8F8\"> obviously</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFF9F9\"> much</span><span style=\"background-color: #FFFEFE\"> grander</span><span style=\"background-color: #FFFEFE\"> scale</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFCFC\"> sort</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> like</span><span style=\"background-color: #FFEEEE\"> bombing</span><span style=\"background-color: #FFFEFE\"> your</span><span style=\"background-color: #FFFDFD\"> victims</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> afar</span><span style=\"background-color: #FFFCFC\"> ,</span><span style=\"background-color: #FFFEFE\"> rather</span><span style=\"background-color: #FFFEFE\"> than</span><span style=\"background-color: #FFFDFD\"> one</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFDFD\"> one</span><span style=\"background-color: #FFFEFE\"> combat</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFCFC\"> movie</span><span style=\"background-color: #FFF9F9\"> is</span><span style=\"background-color: #FFFBFB\"> lighter</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFF9F9\"> tone</span><span style=\"background-color: #FFFDFD\"> than</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FF9696\"> 1st</span><span style=\"background-color: #FFF2F2\"> 2</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFDFD\"> making</span><span style=\"background-color: #FFF7F7\"> it</span><span style=\"background-color: #FFF3F3\"> easier</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFBFB\"> watch</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> there</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFF7F7\"> not</span><span style=\"background-color: #FFF7F7\"> much</span><span style=\"background-color: #FFFBFB\"> import</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFCFC\"> film</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFF8F8\"> its</span><span style=\"background-color: #FFFCFC\"> more</span><span style=\"background-color: #FFFBFB\"> escapism</span><span style=\"background-color: #FFFDFD\"> than</span><span style=\"background-color: #FFFDFD\"> anything</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF9F9\"> its</span><span style=\"background-color: #FFFCFC\"> also</span><span style=\"background-color: #FFD1D1\"> cheesy</span><span style=\"background-color: #FFFCFC\"> at</span><span style=\"background-color: #FFEBEB\"> times</span><span style=\"background-color: #FFFAFA\"> and</span><span style=\"background-color: #FFFCFC\"> pseudo</span><span style=\"background-color: #FFFEFE\"> inspirational</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF9F9\"> but</span><span style=\"background-color: #FFFEFE\"> hose</span><span style=\"background-color: #FFFAFA\"> scenes</span><span style=\"background-color: #FFFCFC\"> fall</span><span style=\"background-color: #FFFCFC\"> flat</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> they</span><span style=\"background-color: #FFF4F4\"> should</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFDFD\"> left</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> original</span><span style=\"background-color: #FFFCFC\"> death</span><span style=\"background-color: #FFFEFE\"> wish</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFF9F9\"> its</span><span style=\"background-color: #FFFEFE\"> own</span><span style=\"background-color: #FFFDFD\"> without</span><span style=\"background-color: #FFF9F9\"> sequels</span><span style=\"background-color: #FFFBFB\"> ,</span><span style=\"background-color: #FFF7F7\"> but</span><span style=\"background-color: #FFF5F5\"> since</span><span style=\"background-color: #FFFCFC\"> they</span><span style=\"background-color: #FFF7F7\"> didn</span><span style=\"background-color: #FFEEEE\"> t</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFDFD\"> they</span><span style=\"background-color: #FFF3F3\"> should</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFF7F7\"> stopped</span><span style=\"background-color: #FFFCFC\"> here</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FF0000\"> 8</span><span style=\"background-color: #FFEBEB\"> 10</span><span style=\"background-color: #FFF9F9\"> <eos></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><br><br>[TransformerBlockの2段目のAttentionを可視化]<br><span style=\"background-color: #FFFEFE\"> <cls></span><span style=\"background-color: #FFFEFE\"> death</span><span style=\"background-color: #FFF4F4\"> wish</span><span style=\"background-color: #FFFEFE\"> 3</span><span style=\"background-color: #FFFEFE\"> brings</span><span style=\"background-color: #FFFEFE\"> back</span><span style=\"background-color: #FFFEFE\"> charles</span><span style=\"background-color: #FFFEFE\"> bronson</span><span style=\"background-color: #FFFDFD\"> as</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> vigilante</span><span style=\"background-color: #FFFEFE\"> paul</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> now</span><span style=\"background-color: #FFFEFE\"> retired</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFCECE\"> yeah</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> right</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> before</span><span style=\"background-color: #FFFDFD\"> long</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> back</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> old</span><span style=\"background-color: #FFFEFE\"> ways</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFCFC\"> but</span><span style=\"background-color: #FFFEFE\"> this</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFBFB\"> not</span><span style=\"background-color: #FFFAFA\"> just</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFAFA\"> few</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> at</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFAFA\"> gang</span><span style=\"background-color: #FFFEFE\"> who</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFDFD\"> taken</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> run</span><span style=\"background-color: #FFFEFE\"> down</span><span style=\"background-color: #FFFEFE\"> part</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> city</span><span style=\"background-color: #FFFEFE\"> new</span><span style=\"background-color: #FFFEFE\"> york</span><span style=\"background-color: #FFFCFC\"> again</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> way</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFDFD\"> this</span><span style=\"background-color: #FFFEFE\"> time</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFEFE\"> war</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> so</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> out</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> big</span><span style=\"background-color: #FFFEFE\"> guns</span><span style=\"background-color: #FFFDFD\"> literally</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFDFD\"> this</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> body</span><span style=\"background-color: #FFFEFE\"> count</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFBFB\"> rivals</span><span style=\"background-color: #FFFDFD\"> anything</span><span style=\"background-color: #FFFDFD\"> stallone</span><span style=\"background-color: #FFFEFE\"> or</span><span style=\"background-color: #FFFEFE\"> schwarzenegger</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> come</span><span style=\"background-color: #FFFDFD\"> up</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFCFC\"> .</span><span style=\"background-color: #FFFDFD\"> this</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFDFD\"> actually</span><span style=\"background-color: #FFABAB\"> somewhat</span><span style=\"background-color: #FFC6C6\"> fun</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFCFC\"> watch</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> particularly</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFBFB\"> few</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFEFE\"> liners</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> course</span><span style=\"background-color: #FFFCFC\"> bad</span><span style=\"background-color: #FFFCFC\"> guys</span><span style=\"background-color: #FFFEFE\"> die</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> or</span><span style=\"background-color: #FFFDFD\"> get</span><span style=\"background-color: #FFE4E4\"> severely</span><span style=\"background-color: #FFFEFE\"> injured</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> creative</span><span style=\"background-color: #FFFEFE\"> ways</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> which</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFBFB\"> always</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFAFA\"> good</span><span style=\"background-color: #FFFDFD\"> thing</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> violence</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFBFB\"> not</span><span style=\"background-color: #FFFDFD\"> as</span><span style=\"background-color: #FFFEFE\"> personal</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFDFD\"> this</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFE0E0\"> obviously</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFF9F9\"> much</span><span style=\"background-color: #FFFBFB\"> grander</span><span style=\"background-color: #FFFDFD\"> scale</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> sort</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFCFC\"> like</span><span style=\"background-color: #FFFEFE\"> bombing</span><span style=\"background-color: #FFFDFD\"> your</span><span style=\"background-color: #FFFEFE\"> victims</span><span style=\"background-color: #FFFEFE\"> from</span><span style=\"background-color: #FFFEFE\"> afar</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFF7F7\"> rather</span><span style=\"background-color: #FFFEFE\"> than</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFEFE\"> one</span><span style=\"background-color: #FFFEFE\"> combat</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFDFD\"> this</span><span style=\"background-color: #FFFEFE\"> movie</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFEFE\"> lighter</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFF7F7\"> tone</span><span style=\"background-color: #FFFEFE\"> than</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> 1st</span><span style=\"background-color: #FFFEFE\"> 2</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> making</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFCFC\"> easier</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFCFC\"> watch</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFCFC\"> there</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFCFC\"> not</span><span style=\"background-color: #FFF6F6\"> much</span><span style=\"background-color: #FFFEFE\"> import</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFDFD\"> this</span><span style=\"background-color: #FFFEFE\"> film</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFCFC\"> more</span><span style=\"background-color: #FFFBFB\"> escapism</span><span style=\"background-color: #FFFDFD\"> than</span><span style=\"background-color: #FFFDFD\"> anything</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFEFE\"> also</span><span style=\"background-color: #FF0000\"> cheesy</span><span style=\"background-color: #FFFEFE\"> at</span><span style=\"background-color: #FFFDFD\"> times</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFDEDE\"> pseudo</span><span style=\"background-color: #FFF8F8\"> inspirational</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFAFA\"> but</span><span style=\"background-color: #FFFEFE\"> hose</span><span style=\"background-color: #FFFEFE\"> scenes</span><span style=\"background-color: #FFFDFD\"> fall</span><span style=\"background-color: #FFFAFA\"> flat</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> they</span><span style=\"background-color: #FFFEFE\"> should</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> left</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> original</span><span style=\"background-color: #FFFEFE\"> death</span><span style=\"background-color: #FFF0F0\"> wish</span><span style=\"background-color: #FFFEFE\"> on</span><span style=\"background-color: #FFFEFE\"> its</span><span style=\"background-color: #FFFEFE\"> own</span><span style=\"background-color: #FFFDFD\"> without</span><span style=\"background-color: #FFFDFD\"> sequels</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> but</span><span style=\"background-color: #FFFEFE\"> since</span><span style=\"background-color: #FFFEFE\"> they</span><span style=\"background-color: #FFFDFD\"> didn</span><span style=\"background-color: #FFFEFE\"> t</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> they</span><span style=\"background-color: #FFFEFE\"> should</span><span style=\"background-color: #FFFEFE\"> have</span><span style=\"background-color: #FFFEFE\"> stopped</span><span style=\"background-color: #FFFEFE\"> here</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> 8</span><span style=\"background-color: #FFFEFE\"> 10</span><span style=\"background-color: #FFFEFE\"> <eos></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 10\n",
    "html_output = mk_html(index, batch, preds, normilized_weights_1, normilized_weights_2, TEXT)\n",
    "HTML(html_output)  # HTML形式で出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
